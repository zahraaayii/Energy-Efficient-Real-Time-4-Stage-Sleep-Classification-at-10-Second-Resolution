{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQW2KZ4WWZ-q",
    "outputId": "d771434b-1869-45e3-c10b-2a6a8c12eb93"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# base_dir='/content/drive/MyDrive/ucd/'\n",
    "base_dir='../../folders/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yinkTQ-8WZ-u"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zazaz\\AppData\\Local\\Temp\\ipykernel_3572\\3898385719.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential,load_model,load_model\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import Conv1D, SeparableConv1D,GlobalAveragePooling1D,Add, Conv2D,MaxPooling1D,MaxPooling2D, Dropout,Dense,Flatten,Activation, Flatten, BatchNormalization,Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import scipy.stats as stats\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install QKeras\n",
    "from qkeras import *\n",
    "import pprint\n",
    "from qkeras.autoqkeras import *\n",
    "from qkeras import *\n",
    "from qkeras.qtools import run_qtools\n",
    "from qkeras.qtools import settings as qtools_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        y_true = K.cast(y_true, 'float32')\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision_m(y_true, y_pred):\n",
    "        y_true = K.cast(y_true, 'float32')\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision\n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3RXsgFbDwmo",
    "outputId": "c4e2418a-2573-404c-a807-83485e509c41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49797, 3840, 1)\n",
      "(49797, 4)\n"
     ]
    }
   ],
   "source": [
    "with open(base_dir+f'all/train_all.pkl', 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "                x_train = res['x_train']\n",
    "                y_train = res['y_train']\n",
    "del res\n",
    "x_train=np.reshape(x_train,(len(x_train),3840,1))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12450, 3840, 1)\n",
      "(12450, 4)\n"
     ]
    }
   ],
   "source": [
    "with open(base_dir+f'all/test_all.pkl', 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "                x_test = res['x_test']\n",
    "                y_test = res['y_test']\n",
    "del res\n",
    "x_test=np.reshape(x_test,(len(x_test),3840,1))\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 3840, 1)]    0           []                               \n",
      "                                                                                                  \n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 3840, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " q_conv1d (QConv1D)             (None, 1920, 64)     512         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1920, 64)    256         ['q_conv1d[0][0]']               \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " q_activation (QActivation)     (None, 1920, 64)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 960, 64)      0           ['q_activation[0][0]']           \n",
      "                                                                                                  \n",
      " q_conv1d_1 (QConv1D)           (None, 960, 64)      12352       ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 960, 64)     256         ['q_conv1d_1[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " q_activation_1 (QActivation)   (None, 960, 64)      0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " q_conv1d_2 (QConv1D)           (None, 960, 64)      12352       ['q_activation_1[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 960, 64)     256         ['q_conv1d_2[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 960, 64)      0           ['batch_normalization_2[0][0]',  \n",
      "                                                                  'max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " q_activation_2 (QActivation)   (None, 960, 64)      0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " q_conv1d_3 (QConv1D)           (None, 960, 64)      12352       ['q_activation_2[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 960, 64)     256         ['q_conv1d_3[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " q_activation_3 (QActivation)   (None, 960, 64)      0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " q_conv1d_4 (QConv1D)           (None, 960, 64)      12352       ['q_activation_3[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 960, 64)     256         ['q_conv1d_4[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 960, 64)      0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'q_activation_2[0][0]']         \n",
      "                                                                                                  \n",
      " q_activation_4 (QActivation)   (None, 960, 64)      0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " q_conv1d_5 (QConv1D)           (None, 480, 128)     24704       ['q_activation_4[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 480, 128)    512         ['q_conv1d_5[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " q_activation_5 (QActivation)   (None, 480, 128)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " q_conv1d_6 (QConv1D)           (None, 480, 128)     49280       ['q_activation_5[0][0]']         \n",
      "                                                                                                  \n",
      " q_conv1d_7 (QConv1D)           (None, 480, 128)     8320        ['q_activation_4[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 480, 128)    512         ['q_conv1d_6[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 480, 128)    512         ['q_conv1d_7[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 480, 128)     0           ['batch_normalization_6[0][0]',  \n",
      "                                                                  'batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " q_activation_6 (QActivation)   (None, 480, 128)     0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " q_conv1d_8 (QConv1D)           (None, 480, 128)     49280       ['q_activation_6[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 480, 128)    512         ['q_conv1d_8[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " q_activation_7 (QActivation)   (None, 480, 128)     0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " q_conv1d_9 (QConv1D)           (None, 480, 128)     49280       ['q_activation_7[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 480, 128)    512         ['q_conv1d_9[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 480, 128)     0           ['batch_normalization_9[0][0]',  \n",
      "                                                                  'q_activation_6[0][0]']         \n",
      "                                                                                                  \n",
      " q_activation_8 (QActivation)   (None, 480, 128)     0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " q_conv1d_10 (QConv1D)          (None, 240, 256)     98560       ['q_activation_8[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 240, 256)    1024        ['q_conv1d_10[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " q_activation_9 (QActivation)   (None, 240, 256)     0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " q_conv1d_11 (QConv1D)          (None, 240, 256)     196864      ['q_activation_9[0][0]']         \n",
      "                                                                                                  \n",
      " q_conv1d_12 (QConv1D)          (None, 240, 256)     33024       ['q_activation_8[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 240, 256)    1024        ['q_conv1d_11[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 240, 256)    1024        ['q_conv1d_12[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 240, 256)     0           ['batch_normalization_11[0][0]', \n",
      "                                                                  'batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " q_activation_10 (QActivation)  (None, 240, 256)     0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " q_conv1d_13 (QConv1D)          (None, 240, 256)     196864      ['q_activation_10[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 240, 256)    1024        ['q_conv1d_13[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " q_activation_11 (QActivation)  (None, 240, 256)     0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " q_conv1d_14 (QConv1D)          (None, 240, 256)     196864      ['q_activation_11[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 240, 256)    1024        ['q_conv1d_14[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 240, 256)     0           ['batch_normalization_14[0][0]', \n",
      "                                                                  'q_activation_10[0][0]']        \n",
      "                                                                                                  \n",
      " q_activation_12 (QActivation)  (None, 240, 256)     0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " q_conv1d_15 (QConv1D)          (None, 120, 512)     393728      ['q_activation_12[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 120, 512)    2048        ['q_conv1d_15[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " q_activation_13 (QActivation)  (None, 120, 512)     0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " q_conv1d_16 (QConv1D)          (None, 120, 512)     786944      ['q_activation_13[0][0]']        \n",
      "                                                                                                  \n",
      " q_conv1d_17 (QConv1D)          (None, 120, 512)     131584      ['q_activation_12[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 120, 512)    2048        ['q_conv1d_16[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 120, 512)    2048        ['q_conv1d_17[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 120, 512)     0           ['batch_normalization_16[0][0]', \n",
      "                                                                  'batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " q_activation_14 (QActivation)  (None, 120, 512)     0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " q_conv1d_18 (QConv1D)          (None, 120, 512)     786944      ['q_activation_14[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 120, 512)    2048        ['q_conv1d_18[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " q_activation_15 (QActivation)  (None, 120, 512)     0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " q_conv1d_19 (QConv1D)          (None, 120, 512)     786944      ['q_activation_15[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 120, 512)    2048        ['q_conv1d_19[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 120, 512)     0           ['batch_normalization_19[0][0]', \n",
      "                                                                  'q_activation_14[0][0]']        \n",
      "                                                                                                  \n",
      " q_activation_16 (QActivation)  (None, 120, 512)     0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 512)         0           ['q_activation_16[0][0]']        \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " q_dense (QDense)               (None, 4)            2052        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,860,356\n",
      "Trainable params: 3,850,756\n",
      "Non-trainable params: 9,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def residual_block(input_tensor, filters, kernel_size, strides=1, l2_reg=0.01):\n",
    "    x = QConv1D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same', kernel_regularizer=l2(l2_reg),kernel_quantizer=quantized_bits(8, 1,alpha=1), bias_quantizer=quantized_bits(8, 1,alpha=1))(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = QActivation(\"quantized_relu(8,1)\")(x)\n",
    "    \n",
    "    x = QConv1D(filters=filters, kernel_size=kernel_size, strides=1, padding='same', kernel_regularizer=l2(l2_reg),kernel_quantizer=quantized_bits(8, 1,alpha=1), bias_quantizer=quantized_bits(8, 1,alpha=1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Shortcut connection\n",
    "    if strides != 1 or input_tensor.shape[-1] != filters:\n",
    "        shortcut = QConv1D(filters=filters, kernel_size=1, strides=strides, padding='same', kernel_regularizer=l2(l2_reg),kernel_quantizer=quantized_bits(8, 1,alpha=1), bias_quantizer=quantized_bits(8, 1,alpha=1))(input_tensor)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    else:\n",
    "        shortcut = input_tensor\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = QActivation(\"quantized_relu(8,1)\")(x)\n",
    "    return x\n",
    "\n",
    "def build_resnet_18(input_shape, num_classes):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = QConv1D(filters=64, kernel_size=7, strides=2, padding='same', kernel_regularizer=l2(0.01),kernel_quantizer=quantized_bits(8, 1,alpha=1), bias_quantizer=quantized_bits(8, 1,alpha=1))(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = QActivation(\"quantized_relu(8,1)\")(x)\n",
    "    x = MaxPooling1D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = residual_block(x, filters=64, kernel_size=3)\n",
    "    x = residual_block(x, filters=64, kernel_size=3)\n",
    "    \n",
    "    x = residual_block(x, filters=128, kernel_size=3, strides=2)\n",
    "    x = residual_block(x, filters=128, kernel_size=3)\n",
    "    \n",
    "    x = residual_block(x, filters=256, kernel_size=3, strides=2)\n",
    "    x = residual_block(x, filters=256, kernel_size=3)\n",
    "    \n",
    "    x = residual_block(x, filters=512, kernel_size=3, strides=2)\n",
    "    x = residual_block(x, filters=512, kernel_size=3)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    " \n",
    "    output_layer =  QDense(num_classes,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='softmax',kernel_quantizer=quantized_bits(8, 1,alpha=1), bias_quantizer=quantized_bits(8, 1,alpha=1))(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "\n",
    "input_shape = (3840,1)\n",
    "num_classes = 4 \n",
    "model = build_resnet_18(input_shape, num_classes)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eT-EH9bzWZ-1",
    "outputId": "aaba5949-69a3-4170-e699-e73d3a8bf10d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "176/176 [==============================] - 102s 521ms/step - loss: 28.7029 - accuracy: 0.5409 - f1: 0.4926 - val_loss: 8.3799 - val_accuracy: 0.2241 - val_f1: 0.0000e+00\n",
      "Epoch 2/200\n",
      "176/176 [==============================] - 90s 512ms/step - loss: 5.2232 - accuracy: 0.5978 - f1: 0.5612 - val_loss: 4.1063 - val_accuracy: 0.2241 - val_f1: 0.1738\n",
      "Epoch 3/200\n",
      "176/176 [==============================] - 89s 509ms/step - loss: 2.9833 - accuracy: 0.6059 - f1: 0.5681 - val_loss: 4.1405 - val_accuracy: 0.2241 - val_f1: 0.2237\n",
      "Epoch 4/200\n",
      "176/176 [==============================] - 90s 509ms/step - loss: 2.2232 - accuracy: 0.6223 - f1: 0.5934 - val_loss: 2.9384 - val_accuracy: 0.2450 - val_f1: 0.2257\n",
      "Epoch 5/200\n",
      "176/176 [==============================] - 90s 511ms/step - loss: 1.9653 - accuracy: 0.6065 - f1: 0.5698 - val_loss: 2.3918 - val_accuracy: 0.5056 - val_f1: 0.5059\n",
      "Epoch 6/200\n",
      "176/176 [==============================] - 90s 511ms/step - loss: 1.7046 - accuracy: 0.6209 - f1: 0.5906 - val_loss: 2.4019 - val_accuracy: 0.2588 - val_f1: 0.2320\n",
      "Epoch 7/200\n",
      "176/176 [==============================] - 89s 505ms/step - loss: 1.5752 - accuracy: 0.6269 - f1: 0.5963 - val_loss: 2.2909 - val_accuracy: 0.2247 - val_f1: 0.2272\n",
      "Epoch 8/200\n",
      "176/176 [==============================] - 88s 501ms/step - loss: 1.4405 - accuracy: 0.6463 - f1: 0.6201 - val_loss: 2.0102 - val_accuracy: 0.5540 - val_f1: 0.5408\n",
      "Epoch 9/200\n",
      "176/176 [==============================] - 88s 499ms/step - loss: 1.4146 - accuracy: 0.6415 - f1: 0.6138 - val_loss: 1.9876 - val_accuracy: 0.5568 - val_f1: 0.5484\n",
      "Epoch 10/200\n",
      "176/176 [==============================] - 89s 507ms/step - loss: 1.3478 - accuracy: 0.6462 - f1: 0.6232 - val_loss: 2.2817 - val_accuracy: 0.5171 - val_f1: 0.5179\n",
      "Epoch 11/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 1.3196 - accuracy: 0.6516 - f1: 0.6292 - val_loss: 2.1781 - val_accuracy: 0.3618 - val_f1: 0.3398\n",
      "Epoch 12/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 1.2812 - accuracy: 0.6532 - f1: 0.6299 - val_loss: 1.9246 - val_accuracy: 0.4440 - val_f1: 0.4394\n",
      "Epoch 13/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 1.2755 - accuracy: 0.6555 - f1: 0.6349 - val_loss: 2.5483 - val_accuracy: 0.2737 - val_f1: 0.2389\n",
      "Epoch 14/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 1.2331 - accuracy: 0.6604 - f1: 0.6415 - val_loss: 1.8334 - val_accuracy: 0.3211 - val_f1: 0.2523\n",
      "Epoch 15/200\n",
      "176/176 [==============================] - 88s 499ms/step - loss: 1.2252 - accuracy: 0.6623 - f1: 0.6420 - val_loss: 1.8870 - val_accuracy: 0.3309 - val_f1: 0.2975\n",
      "Epoch 16/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 1.1904 - accuracy: 0.6687 - f1: 0.6508 - val_loss: 3.4329 - val_accuracy: 0.1518 - val_f1: 0.1504\n",
      "Epoch 17/200\n",
      "176/176 [==============================] - 89s 506ms/step - loss: 1.2217 - accuracy: 0.6561 - f1: 0.6337 - val_loss: 2.9661 - val_accuracy: 0.2078 - val_f1: 0.2057\n",
      "Epoch 18/200\n",
      "176/176 [==============================] - 89s 505ms/step - loss: 1.1647 - accuracy: 0.6682 - f1: 0.6528 - val_loss: 1.6941 - val_accuracy: 0.4667 - val_f1: 0.4151\n",
      "Epoch 19/200\n",
      "176/176 [==============================] - 89s 506ms/step - loss: 1.1486 - accuracy: 0.6737 - f1: 0.6567 - val_loss: 1.5686 - val_accuracy: 0.5219 - val_f1: 0.4942\n",
      "Epoch 20/200\n",
      "176/176 [==============================] - 89s 506ms/step - loss: 1.1369 - accuracy: 0.6738 - f1: 0.6557 - val_loss: 2.4166 - val_accuracy: 0.3223 - val_f1: 0.2873\n",
      "Epoch 21/200\n",
      "176/176 [==============================] - 89s 506ms/step - loss: 1.1495 - accuracy: 0.6715 - f1: 0.6528 - val_loss: 3.7522 - val_accuracy: 0.1390 - val_f1: 0.1374\n",
      "Epoch 22/200\n",
      "176/176 [==============================] - 89s 507ms/step - loss: 1.1088 - accuracy: 0.6780 - f1: 0.6638 - val_loss: 3.3036 - val_accuracy: 0.2002 - val_f1: 0.1977\n",
      "Epoch 23/200\n",
      "176/176 [==============================] - 89s 505ms/step - loss: 1.1065 - accuracy: 0.6783 - f1: 0.6623 - val_loss: 2.4189 - val_accuracy: 0.2606 - val_f1: 0.2437\n",
      "Epoch 24/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 1.0931 - accuracy: 0.6829 - f1: 0.6671 - val_loss: 1.5638 - val_accuracy: 0.5488 - val_f1: 0.5435\n",
      "Epoch 25/200\n",
      "176/176 [==============================] - 89s 505ms/step - loss: 1.0852 - accuracy: 0.6847 - f1: 0.6693 - val_loss: 2.5092 - val_accuracy: 0.3259 - val_f1: 0.3189\n",
      "Epoch 26/200\n",
      "176/176 [==============================] - 89s 506ms/step - loss: 1.0638 - accuracy: 0.6888 - f1: 0.6744 - val_loss: 1.8769 - val_accuracy: 0.5783 - val_f1: 0.5785\n",
      "Epoch 27/200\n",
      "176/176 [==============================] - 89s 505ms/step - loss: 1.0580 - accuracy: 0.6918 - f1: 0.6782 - val_loss: 3.3558 - val_accuracy: 0.1550 - val_f1: 0.1484\n",
      "Epoch 28/200\n",
      "176/176 [==============================] - 88s 503ms/step - loss: 1.0394 - accuracy: 0.6939 - f1: 0.6808 - val_loss: 2.4407 - val_accuracy: 0.3056 - val_f1: 0.2839\n",
      "Epoch 29/200\n",
      "176/176 [==============================] - 89s 506ms/step - loss: 1.0432 - accuracy: 0.6928 - f1: 0.6792 - val_loss: 3.1924 - val_accuracy: 0.1582 - val_f1: 0.1545\n",
      "Epoch 30/200\n",
      "176/176 [==============================] - 92s 522ms/step - loss: 1.0191 - accuracy: 0.7006 - f1: 0.6882 - val_loss: 2.0981 - val_accuracy: 0.3707 - val_f1: 0.3601\n",
      "Epoch 31/200\n",
      "176/176 [==============================] - 91s 517ms/step - loss: 1.0162 - accuracy: 0.7000 - f1: 0.6880 - val_loss: 2.6645 - val_accuracy: 0.2606 - val_f1: 0.2505\n",
      "Epoch 32/200\n",
      "176/176 [==============================] - 91s 516ms/step - loss: 1.0151 - accuracy: 0.6995 - f1: 0.6846 - val_loss: 1.6463 - val_accuracy: 0.4556 - val_f1: 0.3901\n",
      "Epoch 33/200\n",
      "176/176 [==============================] - 90s 513ms/step - loss: 0.9886 - accuracy: 0.7058 - f1: 0.6922 - val_loss: 1.4508 - val_accuracy: 0.5865 - val_f1: 0.5806\n",
      "Epoch 34/200\n",
      "176/176 [==============================] - 89s 505ms/step - loss: 1.0079 - accuracy: 0.6977 - f1: 0.6859 - val_loss: 2.2432 - val_accuracy: 0.3295 - val_f1: 0.2963\n",
      "Epoch 35/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.9817 - accuracy: 0.7076 - f1: 0.6952 - val_loss: 1.7844 - val_accuracy: 0.4629 - val_f1: 0.4623\n",
      "Epoch 36/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.9741 - accuracy: 0.7076 - f1: 0.6966 - val_loss: 1.8754 - val_accuracy: 0.5373 - val_f1: 0.5378\n",
      "Epoch 37/200\n",
      "176/176 [==============================] - 89s 503ms/step - loss: 0.9690 - accuracy: 0.7102 - f1: 0.6987 - val_loss: 2.5740 - val_accuracy: 0.3930 - val_f1: 0.3913\n",
      "Epoch 38/200\n",
      "176/176 [==============================] - 88s 502ms/step - loss: 0.9743 - accuracy: 0.7103 - f1: 0.6985 - val_loss: 1.5307 - val_accuracy: 0.4835 - val_f1: 0.4451\n",
      "Epoch 39/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.9447 - accuracy: 0.7177 - f1: 0.7072 - val_loss: 1.6251 - val_accuracy: 0.4890 - val_f1: 0.4668\n",
      "Epoch 40/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.9538 - accuracy: 0.7121 - f1: 0.7025 - val_loss: 2.2908 - val_accuracy: 0.2944 - val_f1: 0.2813\n",
      "Epoch 41/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.9447 - accuracy: 0.7154 - f1: 0.7047 - val_loss: 1.7416 - val_accuracy: 0.5329 - val_f1: 0.5258\n",
      "Epoch 42/200\n",
      "176/176 [==============================] - 89s 503ms/step - loss: 0.9387 - accuracy: 0.7181 - f1: 0.7093 - val_loss: 3.0342 - val_accuracy: 0.2892 - val_f1: 0.2797\n",
      "Epoch 43/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.9225 - accuracy: 0.7223 - f1: 0.7132 - val_loss: 1.8987 - val_accuracy: 0.4277 - val_f1: 0.4135\n",
      "Epoch 44/200\n",
      "176/176 [==============================] - 88s 503ms/step - loss: 0.9434 - accuracy: 0.7160 - f1: 0.7052 - val_loss: 1.8876 - val_accuracy: 0.4849 - val_f1: 0.4795\n",
      "Epoch 45/200\n",
      "176/176 [==============================] - 89s 503ms/step - loss: 0.9225 - accuracy: 0.7246 - f1: 0.7151 - val_loss: 2.4953 - val_accuracy: 0.2331 - val_f1: 0.2242\n",
      "Epoch 46/200\n",
      "176/176 [==============================] - 89s 503ms/step - loss: 0.9137 - accuracy: 0.7254 - f1: 0.7155 - val_loss: 1.3963 - val_accuracy: 0.5145 - val_f1: 0.4755\n",
      "Epoch 47/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.9044 - accuracy: 0.7278 - f1: 0.7183 - val_loss: 2.8527 - val_accuracy: 0.2936 - val_f1: 0.2864\n",
      "Epoch 48/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.9143 - accuracy: 0.7234 - f1: 0.7129 - val_loss: 1.3880 - val_accuracy: 0.5572 - val_f1: 0.5551\n",
      "Epoch 49/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.9149 - accuracy: 0.7221 - f1: 0.7113 - val_loss: 1.8901 - val_accuracy: 0.4958 - val_f1: 0.4961\n",
      "Epoch 50/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.8984 - accuracy: 0.7294 - f1: 0.7212 - val_loss: 2.6842 - val_accuracy: 0.3376 - val_f1: 0.3318\n",
      "Epoch 51/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.9027 - accuracy: 0.7300 - f1: 0.7194 - val_loss: 2.0616 - val_accuracy: 0.3369 - val_f1: 0.3134\n",
      "Epoch 52/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.8893 - accuracy: 0.7322 - f1: 0.7232 - val_loss: 3.7395 - val_accuracy: 0.2042 - val_f1: 0.1956\n",
      "Epoch 53/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.8835 - accuracy: 0.7290 - f1: 0.7198 - val_loss: 1.5944 - val_accuracy: 0.5305 - val_f1: 0.5284\n",
      "Epoch 54/200\n",
      "176/176 [==============================] - 1910s 11s/step - loss: 0.8865 - accuracy: 0.7341 - f1: 0.7230 - val_loss: 2.7421 - val_accuracy: 0.3084 - val_f1: 0.3086\n",
      "Epoch 55/200\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 0.8828 - accuracy: 0.7336 - f1: 0.7231 - val_loss: 2.1767 - val_accuracy: 0.3323 - val_f1: 0.3089\n",
      "Epoch 56/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.8820 - accuracy: 0.7331 - f1: 0.7234 - val_loss: 1.9617 - val_accuracy: 0.3510 - val_f1: 0.3332\n",
      "Epoch 57/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.8704 - accuracy: 0.7370 - f1: 0.7287 - val_loss: 1.4493 - val_accuracy: 0.6169 - val_f1: 0.6162\n",
      "Epoch 58/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.8742 - accuracy: 0.7372 - f1: 0.7280 - val_loss: 3.0450 - val_accuracy: 0.2936 - val_f1: 0.2896\n",
      "Epoch 59/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.8651 - accuracy: 0.7410 - f1: 0.7307 - val_loss: 2.9039 - val_accuracy: 0.2791 - val_f1: 0.2788\n",
      "Epoch 60/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.8689 - accuracy: 0.7395 - f1: 0.7317 - val_loss: 4.1268 - val_accuracy: 0.2241 - val_f1: 0.2247\n",
      "Epoch 61/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.8449 - accuracy: 0.7460 - f1: 0.7387 - val_loss: 2.2841 - val_accuracy: 0.3183 - val_f1: 0.3037\n",
      "Epoch 62/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.8619 - accuracy: 0.7372 - f1: 0.7296 - val_loss: 2.2402 - val_accuracy: 0.3201 - val_f1: 0.3038\n",
      "Epoch 63/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.8567 - accuracy: 0.7435 - f1: 0.7336 - val_loss: 4.2279 - val_accuracy: 0.1775 - val_f1: 0.1730\n",
      "Epoch 64/200\n",
      "176/176 [==============================] - 88s 501ms/step - loss: 0.8493 - accuracy: 0.7436 - f1: 0.7345 - val_loss: 2.4650 - val_accuracy: 0.3066 - val_f1: 0.2877\n",
      "Epoch 65/200\n",
      "176/176 [==============================] - 88s 501ms/step - loss: 0.8531 - accuracy: 0.7432 - f1: 0.7347 - val_loss: 1.9675 - val_accuracy: 0.4470 - val_f1: 0.4382\n",
      "Epoch 66/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.8576 - accuracy: 0.7433 - f1: 0.7352 - val_loss: 1.9376 - val_accuracy: 0.4637 - val_f1: 0.4464\n",
      "Epoch 67/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.8392 - accuracy: 0.7482 - f1: 0.7416 - val_loss: 3.6644 - val_accuracy: 0.1986 - val_f1: 0.1922\n",
      "Epoch 68/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.8370 - accuracy: 0.7495 - f1: 0.7406 - val_loss: 4.6482 - val_accuracy: 0.1528 - val_f1: 0.1494\n",
      "Epoch 69/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.8601 - accuracy: 0.7415 - f1: 0.7335 - val_loss: 1.5666 - val_accuracy: 0.5305 - val_f1: 0.5219\n",
      "Epoch 70/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.8505 - accuracy: 0.7425 - f1: 0.7339 - val_loss: 1.6158 - val_accuracy: 0.4301 - val_f1: 0.4024\n",
      "Epoch 71/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.8418 - accuracy: 0.7448 - f1: 0.7372 - val_loss: 1.2590 - val_accuracy: 0.5813 - val_f1: 0.5694\n",
      "Epoch 72/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.8400 - accuracy: 0.7444 - f1: 0.7375 - val_loss: 2.2750 - val_accuracy: 0.4894 - val_f1: 0.4894\n",
      "Epoch 73/200\n",
      "176/176 [==============================] - 90s 512ms/step - loss: 0.8370 - accuracy: 0.7502 - f1: 0.7413 - val_loss: 3.1044 - val_accuracy: 0.2426 - val_f1: 0.2335\n",
      "Epoch 74/200\n",
      "176/176 [==============================] - 90s 513ms/step - loss: 0.8239 - accuracy: 0.7539 - f1: 0.7472 - val_loss: 2.4312 - val_accuracy: 0.3201 - val_f1: 0.2856\n",
      "Epoch 75/200\n",
      "176/176 [==============================] - 90s 513ms/step - loss: 0.8392 - accuracy: 0.7468 - f1: 0.7396 - val_loss: 3.2634 - val_accuracy: 0.2450 - val_f1: 0.2434\n",
      "Epoch 76/200\n",
      "176/176 [==============================] - 91s 515ms/step - loss: 0.8411 - accuracy: 0.7463 - f1: 0.7373 - val_loss: 1.9898 - val_accuracy: 0.4004 - val_f1: 0.3758\n",
      "Epoch 77/200\n",
      "176/176 [==============================] - 92s 522ms/step - loss: 0.8286 - accuracy: 0.7520 - f1: 0.7442 - val_loss: 1.4667 - val_accuracy: 0.5044 - val_f1: 0.4602\n",
      "Epoch 78/200\n",
      "176/176 [==============================] - 92s 522ms/step - loss: 0.8306 - accuracy: 0.7517 - f1: 0.7437 - val_loss: 2.7688 - val_accuracy: 0.2743 - val_f1: 0.2634\n",
      "Epoch 79/200\n",
      "176/176 [==============================] - 92s 524ms/step - loss: 0.8185 - accuracy: 0.7558 - f1: 0.7487 - val_loss: 3.2843 - val_accuracy: 0.2787 - val_f1: 0.2739\n",
      "Epoch 80/200\n",
      "176/176 [==============================] - 92s 523ms/step - loss: 0.8294 - accuracy: 0.7519 - f1: 0.7441 - val_loss: 3.4725 - val_accuracy: 0.2526 - val_f1: 0.2448\n",
      "Epoch 81/200\n",
      "176/176 [==============================] - 92s 523ms/step - loss: 0.8239 - accuracy: 0.7540 - f1: 0.7479 - val_loss: 2.6419 - val_accuracy: 0.2829 - val_f1: 0.2787\n",
      "Epoch 82/200\n",
      "176/176 [==============================] - 92s 524ms/step - loss: 0.8161 - accuracy: 0.7553 - f1: 0.7489 - val_loss: 2.7077 - val_accuracy: 0.2936 - val_f1: 0.2781\n",
      "Epoch 83/200\n",
      "176/176 [==============================] - 92s 523ms/step - loss: 0.8114 - accuracy: 0.7564 - f1: 0.7512 - val_loss: 3.0819 - val_accuracy: 0.2508 - val_f1: 0.2456\n",
      "Epoch 84/200\n",
      "176/176 [==============================] - 92s 523ms/step - loss: 0.8091 - accuracy: 0.7581 - f1: 0.7509 - val_loss: 3.7711 - val_accuracy: 0.2450 - val_f1: 0.2423\n",
      "Epoch 85/200\n",
      "176/176 [==============================] - 92s 522ms/step - loss: 0.8133 - accuracy: 0.7594 - f1: 0.7504 - val_loss: 2.3984 - val_accuracy: 0.3143 - val_f1: 0.3049\n",
      "Epoch 86/200\n",
      "176/176 [==============================] - 89s 506ms/step - loss: 0.8168 - accuracy: 0.7529 - f1: 0.7464 - val_loss: 1.5640 - val_accuracy: 0.5169 - val_f1: 0.5064\n",
      "Epoch 87/200\n",
      "176/176 [==============================] - 88s 501ms/step - loss: 0.8094 - accuracy: 0.7584 - f1: 0.7523 - val_loss: 2.8737 - val_accuracy: 0.2896 - val_f1: 0.2852\n",
      "Epoch 88/200\n",
      "176/176 [==============================] - 89s 505ms/step - loss: 0.8156 - accuracy: 0.7544 - f1: 0.7481 - val_loss: 1.8102 - val_accuracy: 0.5084 - val_f1: 0.5066\n",
      "Epoch 89/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.8175 - accuracy: 0.7553 - f1: 0.7500 - val_loss: 1.9305 - val_accuracy: 0.4275 - val_f1: 0.4175\n",
      "Epoch 90/200\n",
      "176/176 [==============================] - 89s 505ms/step - loss: 0.8161 - accuracy: 0.7550 - f1: 0.7470 - val_loss: 2.6163 - val_accuracy: 0.3237 - val_f1: 0.3157\n",
      "Epoch 91/200\n",
      "176/176 [==============================] - 88s 501ms/step - loss: 0.8294 - accuracy: 0.7518 - f1: 0.7448 - val_loss: 1.6691 - val_accuracy: 0.4116 - val_f1: 0.3897\n",
      "Epoch 92/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.8086 - accuracy: 0.7569 - f1: 0.7504 - val_loss: 2.1590 - val_accuracy: 0.3333 - val_f1: 0.3199\n",
      "Epoch 93/200\n",
      "176/176 [==============================] - 88s 502ms/step - loss: 0.8323 - accuracy: 0.7511 - f1: 0.7426 - val_loss: 4.7402 - val_accuracy: 0.2215 - val_f1: 0.2157\n",
      "Epoch 94/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.7943 - accuracy: 0.7636 - f1: 0.7566 - val_loss: 1.8381 - val_accuracy: 0.5323 - val_f1: 0.5320\n",
      "Epoch 95/200\n",
      "176/176 [==============================] - 89s 503ms/step - loss: 0.8138 - accuracy: 0.7568 - f1: 0.7491 - val_loss: 4.6656 - val_accuracy: 0.2245 - val_f1: 0.2250\n",
      "Epoch 96/200\n",
      "176/176 [==============================] - 88s 502ms/step - loss: 0.8114 - accuracy: 0.7588 - f1: 0.7528 - val_loss: 2.1459 - val_accuracy: 0.3578 - val_f1: 0.3426\n",
      "Epoch 97/200\n",
      "176/176 [==============================] - 88s 501ms/step - loss: 0.8068 - accuracy: 0.7598 - f1: 0.7533 - val_loss: 1.7118 - val_accuracy: 0.5151 - val_f1: 0.5103\n",
      "Epoch 98/200\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 0.8028 - accuracy: 0.7601 - f1: 0.7545 - val_loss: 3.0201 - val_accuracy: 0.2504 - val_f1: 0.2422\n",
      "Epoch 99/200\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.8029 - accuracy: 0.7621 - f1: 0.7556 - val_loss: 2.2285 - val_accuracy: 0.3582 - val_f1: 0.3429\n",
      "Epoch 100/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.8135 - accuracy: 0.7582 - f1: 0.7526 - val_loss: 2.1440 - val_accuracy: 0.4369 - val_f1: 0.4270\n",
      "Epoch 101/200\n",
      "176/176 [==============================] - 88s 501ms/step - loss: 0.7841 - accuracy: 0.7669 - f1: 0.7613 - val_loss: 2.0412 - val_accuracy: 0.3498 - val_f1: 0.3116\n",
      "Epoch 102/200\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 0.7993 - accuracy: 0.7605 - f1: 0.7552 - val_loss: 3.2657 - val_accuracy: 0.2659 - val_f1: 0.2597\n",
      "Epoch 103/200\n",
      "176/176 [==============================] - 87s 492ms/step - loss: 0.7984 - accuracy: 0.7643 - f1: 0.7578 - val_loss: 2.3542 - val_accuracy: 0.3416 - val_f1: 0.3325\n",
      "Epoch 104/200\n",
      "176/176 [==============================] - 87s 496ms/step - loss: 0.7862 - accuracy: 0.7678 - f1: 0.7622 - val_loss: 1.7689 - val_accuracy: 0.4118 - val_f1: 0.3698\n",
      "Epoch 105/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.7972 - accuracy: 0.7634 - f1: 0.7571 - val_loss: 2.3945 - val_accuracy: 0.3335 - val_f1: 0.3122\n",
      "Epoch 106/200\n",
      "176/176 [==============================] - 88s 499ms/step - loss: 0.7970 - accuracy: 0.7623 - f1: 0.7563 - val_loss: 3.3282 - val_accuracy: 0.2663 - val_f1: 0.2606\n",
      "Epoch 107/200\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 0.8151 - accuracy: 0.7575 - f1: 0.7491 - val_loss: 1.7617 - val_accuracy: 0.4046 - val_f1: 0.3720\n",
      "Epoch 108/200\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 0.8035 - accuracy: 0.7585 - f1: 0.7529 - val_loss: 2.4400 - val_accuracy: 0.3763 - val_f1: 0.3697\n",
      "Epoch 109/200\n",
      "176/176 [==============================] - 88s 501ms/step - loss: 0.7951 - accuracy: 0.7616 - f1: 0.7569 - val_loss: 1.4626 - val_accuracy: 0.5956 - val_f1: 0.5952\n",
      "Epoch 110/200\n",
      "176/176 [==============================] - 88s 502ms/step - loss: 0.7888 - accuracy: 0.7690 - f1: 0.7632 - val_loss: 2.9587 - val_accuracy: 0.2627 - val_f1: 0.2580\n",
      "Epoch 111/200\n",
      "176/176 [==============================] - 88s 501ms/step - loss: 0.7889 - accuracy: 0.7676 - f1: 0.7614 - val_loss: 2.6752 - val_accuracy: 0.2691 - val_f1: 0.2616\n",
      "Epoch 112/200\n",
      "176/176 [==============================] - 88s 501ms/step - loss: 0.7984 - accuracy: 0.7636 - f1: 0.7565 - val_loss: 3.3908 - val_accuracy: 0.3448 - val_f1: 0.3438\n",
      "Epoch 113/200\n",
      "176/176 [==============================] - 88s 502ms/step - loss: 0.7863 - accuracy: 0.7666 - f1: 0.7615 - val_loss: 1.6196 - val_accuracy: 0.4496 - val_f1: 0.4016\n",
      "Epoch 114/200\n",
      "176/176 [==============================] - 88s 502ms/step - loss: 0.7761 - accuracy: 0.7706 - f1: 0.7658 - val_loss: 2.1695 - val_accuracy: 0.4466 - val_f1: 0.4433\n",
      "Epoch 115/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.7886 - accuracy: 0.7636 - f1: 0.7578 - val_loss: 1.7578 - val_accuracy: 0.3932 - val_f1: 0.3554\n",
      "Epoch 116/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.7923 - accuracy: 0.7658 - f1: 0.7594 - val_loss: 2.0260 - val_accuracy: 0.5006 - val_f1: 0.4991\n",
      "Epoch 117/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.7804 - accuracy: 0.7687 - f1: 0.7626 - val_loss: 2.1241 - val_accuracy: 0.3365 - val_f1: 0.3204\n",
      "Epoch 118/200\n",
      "176/176 [==============================] - 88s 501ms/step - loss: 0.7794 - accuracy: 0.7704 - f1: 0.7632 - val_loss: 2.4864 - val_accuracy: 0.2992 - val_f1: 0.2851\n",
      "Epoch 119/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.7950 - accuracy: 0.7628 - f1: 0.7559 - val_loss: 2.1263 - val_accuracy: 0.3906 - val_f1: 0.3643\n",
      "Epoch 120/200\n",
      "176/176 [==============================] - 89s 505ms/step - loss: 0.7818 - accuracy: 0.7693 - f1: 0.7643 - val_loss: 3.8046 - val_accuracy: 0.2448 - val_f1: 0.2389\n",
      "Epoch 121/200\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.7764 - accuracy: 0.7729 - f1: 0.7679 - val_loss: 3.9380 - val_accuracy: 0.2353 - val_f1: 0.2354\n",
      "Epoch 122/200\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.7852 - accuracy: 0.7654 - f1: 0.7596 - val_loss: 2.3406 - val_accuracy: 0.3233 - val_f1: 0.2960\n",
      "Epoch 123/200\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 0.7897 - accuracy: 0.7638 - f1: 0.7579 - val_loss: 2.5457 - val_accuracy: 0.3281 - val_f1: 0.3230\n",
      "Epoch 124/200\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 0.7823 - accuracy: 0.7690 - f1: 0.7624 - val_loss: 4.0708 - val_accuracy: 0.2384 - val_f1: 0.2331\n",
      "Epoch 125/200\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.7889 - accuracy: 0.7639 - f1: 0.7574 - val_loss: 1.2167 - val_accuracy: 0.5926 - val_f1: 0.5756\n",
      "Epoch 126/200\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.7884 - accuracy: 0.7633 - f1: 0.7580 - val_loss: 1.1780 - val_accuracy: 0.6315 - val_f1: 0.6208\n",
      "Epoch 127/200\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.7848 - accuracy: 0.7675 - f1: 0.7619 - val_loss: 1.6145 - val_accuracy: 0.4978 - val_f1: 0.4907\n",
      "Epoch 128/200\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.7966 - accuracy: 0.7623 - f1: 0.7557 - val_loss: 2.3534 - val_accuracy: 0.3225 - val_f1: 0.3075\n",
      "Epoch 129/200\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.7791 - accuracy: 0.7682 - f1: 0.7636 - val_loss: 1.3866 - val_accuracy: 0.5492 - val_f1: 0.5275\n",
      "Epoch 130/200\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.7715 - accuracy: 0.7729 - f1: 0.7655 - val_loss: 2.2821 - val_accuracy: 0.3584 - val_f1: 0.3367\n",
      "Epoch 131/200\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 0.7766 - accuracy: 0.7706 - f1: 0.7644 - val_loss: 1.8456 - val_accuracy: 0.3944 - val_f1: 0.3735\n",
      "Epoch 132/200\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 0.7922 - accuracy: 0.7640 - f1: 0.7590 - val_loss: 1.5240 - val_accuracy: 0.5006 - val_f1: 0.4728\n",
      "Epoch 133/200\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 0.7746 - accuracy: 0.7705 - f1: 0.7657 - val_loss: 1.8166 - val_accuracy: 0.3990 - val_f1: 0.3851\n",
      "Epoch 134/200\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 0.7671 - accuracy: 0.7727 - f1: 0.7673 - val_loss: 4.8942 - val_accuracy: 0.1779 - val_f1: 0.1722\n",
      "Epoch 135/200\n",
      "176/176 [==============================] - 88s 501ms/step - loss: 0.7819 - accuracy: 0.7690 - f1: 0.7631 - val_loss: 4.0641 - val_accuracy: 0.2359 - val_f1: 0.2346\n",
      "Epoch 136/200\n",
      "176/176 [==============================] - 88s 501ms/step - loss: 0.7748 - accuracy: 0.7716 - f1: 0.7660 - val_loss: 2.6516 - val_accuracy: 0.3201 - val_f1: 0.3109\n",
      "Epoch 137/200\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 0.7723 - accuracy: 0.7727 - f1: 0.7678 - val_loss: 1.4226 - val_accuracy: 0.5341 - val_f1: 0.5063\n",
      "Epoch 138/200\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 0.7713 - accuracy: 0.7716 - f1: 0.7652 - val_loss: 2.1475 - val_accuracy: 0.3683 - val_f1: 0.3524\n",
      "Epoch 139/200\n",
      "176/176 [==============================] - 87s 496ms/step - loss: 0.7763 - accuracy: 0.7706 - f1: 0.7647 - val_loss: 1.8534 - val_accuracy: 0.5327 - val_f1: 0.5314\n",
      "Epoch 140/200\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 0.7704 - accuracy: 0.7735 - f1: 0.7675 - val_loss: 1.7639 - val_accuracy: 0.5201 - val_f1: 0.5200\n",
      "Epoch 141/200\n",
      "176/176 [==============================] - 87s 496ms/step - loss: 0.7807 - accuracy: 0.7671 - f1: 0.7614 - val_loss: 2.3200 - val_accuracy: 0.4120 - val_f1: 0.4042\n",
      "Epoch 142/200\n",
      "176/176 [==============================] - 87s 496ms/step - loss: 0.7721 - accuracy: 0.7710 - f1: 0.7656 - val_loss: 1.9858 - val_accuracy: 0.4904 - val_f1: 0.4866\n",
      "Epoch 143/200\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 0.7831 - accuracy: 0.7692 - f1: 0.7632 - val_loss: 1.8275 - val_accuracy: 0.4918 - val_f1: 0.4848\n",
      "Epoch 144/200\n",
      "176/176 [==============================] - 89s 506ms/step - loss: 0.7635 - accuracy: 0.7757 - f1: 0.7706 - val_loss: 1.5095 - val_accuracy: 0.5301 - val_f1: 0.5184\n",
      "Epoch 145/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.7803 - accuracy: 0.7692 - f1: 0.7631 - val_loss: 1.7527 - val_accuracy: 0.5524 - val_f1: 0.5494\n",
      "Epoch 146/200\n",
      "176/176 [==============================] - 89s 504ms/step - loss: 0.7714 - accuracy: 0.7723 - f1: 0.7664 - val_loss: 2.3445 - val_accuracy: 0.5072 - val_f1: 0.5070\n",
      "Epoch 147/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.7746 - accuracy: 0.7702 - f1: 0.7637 - val_loss: 1.8214 - val_accuracy: 0.4667 - val_f1: 0.4491\n",
      "Epoch 148/200\n",
      "176/176 [==============================] - 88s 499ms/step - loss: 0.7789 - accuracy: 0.7704 - f1: 0.7637 - val_loss: 3.1812 - val_accuracy: 0.2217 - val_f1: 0.2068\n",
      "Epoch 149/200\n",
      "176/176 [==============================] - 88s 499ms/step - loss: 0.7801 - accuracy: 0.7692 - f1: 0.7630 - val_loss: 2.1220 - val_accuracy: 0.3773 - val_f1: 0.3591\n",
      "Epoch 150/200\n",
      "176/176 [==============================] - 88s 499ms/step - loss: 0.7725 - accuracy: 0.7731 - f1: 0.7670 - val_loss: 3.2151 - val_accuracy: 0.2454 - val_f1: 0.2437\n",
      "Epoch 151/200\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 0.7700 - accuracy: 0.7713 - f1: 0.7671 - val_loss: 2.8809 - val_accuracy: 0.3303 - val_f1: 0.3190\n",
      "Epoch 152/200\n",
      "176/176 [==============================] - 88s 499ms/step - loss: 0.7646 - accuracy: 0.7735 - f1: 0.7684 - val_loss: 1.4416 - val_accuracy: 0.5869 - val_f1: 0.5856\n",
      "Epoch 153/200\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 0.7620 - accuracy: 0.7759 - f1: 0.7698 - val_loss: 1.8201 - val_accuracy: 0.4388 - val_f1: 0.4178\n",
      "Epoch 154/200\n",
      "176/176 [==============================] - 88s 499ms/step - loss: 0.7648 - accuracy: 0.7748 - f1: 0.7697 - val_loss: 2.8838 - val_accuracy: 0.2934 - val_f1: 0.2888\n",
      "Epoch 155/200\n",
      "176/176 [==============================] - 88s 499ms/step - loss: 0.7660 - accuracy: 0.7732 - f1: 0.7683 - val_loss: 1.7563 - val_accuracy: 0.5110 - val_f1: 0.5029\n",
      "Epoch 156/200\n",
      "176/176 [==============================] - 88s 499ms/step - loss: 0.7692 - accuracy: 0.7719 - f1: 0.7659 - val_loss: 4.1271 - val_accuracy: 0.2293 - val_f1: 0.2278\n",
      "Epoch 157/200\n",
      "176/176 [==============================] - 88s 501ms/step - loss: 0.7571 - accuracy: 0.7780 - f1: 0.7729 - val_loss: 1.9927 - val_accuracy: 0.4532 - val_f1: 0.4406\n",
      "Epoch 158/200\n",
      "176/176 [==============================] - 89s 508ms/step - loss: 0.7636 - accuracy: 0.7743 - f1: 0.7690 - val_loss: 1.1652 - val_accuracy: 0.5930 - val_f1: 0.5544\n",
      "Epoch 159/200\n",
      "176/176 [==============================] - 91s 519ms/step - loss: 0.7799 - accuracy: 0.7691 - f1: 0.7635 - val_loss: 1.2270 - val_accuracy: 0.6012 - val_f1: 0.5980\n",
      "Epoch 160/200\n",
      "176/176 [==============================] - 91s 520ms/step - loss: 0.7622 - accuracy: 0.7745 - f1: 0.7698 - val_loss: 4.0085 - val_accuracy: 0.2396 - val_f1: 0.2391\n",
      "Epoch 161/200\n",
      "176/176 [==============================] - 91s 519ms/step - loss: 0.7564 - accuracy: 0.7755 - f1: 0.7704 - val_loss: 1.3213 - val_accuracy: 0.5426 - val_f1: 0.5168\n",
      "Epoch 162/200\n",
      "176/176 [==============================] - 92s 521ms/step - loss: 0.7683 - accuracy: 0.7711 - f1: 0.7653 - val_loss: 2.3624 - val_accuracy: 0.3994 - val_f1: 0.3924\n",
      "Epoch 163/200\n",
      "176/176 [==============================] - 91s 520ms/step - loss: 0.7661 - accuracy: 0.7754 - f1: 0.7705 - val_loss: 3.0189 - val_accuracy: 0.2908 - val_f1: 0.2872\n",
      "Epoch 164/200\n",
      "176/176 [==============================] - 92s 521ms/step - loss: 0.7596 - accuracy: 0.7780 - f1: 0.7736 - val_loss: 1.4749 - val_accuracy: 0.5912 - val_f1: 0.5901\n",
      "Epoch 165/200\n",
      "176/176 [==============================] - 92s 522ms/step - loss: 0.7567 - accuracy: 0.7765 - f1: 0.7704 - val_loss: 2.0484 - val_accuracy: 0.4098 - val_f1: 0.3964\n",
      "Epoch 166/200\n",
      "176/176 [==============================] - 92s 522ms/step - loss: 0.7892 - accuracy: 0.7676 - f1: 0.7617 - val_loss: 1.3566 - val_accuracy: 0.5655 - val_f1: 0.5501\n",
      "Epoch 167/200\n",
      "176/176 [==============================] - 92s 522ms/step - loss: 0.7532 - accuracy: 0.7791 - f1: 0.7730 - val_loss: 2.0458 - val_accuracy: 0.3616 - val_f1: 0.3292\n",
      "Epoch 168/200\n",
      "176/176 [==============================] - 92s 521ms/step - loss: 0.7682 - accuracy: 0.7725 - f1: 0.7669 - val_loss: 1.8480 - val_accuracy: 0.4719 - val_f1: 0.4582\n",
      "Epoch 169/200\n",
      "176/176 [==============================] - 92s 523ms/step - loss: 0.7676 - accuracy: 0.7745 - f1: 0.7697 - val_loss: 2.1523 - val_accuracy: 0.3510 - val_f1: 0.3330\n",
      "Epoch 170/200\n",
      "176/176 [==============================] - 92s 523ms/step - loss: 0.7576 - accuracy: 0.7780 - f1: 0.7717 - val_loss: 2.4675 - val_accuracy: 0.4068 - val_f1: 0.3933\n",
      "Epoch 171/200\n",
      "176/176 [==============================] - 92s 523ms/step - loss: 0.7544 - accuracy: 0.7775 - f1: 0.7734 - val_loss: 1.5259 - val_accuracy: 0.4675 - val_f1: 0.4262\n",
      "Epoch 172/200\n",
      "176/176 [==============================] - 92s 522ms/step - loss: 0.7537 - accuracy: 0.7787 - f1: 0.7741 - val_loss: 1.3836 - val_accuracy: 0.6068 - val_f1: 0.6053\n",
      "Epoch 173/200\n",
      "176/176 [==============================] - 91s 518ms/step - loss: 0.7540 - accuracy: 0.7787 - f1: 0.7745 - val_loss: 1.8234 - val_accuracy: 0.4516 - val_f1: 0.4284\n",
      "Epoch 174/200\n",
      "176/176 [==============================] - 90s 514ms/step - loss: 0.7491 - accuracy: 0.7816 - f1: 0.7765 - val_loss: 2.5102 - val_accuracy: 0.3705 - val_f1: 0.3629\n",
      "Epoch 175/200\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 0.7539 - accuracy: 0.7772 - f1: 0.7726 - val_loss: 3.0709 - val_accuracy: 0.3691 - val_f1: 0.3662\n",
      "Epoch 176/200\n",
      "176/176 [==============================] - 88s 497ms/step - loss: 0.7723 - accuracy: 0.7696 - f1: 0.7628 - val_loss: 4.0696 - val_accuracy: 0.2301 - val_f1: 0.2305\n",
      "Epoch 177/200\n",
      "176/176 [==============================] - 88s 497ms/step - loss: 0.7583 - accuracy: 0.7765 - f1: 0.7716 - val_loss: 2.7508 - val_accuracy: 0.4137 - val_f1: 0.4165\n",
      "Epoch 178/200\n",
      "176/176 [==============================] - 88s 497ms/step - loss: 0.7452 - accuracy: 0.7814 - f1: 0.7775 - val_loss: 2.8684 - val_accuracy: 0.2361 - val_f1: 0.2224\n",
      "Epoch 179/200\n",
      "176/176 [==============================] - 88s 497ms/step - loss: 0.7590 - accuracy: 0.7742 - f1: 0.7696 - val_loss: 2.9808 - val_accuracy: 0.2717 - val_f1: 0.2704\n",
      "Epoch 180/200\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 0.7540 - accuracy: 0.7762 - f1: 0.7713 - val_loss: 2.2999 - val_accuracy: 0.3124 - val_f1: 0.2969\n",
      "Epoch 181/200\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 0.7635 - accuracy: 0.7738 - f1: 0.7676 - val_loss: 2.8660 - val_accuracy: 0.3390 - val_f1: 0.3356\n",
      "Epoch 182/200\n",
      "176/176 [==============================] - 88s 497ms/step - loss: 0.7557 - accuracy: 0.7778 - f1: 0.7740 - val_loss: 2.0695 - val_accuracy: 0.4777 - val_f1: 0.4732\n",
      "Epoch 183/200\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 0.7605 - accuracy: 0.7762 - f1: 0.7683 - val_loss: 2.9987 - val_accuracy: 0.2488 - val_f1: 0.2426\n",
      "Epoch 184/200\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 0.7648 - accuracy: 0.7739 - f1: 0.7694 - val_loss: 1.5412 - val_accuracy: 0.5167 - val_f1: 0.5048\n",
      "Epoch 185/200\n",
      "176/176 [==============================] - 88s 497ms/step - loss: 0.7705 - accuracy: 0.7720 - f1: 0.7672 - val_loss: 1.3379 - val_accuracy: 0.6092 - val_f1: 0.6078\n",
      "Epoch 186/200\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 0.7483 - accuracy: 0.7806 - f1: 0.7755 - val_loss: 1.9950 - val_accuracy: 0.3934 - val_f1: 0.3697\n",
      "Epoch 187/200\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 0.7587 - accuracy: 0.7752 - f1: 0.7700 - val_loss: 1.3921 - val_accuracy: 0.5707 - val_f1: 0.5648\n",
      "Epoch 188/200\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 0.7591 - accuracy: 0.7764 - f1: 0.7718 - val_loss: 3.4088 - val_accuracy: 0.2789 - val_f1: 0.2809\n",
      "Epoch 189/200\n",
      "176/176 [==============================] - 88s 497ms/step - loss: 0.7622 - accuracy: 0.7733 - f1: 0.7694 - val_loss: 2.0879 - val_accuracy: 0.4697 - val_f1: 0.4629\n",
      "Epoch 190/200\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 0.7527 - accuracy: 0.7783 - f1: 0.7734 - val_loss: 2.9788 - val_accuracy: 0.3058 - val_f1: 0.2921\n",
      "Epoch 191/200\n",
      "176/176 [==============================] - 88s 497ms/step - loss: 0.7505 - accuracy: 0.7787 - f1: 0.7737 - val_loss: 3.2211 - val_accuracy: 0.2201 - val_f1: 0.1995\n",
      "Epoch 192/200\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 0.7495 - accuracy: 0.7796 - f1: 0.7751 - val_loss: 3.5091 - val_accuracy: 0.2747 - val_f1: 0.2752\n",
      "Epoch 193/200\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 0.7486 - accuracy: 0.7787 - f1: 0.7725 - val_loss: 3.2667 - val_accuracy: 0.2739 - val_f1: 0.2605\n",
      "Epoch 194/200\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 0.7459 - accuracy: 0.7822 - f1: 0.7775 - val_loss: 1.8872 - val_accuracy: 0.4295 - val_f1: 0.4114\n",
      "Epoch 195/200\n",
      "176/176 [==============================] - 88s 497ms/step - loss: 0.7486 - accuracy: 0.7774 - f1: 0.7716 - val_loss: 2.5159 - val_accuracy: 0.3343 - val_f1: 0.3146\n",
      "Epoch 196/200\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 0.7737 - accuracy: 0.7694 - f1: 0.7629 - val_loss: 2.4463 - val_accuracy: 0.3402 - val_f1: 0.3214\n",
      "Epoch 197/200\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 0.7452 - accuracy: 0.7808 - f1: 0.7752 - val_loss: 1.6441 - val_accuracy: 0.4247 - val_f1: 0.3942\n",
      "Epoch 198/200\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 0.7650 - accuracy: 0.7755 - f1: 0.7688 - val_loss: 2.0663 - val_accuracy: 0.4052 - val_f1: 0.4048\n",
      "Epoch 199/200\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 0.7567 - accuracy: 0.7771 - f1: 0.7714 - val_loss: 2.0765 - val_accuracy: 0.3436 - val_f1: 0.3253\n",
      "Epoch 200/200\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 0.7543 - accuracy: 0.7788 - f1: 0.7731 - val_loss: 1.3482 - val_accuracy: 0.5793 - val_f1: 0.5736\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(base_dir+\"models/resnet18_fp8.keras\")\n",
    "model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy',f1])\n",
    "history=model.fit(x_train,y_train,batch_size=256,epochs=200,callbacks=[checkpoint], validation_split=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# Plot F1\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history.history['f1'], label='Training f1')\n",
    "plt.plot(history.history['val_f1'], label='Validation f1')\n",
    "plt.title('Training and Validation f1')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('f1')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGNi79yHryWC",
    "outputId": "0cb71480-52ba-4d6f-b0fb-fb6c7f4f01a9"
   },
   "outputs": [],
   "source": [
    "del x_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKgsFxu7sOLO",
    "outputId": "3600ddf8-285c-430d-d76c-89b73afe3c12"
   },
   "outputs": [],
   "source": [
    "# model=load_model(base_dir+\"models/resnet18_fp8.keras\",custom_objects={'f1':f1})\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebVBf3mIWZ-2",
    "outputId": "c9bffd2a-1bc7-47b0-d3ff-97197b5597b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 12s 225ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(x_test,batch_size=256)\n",
    "y_pred = to_categorical(np.argmax(y_pred, axis=1), 4).astype(int)\n",
    "y_pred=np.argmax(y_pred,axis=1)\n",
    "y_test=np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        WAKE       0.49      0.53      0.51      2810\n",
      "         REM       0.74      0.12      0.21      1809\n",
      "       LIGHT       0.61      0.75      0.67      6233\n",
      "        DEEP       0.54      0.52      0.53      1598\n",
      "\n",
      "    accuracy                           0.58     12450\n",
      "   macro avg       0.60      0.48      0.48     12450\n",
      "weighted avg       0.60      0.58      0.55     12450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred,target_names=['WAKE','REM','LIGHT','DEEP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "JWLTBad8WZ-3",
    "outputId": "aa4b506d-3051-4f63-9c7a-4b450cf95427"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['WAKE','REM','LIGHT','DEEP'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zazaz\\anaconda3\\envs\\tf\\lib\\site-packages\\qkeras\\qtools\\qgraph.py:189: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zazaz\\anaconda3\\envs\\tf\\lib\\site-packages\\qkeras\\qtools\\qgraph.py:189: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n",
      "CRITICAL:absl:unsupported kernel shape, it is neither a dense kernel of length 2, nor a convolution kernel of length 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operation count for <keras.layers.pooling.global_average_pooling1d.GlobalAveragePooling1D object at 0x000001AE43B7D5E0> is defaulted to 0\n",
      "{\n",
      "    \"source_quantizers\": [\n",
      "        {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        }\n",
      "    ],\n",
      "    \"q_conv1d\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                7,\n",
      "                1,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 64\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1920,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 860160\n",
      "    },\n",
      "    \"batch_normalization\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1920,\n",
      "                64\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1920,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 122880\n",
      "    },\n",
      "    \"max_pooling1d\": {\n",
      "        \"layer_type\": \"MaxPooling1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 122880\n",
      "    },\n",
      "    \"q_conv1d_1\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                64,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 64\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 24,\n",
      "            \"int_bits\": 11,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 24,\n",
      "            \"int_bits\": 11,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 11796480\n",
      "    },\n",
      "    \"batch_normalization_1\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 24,\n",
      "                \"int_bits\": 11,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation_1\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_2\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                64,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 64\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 24,\n",
      "            \"int_bits\": 11,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 24,\n",
      "            \"int_bits\": 11,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 11796480\n",
      "    },\n",
      "    \"batch_normalization_2\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 24,\n",
      "                \"int_bits\": 11,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"add\": {\n",
      "        \"layer_type\": \"Add\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"Add_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_activation_2\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_3\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                64,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 64\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 24,\n",
      "            \"int_bits\": 11,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 24,\n",
      "            \"int_bits\": 11,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 11796480\n",
      "    },\n",
      "    \"batch_normalization_3\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 24,\n",
      "                \"int_bits\": 11,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation_3\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_4\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                64,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 64\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 24,\n",
      "            \"int_bits\": 11,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 24,\n",
      "            \"int_bits\": 11,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 11796480\n",
      "    },\n",
      "    \"batch_normalization_4\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 24,\n",
      "                \"int_bits\": 11,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"add_1\": {\n",
      "        \"layer_type\": \"Add\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"Add_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_activation_4\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_5\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                64,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 128\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 24,\n",
      "            \"int_bits\": 11,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 24,\n",
      "            \"int_bits\": 11,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 11796480\n",
      "    },\n",
      "    \"q_conv1d_7\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                64,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 128\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 23,\n",
      "            \"int_bits\": 10,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 23,\n",
      "            \"int_bits\": 10,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 3932160\n",
      "    },\n",
      "    \"batch_normalization_5\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 24,\n",
      "                \"int_bits\": 11,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"batch_normalization_7\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 23,\n",
      "                \"int_bits\": 10,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation_5\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_6\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                128,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 128\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 25,\n",
      "            \"int_bits\": 12,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 25,\n",
      "            \"int_bits\": 12,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 23592960\n",
      "    },\n",
      "    \"batch_normalization_6\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 25,\n",
      "                \"int_bits\": 12,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"add_2\": {\n",
      "        \"layer_type\": \"Add\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"Add_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_activation_6\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_8\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                128,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 128\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 25,\n",
      "            \"int_bits\": 12,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 25,\n",
      "            \"int_bits\": 12,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 23592960\n",
      "    },\n",
      "    \"batch_normalization_8\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 25,\n",
      "                \"int_bits\": 12,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation_7\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_9\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                128,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 128\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 25,\n",
      "            \"int_bits\": 12,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 25,\n",
      "            \"int_bits\": 12,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 23592960\n",
      "    },\n",
      "    \"batch_normalization_9\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 25,\n",
      "                \"int_bits\": 12,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"add_3\": {\n",
      "        \"layer_type\": \"Add\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"Add_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_activation_8\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_10\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                128,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 256\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 25,\n",
      "            \"int_bits\": 12,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 25,\n",
      "            \"int_bits\": 12,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 23592960\n",
      "    },\n",
      "    \"q_conv1d_12\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                128,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 256\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 24,\n",
      "            \"int_bits\": 11,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 24,\n",
      "            \"int_bits\": 11,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 7864320\n",
      "    },\n",
      "    \"batch_normalization_10\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 25,\n",
      "                \"int_bits\": 12,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"batch_normalization_12\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 24,\n",
      "                \"int_bits\": 11,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation_9\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_11\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                256,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 256\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 26,\n",
      "            \"int_bits\": 13,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 26,\n",
      "            \"int_bits\": 13,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 47185920\n",
      "    },\n",
      "    \"batch_normalization_11\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 26,\n",
      "                \"int_bits\": 13,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"add_4\": {\n",
      "        \"layer_type\": \"Add\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"Add_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_activation_10\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_13\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                256,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 256\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 26,\n",
      "            \"int_bits\": 13,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 26,\n",
      "            \"int_bits\": 13,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 47185920\n",
      "    },\n",
      "    \"batch_normalization_13\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 26,\n",
      "                \"int_bits\": 13,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation_11\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_14\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                256,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 256\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 26,\n",
      "            \"int_bits\": 13,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 26,\n",
      "            \"int_bits\": 13,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 47185920\n",
      "    },\n",
      "    \"batch_normalization_14\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 26,\n",
      "                \"int_bits\": 13,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"add_5\": {\n",
      "        \"layer_type\": \"Add\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"Add_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_activation_12\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_15\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                256,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 512\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 26,\n",
      "            \"int_bits\": 13,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 26,\n",
      "            \"int_bits\": 13,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 47185920\n",
      "    },\n",
      "    \"q_conv1d_17\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                256,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 512\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 25,\n",
      "            \"int_bits\": 12,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 25,\n",
      "            \"int_bits\": 12,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 15728640\n",
      "    },\n",
      "    \"batch_normalization_15\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 26,\n",
      "                \"int_bits\": 13,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"batch_normalization_17\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 25,\n",
      "                \"int_bits\": 12,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation_13\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_16\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                512,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 512\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 27,\n",
      "            \"int_bits\": 14,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 27,\n",
      "            \"int_bits\": 14,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 94371840\n",
      "    },\n",
      "    \"batch_normalization_16\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 27,\n",
      "                \"int_bits\": 14,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"add_6\": {\n",
      "        \"layer_type\": \"Add\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"Add_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_activation_14\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_18\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                512,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 512\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 27,\n",
      "            \"int_bits\": 14,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 27,\n",
      "            \"int_bits\": 14,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 94371840\n",
      "    },\n",
      "    \"batch_normalization_18\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 27,\n",
      "                \"int_bits\": 14,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation_15\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_19\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                512,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 512\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 27,\n",
      "            \"int_bits\": 14,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 27,\n",
      "            \"int_bits\": 14,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 94371840\n",
      "    },\n",
      "    \"batch_normalization_19\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 27,\n",
      "                \"int_bits\": 14,\n",
      "                \"is_signed\": 1\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"add_7\": {\n",
      "        \"layer_type\": \"Add\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"Add_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_activation_16\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"global_average_pooling1d\": {\n",
      "        \"layer_type\": \"GlobalAveragePooling1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_relu\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 1,\n",
      "            \"is_signed\": 0,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 0\n",
      "    },\n",
      "    \"q_dense\": {\n",
      "        \"layer_type\": \"QDense\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_relu\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 1,\n",
      "                \"is_signed\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                512,\n",
      "                4\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 4\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 3,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 26,\n",
      "            \"int_bits\": 13,\n",
      "            \"is_signed\": 1,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 26,\n",
      "            \"int_bits\": 13,\n",
      "            \"is_signed\": 1,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                4\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 2048\n",
      "    }\n",
      "}\n",
      "{'add': {'energy': {'inputs': 146065.53,\n",
      "                    'op_cost': 55296.0,\n",
      "                    'outputs': 116852.42,\n",
      "                    'parameters': 0.0},\n",
      "         'total': 55296.0},\n",
      " 'add_1': {'energy': {'inputs': 146065.53,\n",
      "                      'op_cost': 55296.0,\n",
      "                      'outputs': 116852.42,\n",
      "                      'parameters': 0.0},\n",
      "           'total': 55296.0},\n",
      " 'add_2': {'energy': {'inputs': 233704.85,\n",
      "                      'op_cost': 55296.0,\n",
      "                      'outputs': 116852.42,\n",
      "                      'parameters': 0.0},\n",
      "           'total': 55296.0},\n",
      " 'add_3': {'energy': {'inputs': 146065.53,\n",
      "                      'op_cost': 55296.0,\n",
      "                      'outputs': 116852.42,\n",
      "                      'parameters': 0.0},\n",
      "           'total': 55296.0},\n",
      " 'add_4': {'energy': {'inputs': 233704.85,\n",
      "                      'op_cost': 55296.0,\n",
      "                      'outputs': 116852.42,\n",
      "                      'parameters': 0.0},\n",
      "           'total': 55296.0},\n",
      " 'add_5': {'energy': {'inputs': 146065.53,\n",
      "                      'op_cost': 55296.0,\n",
      "                      'outputs': 116852.42,\n",
      "                      'parameters': 0.0},\n",
      "           'total': 55296.0},\n",
      " 'add_6': {'energy': {'inputs': 233704.85,\n",
      "                      'op_cost': 55296.0,\n",
      "                      'outputs': 116852.42,\n",
      "                      'parameters': 0.0},\n",
      "           'total': 55296.0},\n",
      " 'add_7': {'energy': {'inputs': 146065.53,\n",
      "                      'op_cost': 55296.0,\n",
      "                      'outputs': 116852.42,\n",
      "                      'parameters': 0.0},\n",
      "           'total': 55296.0},\n",
      " 'batch_normalization': {'energy': {'inputs': 233704.85,\n",
      "                                    'op_cost': 909312.0,\n",
      "                                    'outputs': 233704.85,\n",
      "                                    'parameters': 486.89},\n",
      "                         'total': 486.89},\n",
      " 'batch_normalization_1': {'energy': {'inputs': 87639.32,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 486.89},\n",
      "                           'total': 486.89},\n",
      " 'batch_normalization_10': {'energy': {'inputs': 91290.96,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 1947.54},\n",
      "                            'total': 1947.54},\n",
      " 'batch_normalization_11': {'energy': {'inputs': 94942.59,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 1947.54},\n",
      "                            'total': 1947.54},\n",
      " 'batch_normalization_12': {'energy': {'inputs': 87639.32,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 1947.54},\n",
      "                            'total': 1947.54},\n",
      " 'batch_normalization_13': {'energy': {'inputs': 94942.59,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 1947.54},\n",
      "                            'total': 1947.54},\n",
      " 'batch_normalization_14': {'energy': {'inputs': 94942.59,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 1947.54},\n",
      "                            'total': 1947.54},\n",
      " 'batch_normalization_15': {'energy': {'inputs': 94942.59,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 3895.08},\n",
      "                            'total': 3895.08},\n",
      " 'batch_normalization_16': {'energy': {'inputs': 98594.23,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 3895.08},\n",
      "                            'total': 3895.08},\n",
      " 'batch_normalization_17': {'energy': {'inputs': 91290.96,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 3895.08},\n",
      "                            'total': 3895.08},\n",
      " 'batch_normalization_18': {'energy': {'inputs': 98594.23,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 3895.08},\n",
      "                            'total': 3895.08},\n",
      " 'batch_normalization_19': {'energy': {'inputs': 98594.23,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 3895.08},\n",
      "                            'total': 3895.08},\n",
      " 'batch_normalization_2': {'energy': {'inputs': 87639.32,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 486.89},\n",
      "                           'total': 486.89},\n",
      " 'batch_normalization_3': {'energy': {'inputs': 87639.32,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 486.89},\n",
      "                           'total': 486.89},\n",
      " 'batch_normalization_4': {'energy': {'inputs': 87639.32,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 486.89},\n",
      "                           'total': 486.89},\n",
      " 'batch_normalization_5': {'energy': {'inputs': 87639.32,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 973.77},\n",
      "                           'total': 973.77},\n",
      " 'batch_normalization_6': {'energy': {'inputs': 91290.96,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 973.77},\n",
      "                           'total': 973.77},\n",
      " 'batch_normalization_7': {'energy': {'inputs': 83987.68,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 973.77},\n",
      "                           'total': 973.77},\n",
      " 'batch_normalization_8': {'energy': {'inputs': 91290.96,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 973.77},\n",
      "                           'total': 973.77},\n",
      " 'batch_normalization_9': {'energy': {'inputs': 91290.96,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 973.77},\n",
      "                           'total': 973.77},\n",
      " 'global_average_pooling1d': {'energy': {'inputs': 29213.11,\n",
      "                                         'op_cost': 0.0,\n",
      "                                         'outputs': 243.44,\n",
      "                                         'parameters': 0.0},\n",
      "                              'total': 29213.11},\n",
      " 'max_pooling1d': {'energy': {'inputs': 58426.21,\n",
      "                              'op_cost': 0.0,\n",
      "                              'outputs': 29213.11,\n",
      "                              'parameters': 0.0},\n",
      "                   'total': 58426.21},\n",
      " 'q_activation': {'energy': {'inputs': 233704.85,\n",
      "                             'op_cost': 0.0,\n",
      "                             'outputs': 58426.21,\n",
      "                             'parameters': 0.0},\n",
      "                  'total': 58426.21},\n",
      " 'q_activation_1': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 29213.11,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 29213.11},\n",
      " 'q_activation_10': {'energy': {'inputs': 116852.42,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 29213.11,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 29213.11},\n",
      " 'q_activation_11': {'energy': {'inputs': 116852.42,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 29213.11,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 29213.11},\n",
      " 'q_activation_12': {'energy': {'inputs': 116852.42,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 29213.11,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 29213.11},\n",
      " 'q_activation_13': {'energy': {'inputs': 116852.42,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 29213.11,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 29213.11},\n",
      " 'q_activation_14': {'energy': {'inputs': 116852.42,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 29213.11,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 29213.11},\n",
      " 'q_activation_15': {'energy': {'inputs': 116852.42,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 29213.11,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 29213.11},\n",
      " 'q_activation_16': {'energy': {'inputs': 116852.42,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 29213.11,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 29213.11},\n",
      " 'q_activation_2': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 29213.11,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 29213.11},\n",
      " 'q_activation_3': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 29213.11,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 29213.11},\n",
      " 'q_activation_4': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 29213.11,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 29213.11},\n",
      " 'q_activation_5': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 29213.11,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 29213.11},\n",
      " 'q_activation_6': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 29213.11,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 29213.11},\n",
      " 'q_activation_7': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 29213.11,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 29213.11},\n",
      " 'q_activation_8': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 29213.11,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 29213.11},\n",
      " 'q_activation_9': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 29213.11,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 29213.11},\n",
      " 'q_conv1d': {'energy': {'inputs': 7303.28,\n",
      "                         'op_cost': 3956736.0,\n",
      "                         'outputs': 233704.85,\n",
      "                         'parameters': 243.44},\n",
      "              'total': 3964282.72},\n",
      " 'q_conv1d_1': {'energy': {'inputs': 29213.11,\n",
      "                           'op_cost': 3244032.0,\n",
      "                           'outputs': 87639.32,\n",
      "                           'parameters': 5873.05},\n",
      "                'total': 3279118.16},\n",
      " 'q_conv1d_10': {'energy': {'inputs': 29213.11,\n",
      "                            'op_cost': 6561792.0,\n",
      "                            'outputs': 91290.96,\n",
      "                            'parameters': 46862.69},\n",
      "                 'total': 6637867.8},\n",
      " 'q_conv1d_11': {'energy': {'inputs': 29213.11,\n",
      "                            'op_cost': 13271040.0,\n",
      "                            'outputs': 94942.59,\n",
      "                            'parameters': 93603.66},\n",
      "                 'total': 13393856.77},\n",
      " 'q_conv1d_12': {'energy': {'inputs': 29213.11,\n",
      "                            'op_cost': 2162688.0,\n",
      "                            'outputs': 87639.32,\n",
      "                            'parameters': 15702.04},\n",
      "                 'total': 2207603.15},\n",
      " 'q_conv1d_13': {'energy': {'inputs': 29213.11,\n",
      "                            'op_cost': 13271040.0,\n",
      "                            'outputs': 94942.59,\n",
      "                            'parameters': 93603.66},\n",
      "                 'total': 13393856.77},\n",
      " 'q_conv1d_14': {'energy': {'inputs': 29213.11,\n",
      "                            'op_cost': 13271040.0,\n",
      "                            'outputs': 94942.59,\n",
      "                            'parameters': 93603.66},\n",
      "                 'total': 13393856.77},\n",
      " 'q_conv1d_15': {'energy': {'inputs': 29213.11,\n",
      "                            'op_cost': 13271040.0,\n",
      "                            'outputs': 94942.59,\n",
      "                            'parameters': 187207.32},\n",
      "                 'total': 13487460.43},\n",
      " 'q_conv1d_16': {'energy': {'inputs': 29213.11,\n",
      "                            'op_cost': 26836992.0,\n",
      "                            'outputs': 98594.23,\n",
      "                            'parameters': 374171.2},\n",
      "                 'total': 27240376.31},\n",
      " 'q_conv1d_17': {'energy': {'inputs': 29213.11,\n",
      "                            'op_cost': 4374528.0,\n",
      "                            'outputs': 91290.96,\n",
      "                            'parameters': 62564.73},\n",
      "                 'total': 4466305.84},\n",
      " 'q_conv1d_18': {'energy': {'inputs': 29213.11,\n",
      "                            'op_cost': 26836992.0,\n",
      "                            'outputs': 98594.23,\n",
      "                            'parameters': 374171.2},\n",
      "                 'total': 27240376.31},\n",
      " 'q_conv1d_19': {'energy': {'inputs': 29213.11,\n",
      "                            'op_cost': 26836992.0,\n",
      "                            'outputs': 98594.23,\n",
      "                            'parameters': 374171.2},\n",
      "                 'total': 27240376.31},\n",
      " 'q_conv1d_2': {'energy': {'inputs': 29213.11,\n",
      "                           'op_cost': 3244032.0,\n",
      "                           'outputs': 87639.32,\n",
      "                           'parameters': 5873.05},\n",
      "                'total': 3279118.16},\n",
      " 'q_conv1d_3': {'energy': {'inputs': 29213.11,\n",
      "                           'op_cost': 3244032.0,\n",
      "                           'outputs': 87639.32,\n",
      "                           'parameters': 5873.05},\n",
      "                'total': 3279118.16},\n",
      " 'q_conv1d_4': {'energy': {'inputs': 29213.11,\n",
      "                           'op_cost': 3244032.0,\n",
      "                           'outputs': 87639.32,\n",
      "                           'parameters': 5873.05},\n",
      "                'total': 3279118.16},\n",
      " 'q_conv1d_5': {'energy': {'inputs': 29213.11,\n",
      "                           'op_cost': 3244032.0,\n",
      "                           'outputs': 87639.32,\n",
      "                           'parameters': 11746.1},\n",
      "                'total': 3284991.21},\n",
      " 'q_conv1d_6': {'energy': {'inputs': 29213.11,\n",
      "                           'op_cost': 6561792.0,\n",
      "                           'outputs': 91290.96,\n",
      "                           'parameters': 23431.35},\n",
      "                'total': 6614436.46},\n",
      " 'q_conv1d_7': {'energy': {'inputs': 29213.11,\n",
      "                           'op_cost': 1069056.0,\n",
      "                           'outputs': 83987.68,\n",
      "                           'parameters': 3955.94},\n",
      "                'total': 1102225.05},\n",
      " 'q_conv1d_8': {'energy': {'inputs': 29213.11,\n",
      "                           'op_cost': 6561792.0,\n",
      "                           'outputs': 91290.96,\n",
      "                           'parameters': 23431.35},\n",
      "                'total': 6614436.46},\n",
      " 'q_conv1d_9': {'energy': {'inputs': 29213.11,\n",
      "                           'op_cost': 6561792.0,\n",
      "                           'outputs': 91290.96,\n",
      "                           'parameters': 23431.35},\n",
      "                'total': 6614436.46},\n",
      " 'q_dense': {'energy': {'inputs': 243.44,\n",
      "                        'op_cost': 576.0,\n",
      "                        'outputs': 7.61,\n",
      "                        'parameters': 977.57},\n",
      "             'total': 1797.01}}\n",
      "\n",
      "Total energy: 191.11 uJ\n"
     ]
    }
   ],
   "source": [
    "q = run_qtools.QTools(\n",
    "    model,\n",
    "    # energy calculation using a given process\n",
    "    # \"horowitz\" refers to 45nm process published at\n",
    "    # M. Horowitz, \"1.1 Computing's energy problem (and what we can do about\n",
    "    # it), \"2014 IEEE International Solid-State Circuits Conference Digest of\n",
    "    # Technical Papers (ISSCC), San Francisco, CA, 2014, pp. 10-14, \n",
    "    # doi: 10.1109/ISSCC.2014.6757323.\n",
    "    \n",
    "    process=\"horowitz\",\n",
    "    # quantizers for model input\n",
    "    source_quantizers=[\"fp32\"],\n",
    "    \n",
    "    is_inference=True,\n",
    "    # whether model has been trained already, which is\n",
    "    # needed to compute tighter bounds for QBatchNormalization Power estimation.\n",
    "    \n",
    "    # weights_path=None,\n",
    "    # absolute path (including filename) of the model weights\n",
    "    \n",
    "    \n",
    "    keras_quantizer=\"fp32\",\n",
    "    # keras_quantizer to quantize weight/bias in un-quantized keras layers\n",
    "    \n",
    "    keras_accumulator=\"fp32\",\n",
    "    # keras_quantizer to quantize MAC in un-quantized keras layers\n",
    "    \n",
    "    for_reference=False,\n",
    "    # whether calculate baseline energy\n",
    ")\n",
    "q.qtools_stats_print()\n",
    "\n",
    "# caculate energy of the derived data type map.\n",
    "energy_dict = q.pe(\n",
    "    # whether to store parameters in dram, sram, or fixed\n",
    "    weights_on_memory=\"sram\",\n",
    "    # store activations in dram or sram\n",
    "    activations_on_memory=\"sram\",\n",
    "    # minimum sram size in number of bits\n",
    "    min_sram_size=8*16*1024*1024,\n",
    "    # whether load data from dram to sram (consider sram as a cache\n",
    "    # for dram. If false, we will assume data will be already in SRAM\n",
    "    rd_wr_on_io=False)\n",
    "\n",
    "# get stats of energy distribution in each layer\n",
    "energy_profile = q.extract_energy_profile(qtools_settings.cfg.include_energy, energy_dict)\n",
    "# extract sum of energy of each layer according to the rule specified in\n",
    "# qtools_settings.cfg.include_energy\n",
    "total_energy = q.extract_energy_sum(qtools_settings.cfg.include_energy, energy_dict)\n",
    "\n",
    "pprint.pprint(energy_profile)\n",
    "print()\n",
    "\n",
    "print(\"Total energy: {:.2f} uJ\".format(total_energy / 1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operation count for <keras.layers.pooling.global_average_pooling1d.GlobalAveragePooling1D object at 0x000001AE43B7D5E0> is defaulted to 0\n",
      "{\n",
      "    \"source_quantizers\": [\n",
      "        {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        }\n",
      "    ],\n",
      "    \"q_conv1d\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                7,\n",
      "                1,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 64\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1920,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 860160\n",
      "    },\n",
      "    \"batch_normalization\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1920,\n",
      "                64\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1920,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 122880\n",
      "    },\n",
      "    \"max_pooling1d\": {\n",
      "        \"layer_type\": \"MaxPooling1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 122880\n",
      "    },\n",
      "    \"q_conv1d_1\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                64,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 64\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 11796480\n",
      "    },\n",
      "    \"batch_normalization_1\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation_1\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_2\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                64,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 64\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 11796480\n",
      "    },\n",
      "    \"batch_normalization_2\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"add\": {\n",
      "        \"layer_type\": \"Add\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"Add_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_activation_2\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_3\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                64,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 64\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 11796480\n",
      "    },\n",
      "    \"batch_normalization_3\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation_3\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_4\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                64,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 64\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 11796480\n",
      "    },\n",
      "    \"batch_normalization_4\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"add_1\": {\n",
      "        \"layer_type\": \"Add\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"Add_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_activation_4\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                960,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_5\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                64,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 128\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 11796480\n",
      "    },\n",
      "    \"q_conv1d_7\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                64,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 128\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 3932160\n",
      "    },\n",
      "    \"batch_normalization_5\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"batch_normalization_7\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation_5\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_6\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                128,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 128\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 23592960\n",
      "    },\n",
      "    \"batch_normalization_6\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"add_2\": {\n",
      "        \"layer_type\": \"Add\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"Add_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_activation_6\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_8\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                128,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 128\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 23592960\n",
      "    },\n",
      "    \"batch_normalization_8\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation_7\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_9\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                128,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 128\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 23592960\n",
      "    },\n",
      "    \"batch_normalization_9\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"add_3\": {\n",
      "        \"layer_type\": \"Add\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"Add_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_activation_8\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                480,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_10\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                128,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 256\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 23592960\n",
      "    },\n",
      "    \"q_conv1d_12\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                128,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 256\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 7864320\n",
      "    },\n",
      "    \"batch_normalization_10\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"batch_normalization_12\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation_9\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_11\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                256,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 256\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 47185920\n",
      "    },\n",
      "    \"batch_normalization_11\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"add_4\": {\n",
      "        \"layer_type\": \"Add\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"Add_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_activation_10\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_13\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                256,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 256\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 47185920\n",
      "    },\n",
      "    \"batch_normalization_13\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation_11\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_14\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                256,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 256\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 47185920\n",
      "    },\n",
      "    \"batch_normalization_14\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"add_5\": {\n",
      "        \"layer_type\": \"Add\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"Add_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_activation_12\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                240,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_15\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                256,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 512\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 47185920\n",
      "    },\n",
      "    \"q_conv1d_17\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                256,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 512\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 15728640\n",
      "    },\n",
      "    \"batch_normalization_15\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"batch_normalization_17\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation_13\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_16\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                512,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 512\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 94371840\n",
      "    },\n",
      "    \"batch_normalization_16\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"add_6\": {\n",
      "        \"layer_type\": \"Add\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"Add_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_activation_14\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_18\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                512,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 512\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 94371840\n",
      "    },\n",
      "    \"batch_normalization_18\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_activation_15\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_conv1d_19\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                512,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 512\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 94371840\n",
      "    },\n",
      "    \"batch_normalization_19\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"add_7\": {\n",
      "        \"layer_type\": \"Add\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"Add_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"q_activation_16\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                120,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 61440\n",
      "    },\n",
      "    \"global_average_pooling1d\": {\n",
      "        \"layer_type\": \"GlobalAveragePooling1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                512\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 0\n",
      "    },\n",
      "    \"q_dense\": {\n",
      "        \"layer_type\": \"QDense\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                512,\n",
      "                4\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 4\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                4\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 2048\n",
      "    }\n",
      "}\n",
      "{'add': {'energy': {'inputs': 233704.85,\n",
      "                    'op_cost': 55296.0,\n",
      "                    'outputs': 116852.42,\n",
      "                    'parameters': 0.0},\n",
      "         'total': 55296.0},\n",
      " 'add_1': {'energy': {'inputs': 233704.85,\n",
      "                      'op_cost': 55296.0,\n",
      "                      'outputs': 116852.42,\n",
      "                      'parameters': 0.0},\n",
      "           'total': 55296.0},\n",
      " 'add_2': {'energy': {'inputs': 233704.85,\n",
      "                      'op_cost': 55296.0,\n",
      "                      'outputs': 116852.42,\n",
      "                      'parameters': 0.0},\n",
      "           'total': 55296.0},\n",
      " 'add_3': {'energy': {'inputs': 233704.85,\n",
      "                      'op_cost': 55296.0,\n",
      "                      'outputs': 116852.42,\n",
      "                      'parameters': 0.0},\n",
      "           'total': 55296.0},\n",
      " 'add_4': {'energy': {'inputs': 233704.85,\n",
      "                      'op_cost': 55296.0,\n",
      "                      'outputs': 116852.42,\n",
      "                      'parameters': 0.0},\n",
      "           'total': 55296.0},\n",
      " 'add_5': {'energy': {'inputs': 233704.85,\n",
      "                      'op_cost': 55296.0,\n",
      "                      'outputs': 116852.42,\n",
      "                      'parameters': 0.0},\n",
      "           'total': 55296.0},\n",
      " 'add_6': {'energy': {'inputs': 233704.85,\n",
      "                      'op_cost': 55296.0,\n",
      "                      'outputs': 116852.42,\n",
      "                      'parameters': 0.0},\n",
      "           'total': 55296.0},\n",
      " 'add_7': {'energy': {'inputs': 233704.85,\n",
      "                      'op_cost': 55296.0,\n",
      "                      'outputs': 116852.42,\n",
      "                      'parameters': 0.0},\n",
      "           'total': 55296.0},\n",
      " 'batch_normalization': {'energy': {'inputs': 233704.85,\n",
      "                                    'op_cost': 909312.0,\n",
      "                                    'outputs': 233704.85,\n",
      "                                    'parameters': 486.89},\n",
      "                         'total': 486.89},\n",
      " 'batch_normalization_1': {'energy': {'inputs': 116852.42,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 486.89},\n",
      "                           'total': 486.89},\n",
      " 'batch_normalization_10': {'energy': {'inputs': 116852.42,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 1947.54},\n",
      "                            'total': 1947.54},\n",
      " 'batch_normalization_11': {'energy': {'inputs': 116852.42,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 1947.54},\n",
      "                            'total': 1947.54},\n",
      " 'batch_normalization_12': {'energy': {'inputs': 116852.42,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 1947.54},\n",
      "                            'total': 1947.54},\n",
      " 'batch_normalization_13': {'energy': {'inputs': 116852.42,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 1947.54},\n",
      "                            'total': 1947.54},\n",
      " 'batch_normalization_14': {'energy': {'inputs': 116852.42,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 1947.54},\n",
      "                            'total': 1947.54},\n",
      " 'batch_normalization_15': {'energy': {'inputs': 116852.42,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 3895.08},\n",
      "                            'total': 3895.08},\n",
      " 'batch_normalization_16': {'energy': {'inputs': 116852.42,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 3895.08},\n",
      "                            'total': 3895.08},\n",
      " 'batch_normalization_17': {'energy': {'inputs': 116852.42,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 3895.08},\n",
      "                            'total': 3895.08},\n",
      " 'batch_normalization_18': {'energy': {'inputs': 116852.42,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 3895.08},\n",
      "                            'total': 3895.08},\n",
      " 'batch_normalization_19': {'energy': {'inputs': 116852.42,\n",
      "                                       'op_cost': 454656.0,\n",
      "                                       'outputs': 116852.42,\n",
      "                                       'parameters': 3895.08},\n",
      "                            'total': 3895.08},\n",
      " 'batch_normalization_2': {'energy': {'inputs': 116852.42,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 486.89},\n",
      "                           'total': 486.89},\n",
      " 'batch_normalization_3': {'energy': {'inputs': 116852.42,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 486.89},\n",
      "                           'total': 486.89},\n",
      " 'batch_normalization_4': {'energy': {'inputs': 116852.42,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 486.89},\n",
      "                           'total': 486.89},\n",
      " 'batch_normalization_5': {'energy': {'inputs': 116852.42,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 973.77},\n",
      "                           'total': 973.77},\n",
      " 'batch_normalization_6': {'energy': {'inputs': 116852.42,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 973.77},\n",
      "                           'total': 973.77},\n",
      " 'batch_normalization_7': {'energy': {'inputs': 116852.42,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 973.77},\n",
      "                           'total': 973.77},\n",
      " 'batch_normalization_8': {'energy': {'inputs': 116852.42,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 973.77},\n",
      "                           'total': 973.77},\n",
      " 'batch_normalization_9': {'energy': {'inputs': 116852.42,\n",
      "                                      'op_cost': 454656.0,\n",
      "                                      'outputs': 116852.42,\n",
      "                                      'parameters': 973.77},\n",
      "                           'total': 973.77},\n",
      " 'global_average_pooling1d': {'energy': {'inputs': 116852.42,\n",
      "                                         'op_cost': 0.0,\n",
      "                                         'outputs': 973.77,\n",
      "                                         'parameters': 0.0},\n",
      "                              'total': 116852.42},\n",
      " 'max_pooling1d': {'energy': {'inputs': 233704.85,\n",
      "                              'op_cost': 0.0,\n",
      "                              'outputs': 116852.42,\n",
      "                              'parameters': 0.0},\n",
      "                   'total': 233704.85},\n",
      " 'q_activation': {'energy': {'inputs': 233704.85,\n",
      "                             'op_cost': 0.0,\n",
      "                             'outputs': 233704.85,\n",
      "                             'parameters': 0.0},\n",
      "                  'total': 233704.85},\n",
      " 'q_activation_1': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 116852.42,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 116852.42},\n",
      " 'q_activation_10': {'energy': {'inputs': 116852.42,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 116852.42,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 116852.42},\n",
      " 'q_activation_11': {'energy': {'inputs': 116852.42,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 116852.42,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 116852.42},\n",
      " 'q_activation_12': {'energy': {'inputs': 116852.42,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 116852.42,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 116852.42},\n",
      " 'q_activation_13': {'energy': {'inputs': 116852.42,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 116852.42,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 116852.42},\n",
      " 'q_activation_14': {'energy': {'inputs': 116852.42,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 116852.42,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 116852.42},\n",
      " 'q_activation_15': {'energy': {'inputs': 116852.42,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 116852.42,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 116852.42},\n",
      " 'q_activation_16': {'energy': {'inputs': 116852.42,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 116852.42,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 116852.42},\n",
      " 'q_activation_2': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 116852.42,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 116852.42},\n",
      " 'q_activation_3': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 116852.42,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 116852.42},\n",
      " 'q_activation_4': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 116852.42,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 116852.42},\n",
      " 'q_activation_5': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 116852.42,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 116852.42},\n",
      " 'q_activation_6': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 116852.42,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 116852.42},\n",
      " 'q_activation_7': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 116852.42,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 116852.42},\n",
      " 'q_activation_8': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 116852.42,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 116852.42},\n",
      " 'q_activation_9': {'energy': {'inputs': 116852.42,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 116852.42,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 116852.42},\n",
      " 'q_conv1d': {'energy': {'inputs': 7303.28,\n",
      "                         'op_cost': 3956736.0,\n",
      "                         'outputs': 233704.85,\n",
      "                         'parameters': 973.77},\n",
      "              'total': 3965013.05},\n",
      " 'q_conv1d_1': {'energy': {'inputs': 116852.42,\n",
      "                           'op_cost': 54263808.0,\n",
      "                           'outputs': 116852.42,\n",
      "                           'parameters': 23492.21},\n",
      "                'total': 54404152.63},\n",
      " 'q_conv1d_10': {'energy': {'inputs': 116852.42,\n",
      "                            'op_cost': 108527616.0,\n",
      "                            'outputs': 116852.42,\n",
      "                            'parameters': 187450.76},\n",
      "                 'total': 108831919.18},\n",
      " 'q_conv1d_11': {'energy': {'inputs': 116852.42,\n",
      "                            'op_cost': 217055232.0,\n",
      "                            'outputs': 116852.42,\n",
      "                            'parameters': 374414.64},\n",
      "                 'total': 217546499.06},\n",
      " 'q_conv1d_12': {'energy': {'inputs': 116852.42,\n",
      "                            'op_cost': 36175872.0,\n",
      "                            'outputs': 116852.42,\n",
      "                            'parameters': 62808.18},\n",
      "                 'total': 36355532.6},\n",
      " 'q_conv1d_13': {'energy': {'inputs': 116852.42,\n",
      "                            'op_cost': 217055232.0,\n",
      "                            'outputs': 116852.42,\n",
      "                            'parameters': 374414.64},\n",
      "                 'total': 217546499.06},\n",
      " 'q_conv1d_14': {'energy': {'inputs': 116852.42,\n",
      "                            'op_cost': 217055232.0,\n",
      "                            'outputs': 116852.42,\n",
      "                            'parameters': 374414.64},\n",
      "                 'total': 217546499.06},\n",
      " 'q_conv1d_15': {'energy': {'inputs': 116852.42,\n",
      "                            'op_cost': 217055232.0,\n",
      "                            'outputs': 116852.42,\n",
      "                            'parameters': 748829.28},\n",
      "                 'total': 217920913.7},\n",
      " 'q_conv1d_16': {'energy': {'inputs': 116852.42,\n",
      "                            'op_cost': 434110464.0,\n",
      "                            'outputs': 116852.42,\n",
      "                            'parameters': 1496684.79},\n",
      "                 'total': 435724001.21},\n",
      " 'q_conv1d_17': {'energy': {'inputs': 116852.42,\n",
      "                            'op_cost': 72351744.0,\n",
      "                            'outputs': 116852.42,\n",
      "                            'parameters': 250258.94},\n",
      "                 'total': 72718855.36},\n",
      " 'q_conv1d_18': {'energy': {'inputs': 116852.42,\n",
      "                            'op_cost': 434110464.0,\n",
      "                            'outputs': 116852.42,\n",
      "                            'parameters': 1496684.79},\n",
      "                 'total': 435724001.21},\n",
      " 'q_conv1d_19': {'energy': {'inputs': 116852.42,\n",
      "                            'op_cost': 434110464.0,\n",
      "                            'outputs': 116852.42,\n",
      "                            'parameters': 1496684.79},\n",
      "                 'total': 435724001.21},\n",
      " 'q_conv1d_2': {'energy': {'inputs': 116852.42,\n",
      "                           'op_cost': 54263808.0,\n",
      "                           'outputs': 116852.42,\n",
      "                           'parameters': 23492.21},\n",
      "                'total': 54404152.63},\n",
      " 'q_conv1d_3': {'energy': {'inputs': 116852.42,\n",
      "                           'op_cost': 54263808.0,\n",
      "                           'outputs': 116852.42,\n",
      "                           'parameters': 23492.21},\n",
      "                'total': 54404152.63},\n",
      " 'q_conv1d_4': {'energy': {'inputs': 116852.42,\n",
      "                           'op_cost': 54263808.0,\n",
      "                           'outputs': 116852.42,\n",
      "                           'parameters': 23492.21},\n",
      "                'total': 54404152.63},\n",
      " 'q_conv1d_5': {'energy': {'inputs': 116852.42,\n",
      "                           'op_cost': 54263808.0,\n",
      "                           'outputs': 116852.42,\n",
      "                           'parameters': 46984.41},\n",
      "                'total': 54427644.83},\n",
      " 'q_conv1d_6': {'energy': {'inputs': 116852.42,\n",
      "                           'op_cost': 108527616.0,\n",
      "                           'outputs': 116852.42,\n",
      "                           'parameters': 93725.38},\n",
      "                'total': 108738193.8},\n",
      " 'q_conv1d_7': {'energy': {'inputs': 116852.42,\n",
      "                           'op_cost': 18087936.0,\n",
      "                           'outputs': 116852.42,\n",
      "                           'parameters': 15823.77},\n",
      "                'total': 18220612.19},\n",
      " 'q_conv1d_8': {'energy': {'inputs': 116852.42,\n",
      "                           'op_cost': 108527616.0,\n",
      "                           'outputs': 116852.42,\n",
      "                           'parameters': 93725.38},\n",
      "                'total': 108738193.8},\n",
      " 'q_conv1d_9': {'energy': {'inputs': 116852.42,\n",
      "                           'op_cost': 108527616.0,\n",
      "                           'outputs': 116852.42,\n",
      "                           'parameters': 93725.38},\n",
      "                'total': 108738193.8},\n",
      " 'q_dense': {'energy': {'inputs': 973.77,\n",
      "                        'op_cost': 9420.8,\n",
      "                        'outputs': 7.61,\n",
      "                        'parameters': 3902.69},\n",
      "             'total': 14297.259999999998}}\n",
      "\n",
      "Total energy: 3019.03 uJ\n"
     ]
    }
   ],
   "source": [
    "q = run_qtools.QTools(\n",
    "    model,\n",
    "    # energy calculation using a given process\n",
    "    # \"horowitz\" refers to 45nm process published at\n",
    "    # M. Horowitz, \"1.1 Computing's energy problem (and what we can do about\n",
    "    # it), \"2014 IEEE International Solid-State Circuits Conference Digest of\n",
    "    # Technical Papers (ISSCC), San Francisco, CA, 2014, pp. 10-14, \n",
    "    # doi: 10.1109/ISSCC.2014.6757323.\n",
    "    \n",
    "    process=\"horowitz\",\n",
    "    # quantizers for model input\n",
    "    source_quantizers=[\"fp32\"],\n",
    "    \n",
    "    is_inference=True,\n",
    "    # whether model has been trained already, which is\n",
    "    # needed to compute tighter bounds for QBatchNormalization Power estimation.\n",
    "    \n",
    "    # weights_path=None,\n",
    "    # absolute path (including filename) of the model weights\n",
    "    \n",
    "    \n",
    "    keras_quantizer=\"fp32\",\n",
    "    # keras_quantizer to quantize weight/bias in un-quantized keras layers\n",
    "    \n",
    "    keras_accumulator=\"fp32\",\n",
    "    # keras_quantizer to quantize MAC in un-quantized keras layers\n",
    "    \n",
    "    for_reference=True,\n",
    "    # whether calculate baseline energy\n",
    ")\n",
    "q.qtools_stats_print()\n",
    "\n",
    "# caculate energy of the derived data type map.\n",
    "energy_dict = q.pe(\n",
    "    # whether to store parameters in dram, sram, or fixed\n",
    "    weights_on_memory=\"sram\",\n",
    "    # store activations in dram or sram\n",
    "    activations_on_memory=\"sram\",\n",
    "    # minimum sram size in number of bits\n",
    "    min_sram_size=8*16*1024*1024,\n",
    "    # whether load data from dram to sram (consider sram as a cache\n",
    "    # for dram. If false, we will assume data will be already in SRAM\n",
    "    rd_wr_on_io=False)\n",
    "\n",
    "# get stats of energy distribution in each layer\n",
    "energy_profile = q.extract_energy_profile(qtools_settings.cfg.include_energy, energy_dict)\n",
    "# extract sum of energy of each layer according to the rule specified in\n",
    "# qtools_settings.cfg.include_energy\n",
    "total_energy = q.extract_energy_sum(qtools_settings.cfg.include_energy, energy_dict)\n",
    "\n",
    "pprint.pprint(energy_profile)\n",
    "print()\n",
    "\n",
    "print(\"Total energy: {:.2f} uJ\".format(total_energy / 1000000.0))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuClass": "premium",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
