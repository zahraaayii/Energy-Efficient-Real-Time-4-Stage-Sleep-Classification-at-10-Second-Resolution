{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQW2KZ4WWZ-q",
    "outputId": "d771434b-1869-45e3-c10b-2a6a8c12eb93"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# base_dir='/content/drive/MyDrive/ucd/'\n",
    "base_dir='../../folders/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yinkTQ-8WZ-u"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zazaz\\AppData\\Local\\Temp\\ipykernel_16432\\3697400870.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential,load_model,load_model\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import Conv1D, SeparableConv1D,GlobalAveragePooling1D,Add,concatenate, Conv2D,MaxPooling1D,MaxPooling2D, Dropout,Dense,Flatten,Activation, Flatten, BatchNormalization,Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import scipy.stats as stats\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install QKeras\n",
    "from qkeras import *\n",
    "import pprint\n",
    "from qkeras.autoqkeras import *\n",
    "from qkeras import *\n",
    "from qkeras.qtools import run_qtools\n",
    "from qkeras.qtools import settings as qtools_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        y_true = K.cast(y_true, 'float32')\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision_m(y_true, y_pred):\n",
    "        y_true = K.cast(y_true, 'float32')\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision\n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3RXsgFbDwmo",
    "outputId": "c4e2418a-2573-404c-a807-83485e509c41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49797, 3840, 1)\n",
      "(49797, 4)\n"
     ]
    }
   ],
   "source": [
    "with open(base_dir+f'all/train_all.pkl', 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "                x_train = res['x_train']\n",
    "                y_train = res['y_train']\n",
    "del res\n",
    "x_train=np.reshape(x_train,(len(x_train),3840,1))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12450, 3840, 1)\n",
      "(12450, 4)\n"
     ]
    }
   ],
   "source": [
    "with open(base_dir+f'all/test_all.pkl', 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "                x_test = res['x_test']\n",
    "                y_test = res['y_test']\n",
    "del res\n",
    "x_test=np.reshape(x_test,(len(x_test),3840,1))\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 3840, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 3840, 1)     4           ['input_1[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " q_conv1d (QConv1D)             (None, 3838, 32)     128         ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " q_conv1d_1 (QConv1D)           (None, 3836, 64)     6208        ['q_conv1d[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 1917, 64)     0           ['q_conv1d_1[0][0]']             \n",
      "                                                                                                  \n",
      " q_conv1d_3 (QConv1D)           (None, 1917, 96)     6240        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " q_conv1d_5 (QConv1D)           (None, 1917, 16)     1040        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 1917, 64)    0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " q_conv1d_2 (QConv1D)           (None, 1917, 64)     4160        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 3840, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 3840, 1)     4           ['input_1[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " q_conv1d (QConv1D)             (None, 3838, 32)     128         ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " q_conv1d_1 (QConv1D)           (None, 3836, 64)     6208        ['q_conv1d[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 1917, 64)     0           ['q_conv1d_1[0][0]']             \n",
      "                                                                                                  \n",
      " q_conv1d_3 (QConv1D)           (None, 1917, 96)     6240        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " q_conv1d_5 (QConv1D)           (None, 1917, 16)     1040        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 1917, 64)    0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " q_conv1d_2 (QConv1D)           (None, 1917, 64)     4160        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " q_conv1d_4 (QConv1D)           (None, 1917, 128)    36992       ['q_conv1d_3[0][0]']             \n",
      "                                                                                                  \n",
      " q_conv1d_6 (QConv1D)           (None, 1917, 32)     2592        ['q_conv1d_5[0][0]']             \n",
      "                                                                                                  \n",
      " q_conv1d_7 (QConv1D)           (None, 1917, 32)     2080        ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1917, 256)    0           ['q_conv1d_2[0][0]',             \n",
      "                                                                  'q_conv1d_4[0][0]',             \n",
      "                                                                  'q_conv1d_6[0][0]',             \n",
      "                                                                  'q_conv1d_7[0][0]']             \n",
      "                                                                                                  \n",
      " q_conv1d_9 (QConv1D)           (None, 1917, 128)    32896       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " q_conv1d_11 (QConv1D)          (None, 1917, 32)     8224        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 1917, 256)   0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " q_conv1d_8 (QConv1D)           (None, 1917, 128)    32896       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " q_conv1d_10 (QConv1D)          (None, 1917, 192)    73920       ['q_conv1d_9[0][0]']             \n",
      "                                                                                                  \n",
      " q_conv1d_12 (QConv1D)          (None, 1917, 96)     15456       ['q_conv1d_11[0][0]']            \n",
      "                                                                                                  \n",
      " q_conv1d_13 (QConv1D)          (None, 1917, 64)     16448       ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1917, 480)    0           ['q_conv1d_8[0][0]',             \n",
      "                                                                  'q_conv1d_10[0][0]',            \n",
      "                                                                  'q_conv1d_12[0][0]',            \n",
      "                                                                  'q_conv1d_13[0][0]']            \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 920160)       0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 920160)       0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " q_dense (QDense)               (None, 4)            3680644     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,919,928\n",
      "Trainable params: 3,919,926\n",
      "Non-trainable params: 2\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (3840,1)\n",
    "num_classes = 4 \n",
    "\n",
    "def inception_module(inputs, filters):\n",
    "    tower_1 = QConv1D(filters=filters[0], kernel_size=1, padding='same', activation='relu',kernel_quantizer=quantized_bits(8, 1,alpha=1), bias_quantizer=quantized_bits(8, 1,alpha=1))(inputs)\n",
    "    \n",
    "    tower_2 = QConv1D(filters=filters[1], kernel_size=1, padding='same', activation='relu',kernel_quantizer=quantized_bits(8, 1,alpha=1), bias_quantizer=quantized_bits(8, 1,alpha=1))(inputs)\n",
    "    tower_2 = QConv1D(filters=filters[2], kernel_size=3, padding='same', activation='relu',kernel_quantizer=quantized_bits(8, 1,alpha=1), bias_quantizer=quantized_bits(8, 1,alpha=1))(tower_2)\n",
    "    \n",
    "    tower_3 = QConv1D(filters=filters[3], kernel_size=1, padding='same', activation='relu',kernel_quantizer=quantized_bits(8, 1,alpha=1), bias_quantizer=quantized_bits(8, 1,alpha=1))(inputs)\n",
    "    tower_3 = QConv1D(filters=filters[4], kernel_size=5, padding='same', activation='relu',kernel_quantizer=quantized_bits(8, 1,alpha=1), bias_quantizer=quantized_bits(8, 1,alpha=1))(tower_3)\n",
    "    \n",
    "    tower_4 = MaxPooling1D(pool_size=3, strides=1, padding='same')(inputs)\n",
    "    tower_4 = QConv1D(filters=filters[5], kernel_size=1, padding='same', activation='relu',kernel_quantizer=quantized_bits(8, 1,alpha=1), bias_quantizer=quantized_bits(8, 1,alpha=1))(tower_4)\n",
    "    \n",
    "    output = concatenate([tower_1, tower_2, tower_3, tower_4], axis=2)\n",
    "    return output\n",
    "\n",
    "input_layer = Input(shape=(input_shape)) # Define your input shape\n",
    "\n",
    "# Stem\n",
    "x = BatchNormalization()(input_layer)\n",
    "x = QConv1D(filters=32, kernel_size=3, activation='relu',kernel_quantizer=quantized_bits(8, 1,alpha=1), bias_quantizer=quantized_bits(8, 1,alpha=1))(x)\n",
    "x = QConv1D(filters=64, kernel_size=3, activation='relu',kernel_quantizer=quantized_bits(8, 1,alpha=1), bias_quantizer=quantized_bits(8, 1,alpha=1))(x)\n",
    "x = MaxPooling1D(pool_size=3, strides=2)(x)\n",
    "\n",
    "# Inception modules\n",
    "x = inception_module(x, filters=[64, 96, 128, 16, 32, 32])\n",
    "x = inception_module(x, filters=[128, 128, 192, 32, 96, 64])\n",
    "\n",
    "# Add more inception modules as needed\n",
    "\n",
    "# Fully connected layers\n",
    "x = Flatten()(x)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "output_layer = QDense(num_classes,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='softmax',kernel_quantizer=quantized_bits(8, 1,alpha=1), bias_quantizer=quantized_bits(8, 1,alpha=1))(x)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eT-EH9bzWZ-1",
    "outputId": "aaba5949-69a3-4170-e699-e73d3a8bf10d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "195/195 [==============================] - 69s 325ms/step - loss: 90.4637 - accuracy: 0.4499 - f1: 0.3411\n",
      "Epoch 2/100\n",
      "195/195 [==============================] - 62s 318ms/step - loss: 48.2363 - accuracy: 0.5286 - f1: 0.4103\n",
      "Epoch 3/100\n",
      "195/195 [==============================] - 62s 316ms/step - loss: 31.2493 - accuracy: 0.5428 - f1: 0.4305\n",
      "Epoch 4/100\n",
      "195/195 [==============================] - 62s 316ms/step - loss: 20.7502 - accuracy: 0.5512 - f1: 0.4572\n",
      "Epoch 5/100\n",
      "195/195 [==============================] - 61s 315ms/step - loss: 13.9588 - accuracy: 0.5624 - f1: 0.4759\n",
      "Epoch 6/100\n",
      "195/195 [==============================] - 62s 317ms/step - loss: 9.4839 - accuracy: 0.5799 - f1: 0.5042\n",
      "Epoch 7/100\n",
      "195/195 [==============================] - 62s 316ms/step - loss: 6.5446 - accuracy: 0.5889 - f1: 0.5176\n",
      "Epoch 8/100\n",
      "195/195 [==============================] - 61s 315ms/step - loss: 4.5940 - accuracy: 0.6067 - f1: 0.5453\n",
      "Epoch 9/100\n",
      "195/195 [==============================] - 62s 319ms/step - loss: 3.3367 - accuracy: 0.6164 - f1: 0.5589\n",
      "Epoch 10/100\n",
      "195/195 [==============================] - 63s 323ms/step - loss: 2.5158 - accuracy: 0.6311 - f1: 0.5822\n",
      "Epoch 11/100\n",
      "195/195 [==============================] - 63s 321ms/step - loss: 1.9992 - accuracy: 0.6471 - f1: 0.6055\n",
      "Epoch 12/100\n",
      "195/195 [==============================] - 63s 321ms/step - loss: 1.6785 - accuracy: 0.6573 - f1: 0.6226\n",
      "Epoch 13/100\n",
      "195/195 [==============================] - 63s 321ms/step - loss: 1.4787 - accuracy: 0.6712 - f1: 0.6380\n",
      "Epoch 14/100\n",
      "195/195 [==============================] - 62s 316ms/step - loss: 1.3655 - accuracy: 0.6824 - f1: 0.6537\n",
      "Epoch 15/100\n",
      "195/195 [==============================] - 61s 313ms/step - loss: 1.2927 - accuracy: 0.6998 - f1: 0.6743\n",
      "Epoch 16/100\n",
      "195/195 [==============================] - 61s 313ms/step - loss: 1.2539 - accuracy: 0.7101 - f1: 0.6902\n",
      "Epoch 17/100\n",
      "195/195 [==============================] - 61s 313ms/step - loss: 1.2337 - accuracy: 0.7233 - f1: 0.7051\n",
      "Epoch 18/100\n",
      "195/195 [==============================] - 61s 313ms/step - loss: 1.2329 - accuracy: 0.7347 - f1: 0.7181\n",
      "Epoch 19/100\n",
      "195/195 [==============================] - 61s 313ms/step - loss: 1.2134 - accuracy: 0.7439 - f1: 0.7298\n",
      "Epoch 20/100\n",
      "195/195 [==============================] - 61s 313ms/step - loss: 1.2146 - accuracy: 0.7512 - f1: 0.7385\n",
      "Epoch 21/100\n",
      "195/195 [==============================] - 61s 313ms/step - loss: 1.2152 - accuracy: 0.7570 - f1: 0.7445\n",
      "Epoch 22/100\n",
      "195/195 [==============================] - 61s 313ms/step - loss: 1.2134 - accuracy: 0.7628 - f1: 0.7503\n",
      "Epoch 23/100\n",
      "195/195 [==============================] - 61s 313ms/step - loss: 1.1984 - accuracy: 0.7728 - f1: 0.7629\n",
      "Epoch 24/100\n",
      "195/195 [==============================] - 61s 313ms/step - loss: 1.2076 - accuracy: 0.7760 - f1: 0.7662\n",
      "Epoch 25/100\n",
      "195/195 [==============================] - 61s 313ms/step - loss: 1.2049 - accuracy: 0.7789 - f1: 0.7694\n",
      "Epoch 26/100\n",
      "195/195 [==============================] - 61s 313ms/step - loss: 1.2023 - accuracy: 0.7882 - f1: 0.7811\n",
      "Epoch 27/100\n",
      "195/195 [==============================] - 61s 313ms/step - loss: 1.1953 - accuracy: 0.7905 - f1: 0.7820\n",
      "Epoch 28/100\n",
      "195/195 [==============================] - 61s 313ms/step - loss: 1.1910 - accuracy: 0.7949 - f1: 0.7870\n",
      "Epoch 29/100\n",
      "195/195 [==============================] - 1719s 9s/step - loss: 1.1842 - accuracy: 0.7960 - f1: 0.7881\n",
      "Epoch 30/100\n",
      "195/195 [==============================] - 63s 323ms/step - loss: 1.1797 - accuracy: 0.8014 - f1: 0.7935\n",
      "Epoch 31/100\n",
      "195/195 [==============================] - 63s 325ms/step - loss: 1.1769 - accuracy: 0.8029 - f1: 0.7975\n",
      "Epoch 32/100\n",
      "195/195 [==============================] - 63s 322ms/step - loss: 1.1790 - accuracy: 0.8045 - f1: 0.7991\n",
      "Epoch 33/100\n",
      "195/195 [==============================] - 62s 317ms/step - loss: 1.1645 - accuracy: 0.8100 - f1: 0.8042\n",
      "Epoch 34/100\n",
      "195/195 [==============================] - 63s 323ms/step - loss: 1.1519 - accuracy: 0.8134 - f1: 0.8078\n",
      "Epoch 35/100\n",
      "195/195 [==============================] - 62s 320ms/step - loss: 1.1462 - accuracy: 0.8164 - f1: 0.8123\n",
      "Epoch 36/100\n",
      "195/195 [==============================] - 63s 321ms/step - loss: 1.1352 - accuracy: 0.8174 - f1: 0.8128\n",
      "Epoch 37/100\n",
      "195/195 [==============================] - 63s 321ms/step - loss: 1.1094 - accuracy: 0.8259 - f1: 0.8220\n",
      "Epoch 38/100\n",
      "195/195 [==============================] - 63s 322ms/step - loss: 1.1206 - accuracy: 0.8279 - f1: 0.8246\n",
      "Epoch 39/100\n",
      "195/195 [==============================] - 63s 321ms/step - loss: 1.1176 - accuracy: 0.8289 - f1: 0.8256\n",
      "Epoch 40/100\n",
      "195/195 [==============================] - 63s 323ms/step - loss: 1.1090 - accuracy: 0.8275 - f1: 0.8242\n",
      "Epoch 41/100\n",
      "195/195 [==============================] - 62s 318ms/step - loss: 1.0706 - accuracy: 0.8390 - f1: 0.8354\n",
      "Epoch 42/100\n",
      "195/195 [==============================] - 61s 314ms/step - loss: 1.0773 - accuracy: 0.8389 - f1: 0.8353\n",
      "Epoch 43/100\n",
      "195/195 [==============================] - 61s 314ms/step - loss: 1.0759 - accuracy: 0.8373 - f1: 0.8343\n",
      "Epoch 44/100\n",
      "195/195 [==============================] - 61s 314ms/step - loss: 1.0551 - accuracy: 0.8452 - f1: 0.8413\n",
      "Epoch 45/100\n",
      "195/195 [==============================] - 62s 319ms/step - loss: 1.0666 - accuracy: 0.8405 - f1: 0.8382\n",
      "Epoch 46/100\n",
      "195/195 [==============================] - 63s 324ms/step - loss: 1.0420 - accuracy: 0.8481 - f1: 0.8453\n",
      "Epoch 47/100\n",
      "195/195 [==============================] - 63s 323ms/step - loss: 1.0213 - accuracy: 0.8539 - f1: 0.8511\n",
      "Epoch 48/100\n",
      "195/195 [==============================] - 63s 323ms/step - loss: 1.0147 - accuracy: 0.8554 - f1: 0.8530\n",
      "Epoch 49/100\n",
      "195/195 [==============================] - 64s 326ms/step - loss: 1.0108 - accuracy: 0.8570 - f1: 0.8547\n",
      "Epoch 50/100\n",
      "195/195 [==============================] - 63s 325ms/step - loss: 1.0088 - accuracy: 0.8582 - f1: 0.8557\n",
      "Epoch 51/100\n",
      "195/195 [==============================] - 63s 325ms/step - loss: 1.0039 - accuracy: 0.8551 - f1: 0.8531\n",
      "Epoch 52/100\n",
      "195/195 [==============================] - 64s 326ms/step - loss: 0.9957 - accuracy: 0.8603 - f1: 0.8584\n",
      "Epoch 53/100\n",
      "195/195 [==============================] - 64s 330ms/step - loss: 0.9933 - accuracy: 0.8599 - f1: 0.8576\n",
      "Epoch 54/100\n",
      "195/195 [==============================] - 64s 330ms/step - loss: 0.9610 - accuracy: 0.8670 - f1: 0.8655\n",
      "Epoch 55/100\n",
      "195/195 [==============================] - 64s 329ms/step - loss: 0.9650 - accuracy: 0.8682 - f1: 0.8667\n",
      "Epoch 56/100\n",
      "195/195 [==============================] - 65s 331ms/step - loss: 0.9706 - accuracy: 0.8669 - f1: 0.8653\n",
      "Epoch 57/100\n",
      "195/195 [==============================] - 64s 331ms/step - loss: 0.9427 - accuracy: 0.8720 - f1: 0.8705\n",
      "Epoch 58/100\n",
      "195/195 [==============================] - 65s 331ms/step - loss: 0.9441 - accuracy: 0.8721 - f1: 0.8710\n",
      "Epoch 59/100\n",
      "195/195 [==============================] - 64s 330ms/step - loss: 0.9395 - accuracy: 0.8757 - f1: 0.8743\n",
      "Epoch 60/100\n",
      "195/195 [==============================] - 63s 322ms/step - loss: 0.9530 - accuracy: 0.8723 - f1: 0.8710\n",
      "Epoch 61/100\n",
      "195/195 [==============================] - 62s 319ms/step - loss: 0.9265 - accuracy: 0.8762 - f1: 0.8746\n",
      "Epoch 62/100\n",
      "195/195 [==============================] - 62s 319ms/step - loss: 0.9290 - accuracy: 0.8781 - f1: 0.8759\n",
      "Epoch 63/100\n",
      "195/195 [==============================] - 61s 313ms/step - loss: 0.9211 - accuracy: 0.8791 - f1: 0.8777\n",
      "Epoch 64/100\n",
      "195/195 [==============================] - 60s 309ms/step - loss: 0.9124 - accuracy: 0.8832 - f1: 0.8813\n",
      "Epoch 65/100\n",
      "195/195 [==============================] - 60s 308ms/step - loss: 0.9032 - accuracy: 0.8847 - f1: 0.8841\n",
      "Epoch 66/100\n",
      "195/195 [==============================] - 60s 309ms/step - loss: 0.8958 - accuracy: 0.8870 - f1: 0.8861\n",
      "Epoch 67/100\n",
      "195/195 [==============================] - 60s 309ms/step - loss: 0.9021 - accuracy: 0.8849 - f1: 0.8843\n",
      "Epoch 68/100\n",
      "195/195 [==============================] - 60s 309ms/step - loss: 0.8995 - accuracy: 0.8858 - f1: 0.8849\n",
      "Epoch 69/100\n",
      "195/195 [==============================] - 60s 308ms/step - loss: 0.9006 - accuracy: 0.8867 - f1: 0.8865\n",
      "Epoch 70/100\n",
      "195/195 [==============================] - 60s 309ms/step - loss: 0.8821 - accuracy: 0.8898 - f1: 0.8889\n",
      "Epoch 71/100\n",
      "195/195 [==============================] - 60s 309ms/step - loss: 0.8603 - accuracy: 0.8927 - f1: 0.8921\n",
      "Epoch 72/100\n",
      "195/195 [==============================] - 60s 309ms/step - loss: 0.8591 - accuracy: 0.8947 - f1: 0.8940\n",
      "Epoch 73/100\n",
      "195/195 [==============================] - 60s 308ms/step - loss: 0.8677 - accuracy: 0.8898 - f1: 0.8894\n",
      "Epoch 74/100\n",
      "195/195 [==============================] - 60s 308ms/step - loss: 0.8608 - accuracy: 0.8905 - f1: 0.8900\n",
      "Epoch 75/100\n",
      "195/195 [==============================] - 60s 308ms/step - loss: 0.8374 - accuracy: 0.8987 - f1: 0.8982\n",
      "Epoch 76/100\n",
      "195/195 [==============================] - 60s 308ms/step - loss: 0.8583 - accuracy: 0.8953 - f1: 0.8950\n",
      "Epoch 77/100\n",
      "195/195 [==============================] - 60s 308ms/step - loss: 0.8459 - accuracy: 0.8963 - f1: 0.8966\n",
      "Epoch 78/100\n",
      "195/195 [==============================] - 2866s 15s/step - loss: 0.8453 - accuracy: 0.8981 - f1: 0.8977\n",
      "Epoch 79/100\n",
      "195/195 [==============================] - 60s 310ms/step - loss: 0.8684 - accuracy: 0.8952 - f1: 0.8947\n",
      "Epoch 80/100\n",
      "195/195 [==============================] - 61s 314ms/step - loss: 0.8294 - accuracy: 0.9025 - f1: 0.9022\n",
      "Epoch 81/100\n",
      "195/195 [==============================] - 62s 316ms/step - loss: 0.8325 - accuracy: 0.9007 - f1: 0.9007\n",
      "Epoch 82/100\n",
      "195/195 [==============================] - 62s 317ms/step - loss: 0.8283 - accuracy: 0.9027 - f1: 0.9022\n",
      "Epoch 83/100\n",
      "195/195 [==============================] - 61s 315ms/step - loss: 0.8274 - accuracy: 0.9008 - f1: 0.9006\n",
      "Epoch 84/100\n",
      "195/195 [==============================] - 62s 316ms/step - loss: 0.8386 - accuracy: 0.9010 - f1: 0.9002\n",
      "Epoch 85/100\n",
      "195/195 [==============================] - 62s 316ms/step - loss: 0.8189 - accuracy: 0.9051 - f1: 0.9047\n",
      "Epoch 86/100\n",
      "195/195 [==============================] - 62s 315ms/step - loss: 0.8268 - accuracy: 0.9022 - f1: 0.9020\n",
      "Epoch 87/100\n",
      "195/195 [==============================] - 61s 315ms/step - loss: 0.8092 - accuracy: 0.9051 - f1: 0.9047\n",
      "Epoch 88/100\n",
      "195/195 [==============================] - 62s 316ms/step - loss: 0.8233 - accuracy: 0.9067 - f1: 0.9060\n",
      "Epoch 89/100\n",
      "195/195 [==============================] - 62s 316ms/step - loss: 0.8037 - accuracy: 0.9071 - f1: 0.9062\n",
      "Epoch 90/100\n",
      "195/195 [==============================] - 62s 316ms/step - loss: 0.7973 - accuracy: 0.9100 - f1: 0.9094\n",
      "Epoch 91/100\n",
      "195/195 [==============================] - 61s 313ms/step - loss: 0.8121 - accuracy: 0.9061 - f1: 0.9057\n",
      "Epoch 92/100\n",
      "195/195 [==============================] - 61s 312ms/step - loss: 0.8034 - accuracy: 0.9091 - f1: 0.9086\n",
      "Epoch 93/100\n",
      "195/195 [==============================] - 61s 313ms/step - loss: 0.7898 - accuracy: 0.9110 - f1: 0.9107\n",
      "Epoch 94/100\n",
      "195/195 [==============================] - 62s 318ms/step - loss: 0.8019 - accuracy: 0.9070 - f1: 0.9069\n",
      "Epoch 95/100\n",
      "195/195 [==============================] - 62s 316ms/step - loss: 0.7936 - accuracy: 0.9115 - f1: 0.9115\n",
      "Epoch 96/100\n",
      "195/195 [==============================] - 62s 316ms/step - loss: 0.7778 - accuracy: 0.9139 - f1: 0.9131\n",
      "Epoch 97/100\n",
      "195/195 [==============================] - 62s 316ms/step - loss: 0.7839 - accuracy: 0.9148 - f1: 0.9140\n",
      "Epoch 98/100\n",
      "195/195 [==============================] - 62s 316ms/step - loss: 0.7783 - accuracy: 0.9148 - f1: 0.9147\n",
      "Epoch 99/100\n",
      "195/195 [==============================] - 62s 316ms/step - loss: 0.7800 - accuracy: 0.9150 - f1: 0.9142\n",
      "Epoch 100/100\n",
      "195/195 [==============================] - 62s 315ms/step - loss: 0.7784 - accuracy: 0.9158 - f1: 0.9150\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(base_dir+\"models/inceptionV3_fp8.keras\")\n",
    "model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy',f1])\n",
    "history=model.fit(x_train,y_train,batch_size=256,epochs=100,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# Plot F1\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history.history['f1'], label='Training f1')\n",
    "plt.plot(history.history['val_f1'], label='Validation f1')\n",
    "plt.title('Training and Validation f1')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('f1')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGNi79yHryWC",
    "outputId": "0cb71480-52ba-4d6f-b0fb-fb6c7f4f01a9"
   },
   "outputs": [],
   "source": [
    "del x_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKgsFxu7sOLO",
    "outputId": "3600ddf8-285c-430d-d76c-89b73afe3c12"
   },
   "outputs": [],
   "source": [
    "# model=load_model(base_dir+\"models/inceptionV3_fp8.keras\",custom_objects={'f1':f1})\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebVBf3mIWZ-2",
    "outputId": "c9bffd2a-1bc7-47b0-d3ff-97197b5597b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 5s 96ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(x_test,batch_size=256)\n",
    "y_pred = to_categorical(np.argmax(y_pred, axis=1), 4).astype(int)\n",
    "y_pred=np.argmax(y_pred,axis=1)\n",
    "y_test=np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        WAKE       0.90      0.62      0.73      2810\n",
      "         REM       0.88      0.60      0.72      1809\n",
      "       LIGHT       0.73      0.93      0.82      6233\n",
      "        DEEP       0.77      0.65      0.71      1598\n",
      "\n",
      "    accuracy                           0.78     12450\n",
      "   macro avg       0.82      0.70      0.74     12450\n",
      "weighted avg       0.80      0.78      0.77     12450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred,target_names=['WAKE','REM','LIGHT','DEEP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "JWLTBad8WZ-3",
    "outputId": "aa4b506d-3051-4f63-9c7a-4b450cf95427"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['WAKE','REM','LIGHT','DEEP'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zazaz\\anaconda3\\envs\\tf\\lib\\site-packages\\qkeras\\qtools\\qgraph.py:189: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zazaz\\anaconda3\\envs\\tf\\lib\\site-packages\\qkeras\\qtools\\qgraph.py:189: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"source_quantizers\": [\n",
      "        {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        }\n",
      "    ],\n",
      "    \"batch_normalization\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                [\n",
      "                    null,\n",
      "                    3840,\n",
      "                    1\n",
      "                ]\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_conv1d\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                1,\n",
      "                32\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 32\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                3838,\n",
      "                32\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 368448\n",
      "    },\n",
      "    \"q_conv1d_1\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                32,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 64\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                3836,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 23568384\n",
      "    },\n",
      "    \"max_pooling1d\": {\n",
      "        \"layer_type\": \"MaxPooling1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 245504\n",
      "    },\n",
      "    \"q_conv1d_3\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                64,\n",
      "                96\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 96\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                96\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 11778048\n",
      "    },\n",
      "    \"q_conv1d_5\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                64,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 16\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 1963008\n",
      "    },\n",
      "    \"max_pooling1d_1\": {\n",
      "        \"layer_type\": \"MaxPooling1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 122688\n",
      "    },\n",
      "    \"q_conv1d_2\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                64,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 64\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 7852032\n",
      "    },\n",
      "    \"q_conv1d_4\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                96,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 128\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 70668288\n",
      "    },\n",
      "    \"q_conv1d_6\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                5,\n",
      "                16,\n",
      "                32\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 32\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                32\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 4907520\n",
      "    },\n",
      "    \"q_conv1d_7\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                64,\n",
      "                32\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 32\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                32\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 3926016\n",
      "    },\n",
      "    \"concatenate\": {\n",
      "        \"layer_type\": \"Concatenate\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"Concatenate_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 245376\n",
      "    },\n",
      "    \"q_conv1d_9\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                256,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 128\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 62816256\n",
      "    },\n",
      "    \"q_conv1d_11\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                256,\n",
      "                32\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 32\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                32\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 15704064\n",
      "    },\n",
      "    \"max_pooling1d_2\": {\n",
      "        \"layer_type\": \"MaxPooling1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 490752\n",
      "    },\n",
      "    \"q_conv1d_8\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                256,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 128\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 62816256\n",
      "    },\n",
      "    \"q_conv1d_10\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                128,\n",
      "                192\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 192\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                192\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 141336576\n",
      "    },\n",
      "    \"q_conv1d_12\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                5,\n",
      "                32,\n",
      "                96\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 96\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                96\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 29445120\n",
      "    },\n",
      "    \"q_conv1d_13\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                256,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 64\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 31408128\n",
      "    },\n",
      "    \"concatenate_1\": {\n",
      "        \"layer_type\": \"Concatenate\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"Concatenate_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                480\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 368064\n",
      "    },\n",
      "    \"flatten\": {\n",
      "        \"layer_type\": \"Flatten\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                920160\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 920160\n",
      "    },\n",
      "    \"q_dense\": {\n",
      "        \"layer_type\": \"QDense\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": [\n",
      "                920160,\n",
      "                4\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 2,\n",
      "            \"is_signed\": true,\n",
      "            \"shape\": 4\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                4\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 3680640\n",
      "    }\n",
      "}\n",
      "{'batch_normalization': {'energy': {'inputs': 7303.28,\n",
      "                                    'op_cost': 28416.0,\n",
      "                                    'outputs': 3.8,\n",
      "                                    'parameters': 15.22},\n",
      "                         'total': 15.22},\n",
      " 'concatenate': {'energy': {'inputs': 933358.73,\n",
      "                            'op_cost': 0.0,\n",
      "                            'outputs': 933358.73,\n",
      "                            'parameters': 0.0},\n",
      "                 'total': 933358.73},\n",
      " 'concatenate_1': {'energy': {'inputs': 1750047.62,\n",
      "                              'op_cost': 0.0,\n",
      "                              'outputs': 1750047.62,\n",
      "                              'parameters': 0.0},\n",
      "                   'total': 1750047.62},\n",
      " 'flatten': {'energy': {'inputs': 1750047.62,\n",
      "                        'op_cost': 0.0,\n",
      "                        'outputs': 1750047.62,\n",
      "                        'parameters': 0.0},\n",
      "             'total': 1750047.62},\n",
      " 'max_pooling1d': {'energy': {'inputs': 466922.81,\n",
      "                              'op_cost': 0.0,\n",
      "                              'outputs': 233339.68,\n",
      "                              'parameters': 0.0},\n",
      "                   'total': 466922.81},\n",
      " 'max_pooling1d_1': {'energy': {'inputs': 233339.68,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 233339.68,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 233339.68},\n",
      " 'max_pooling1d_2': {'energy': {'inputs': 933358.73,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 933358.73,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 933358.73},\n",
      " 'q_conv1d': {'energy': {'inputs': 7303.28,\n",
      "                         'op_cost': 1694860.8,\n",
      "                         'outputs': 233583.13,\n",
      "                         'parameters': 60.86},\n",
      "              'total': 1702224.94},\n",
      " 'q_conv1d_1': {'energy': {'inputs': 233583.13,\n",
      "                           'op_cost': 108414566.4,\n",
      "                           'outputs': 466922.81,\n",
      "                           'parameters': 2951.74},\n",
      "                'total': 108651101.27000001},\n",
      " 'q_conv1d_10': {'energy': {'inputs': 466679.37,\n",
      "                            'op_cost': 650148249.6,\n",
      "                            'outputs': 700019.05,\n",
      "                            'parameters': 35147.02},\n",
      "                 'total': 650650075.99},\n",
      " 'q_conv1d_11': {'energy': {'inputs': 933358.73,\n",
      "                            'op_cost': 72238694.4,\n",
      "                            'outputs': 116669.84,\n",
      "                            'parameters': 3910.3},\n",
      "                 'total': 73175963.43},\n",
      " 'q_conv1d_12': {'energy': {'inputs': 116669.84,\n",
      "                            'op_cost': 135447552.0,\n",
      "                            'outputs': 350009.52,\n",
      "                            'parameters': 7348.92},\n",
      "                 'total': 135571570.76},\n",
      " 'q_conv1d_13': {'energy': {'inputs': 933358.73,\n",
      "                            'op_cost': 144477388.8,\n",
      "                            'outputs': 233339.68,\n",
      "                            'parameters': 7820.59},\n",
      "                 'total': 145418568.12},\n",
      " 'q_conv1d_2': {'energy': {'inputs': 233339.68,\n",
      "                           'op_cost': 36119347.2,\n",
      "                           'outputs': 233339.68,\n",
      "                           'parameters': 1977.97},\n",
      "                'total': 36354664.85},\n",
      " 'q_conv1d_3': {'energy': {'inputs': 233339.68,\n",
      "                           'op_cost': 54179020.8,\n",
      "                           'outputs': 350009.52,\n",
      "                           'parameters': 2966.96},\n",
      "                'total': 54415327.44},\n",
      " 'q_conv1d_4': {'energy': {'inputs': 350009.52,\n",
      "                           'op_cost': 325074124.8,\n",
      "                           'outputs': 466679.37,\n",
      "                           'parameters': 17588.72},\n",
      "                'total': 325441723.04},\n",
      " 'q_conv1d_5': {'energy': {'inputs': 233339.68,\n",
      "                           'op_cost': 9029836.8,\n",
      "                           'outputs': 58334.92,\n",
      "                           'parameters': 494.49},\n",
      "                'total': 9263670.97},\n",
      " 'q_conv1d_6': {'energy': {'inputs': 58334.92,\n",
      "                           'op_cost': 22574592.0,\n",
      "                           'outputs': 116669.84,\n",
      "                           'parameters': 1232.43},\n",
      "                'total': 22634159.35},\n",
      " 'q_conv1d_7': {'energy': {'inputs': 233339.68,\n",
      "                           'op_cost': 18059673.6,\n",
      "                           'outputs': 116669.84,\n",
      "                           'parameters': 988.99},\n",
      "                'total': 18294002.270000003},\n",
      " 'q_conv1d_8': {'energy': {'inputs': 933358.73,\n",
      "                           'op_cost': 288954777.6,\n",
      "                           'outputs': 466679.37,\n",
      "                           'parameters': 15641.18},\n",
      "                'total': 289903777.51000005},\n",
      " 'q_conv1d_9': {'energy': {'inputs': 933358.73,\n",
      "                           'op_cost': 288954777.6,\n",
      "                           'outputs': 466679.37,\n",
      "                           'parameters': 15641.18},\n",
      "                'total': 289903777.51000005},\n",
      " 'q_dense': {'energy': {'inputs': 1750047.62,\n",
      "                        'op_cost': 16930944.0,\n",
      "                        'outputs': 7.61,\n",
      "                        'parameters': 1750051.42},\n",
      "             'total': 20431043.04}}\n",
      "\n",
      "Total energy: 2187.88 uJ\n",
      "{'batch_normalization': {'energy': {'inputs': 7303.28,\n",
      "                                    'op_cost': 28416.0,\n",
      "                                    'outputs': 3.8,\n",
      "                                    'parameters': 15.22},\n",
      "                         'total': 15.22},\n",
      " 'concatenate': {'energy': {'inputs': 933358.73,\n",
      "                            'op_cost': 0.0,\n",
      "                            'outputs': 933358.73,\n",
      "                            'parameters': 0.0},\n",
      "                 'total': 933358.73},\n",
      " 'concatenate_1': {'energy': {'inputs': 1750047.62,\n",
      "                              'op_cost': 0.0,\n",
      "                              'outputs': 1750047.62,\n",
      "                              'parameters': 0.0},\n",
      "                   'total': 1750047.62},\n",
      " 'flatten': {'energy': {'inputs': 1750047.62,\n",
      "                        'op_cost': 0.0,\n",
      "                        'outputs': 1750047.62,\n",
      "                        'parameters': 0.0},\n",
      "             'total': 1750047.62},\n",
      " 'max_pooling1d': {'energy': {'inputs': 466922.81,\n",
      "                              'op_cost': 0.0,\n",
      "                              'outputs': 233339.68,\n",
      "                              'parameters': 0.0},\n",
      "                   'total': 466922.81},\n",
      " 'max_pooling1d_1': {'energy': {'inputs': 233339.68,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 233339.68,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 233339.68},\n",
      " 'max_pooling1d_2': {'energy': {'inputs': 933358.73,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 933358.73,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 933358.73},\n",
      " 'q_conv1d': {'energy': {'inputs': 7303.28,\n",
      "                         'op_cost': 1694860.8,\n",
      "                         'outputs': 233583.13,\n",
      "                         'parameters': 60.86},\n",
      "              'total': 1702224.94},\n",
      " 'q_conv1d_1': {'energy': {'inputs': 233583.13,\n",
      "                           'op_cost': 108414566.4,\n",
      "                           'outputs': 466922.81,\n",
      "                           'parameters': 2951.74},\n",
      "                'total': 108651101.27000001},\n",
      " 'q_conv1d_10': {'energy': {'inputs': 466679.37,\n",
      "                            'op_cost': 650148249.6,\n",
      "                            'outputs': 700019.05,\n",
      "                            'parameters': 35147.02},\n",
      "                 'total': 650650075.99},\n",
      " 'q_conv1d_11': {'energy': {'inputs': 933358.73,\n",
      "                            'op_cost': 72238694.4,\n",
      "                            'outputs': 116669.84,\n",
      "                            'parameters': 3910.3},\n",
      "                 'total': 73175963.43},\n",
      " 'q_conv1d_12': {'energy': {'inputs': 116669.84,\n",
      "                            'op_cost': 135447552.0,\n",
      "                            'outputs': 350009.52,\n",
      "                            'parameters': 7348.92},\n",
      "                 'total': 135571570.76},\n",
      " 'q_conv1d_13': {'energy': {'inputs': 933358.73,\n",
      "                            'op_cost': 144477388.8,\n",
      "                            'outputs': 233339.68,\n",
      "                            'parameters': 7820.59},\n",
      "                 'total': 145418568.12},\n",
      " 'q_conv1d_2': {'energy': {'inputs': 233339.68,\n",
      "                           'op_cost': 36119347.2,\n",
      "                           'outputs': 233339.68,\n",
      "                           'parameters': 1977.97},\n",
      "                'total': 36354664.85},\n",
      " 'q_conv1d_3': {'energy': {'inputs': 233339.68,\n",
      "                           'op_cost': 54179020.8,\n",
      "                           'outputs': 350009.52,\n",
      "                           'parameters': 2966.96},\n",
      "                'total': 54415327.44},\n",
      " 'q_conv1d_4': {'energy': {'inputs': 350009.52,\n",
      "                           'op_cost': 325074124.8,\n",
      "                           'outputs': 466679.37,\n",
      "                           'parameters': 17588.72},\n",
      "                'total': 325441723.04},\n",
      " 'q_conv1d_5': {'energy': {'inputs': 233339.68,\n",
      "                           'op_cost': 9029836.8,\n",
      "                           'outputs': 58334.92,\n",
      "                           'parameters': 494.49},\n",
      "                'total': 9263670.97},\n",
      " 'q_conv1d_6': {'energy': {'inputs': 58334.92,\n",
      "                           'op_cost': 22574592.0,\n",
      "                           'outputs': 116669.84,\n",
      "                           'parameters': 1232.43},\n",
      "                'total': 22634159.35},\n",
      " 'q_conv1d_7': {'energy': {'inputs': 233339.68,\n",
      "                           'op_cost': 18059673.6,\n",
      "                           'outputs': 116669.84,\n",
      "                           'parameters': 988.99},\n",
      "                'total': 18294002.270000003},\n",
      " 'q_conv1d_8': {'energy': {'inputs': 933358.73,\n",
      "                           'op_cost': 288954777.6,\n",
      "                           'outputs': 466679.37,\n",
      "                           'parameters': 15641.18},\n",
      "                'total': 289903777.51000005},\n",
      " 'q_conv1d_9': {'energy': {'inputs': 933358.73,\n",
      "                           'op_cost': 288954777.6,\n",
      "                           'outputs': 466679.37,\n",
      "                           'parameters': 15641.18},\n",
      "                'total': 289903777.51000005},\n",
      " 'q_dense': {'energy': {'inputs': 1750047.62,\n",
      "                        'op_cost': 16930944.0,\n",
      "                        'outputs': 7.61,\n",
      "                        'parameters': 1750051.42},\n",
      "             'total': 20431043.04}}\n",
      "\n",
      "Total energy: 2187.88 uJ\n"
     ]
    }
   ],
   "source": [
    "q = run_qtools.QTools(\n",
    "    model,\n",
    "    # energy calculation using a given process\n",
    "    # \"horowitz\" refers to 45nm process published at\n",
    "    # M. Horowitz, \"1.1 Computing's energy problem (and what we can do about\n",
    "    # it), \"2014 IEEE International Solid-State Circuits Conference Digest of\n",
    "    # Technical Papers (ISSCC), San Francisco, CA, 2014, pp. 10-14, \n",
    "    # doi: 10.1109/ISSCC.2014.6757323.\n",
    "    \n",
    "    process=\"horowitz\",\n",
    "    # quantizers for model input\n",
    "    source_quantizers=[\"fp32\"],\n",
    "    \n",
    "    is_inference=True,\n",
    "    # whether model has been trained already, which is\n",
    "    # needed to compute tighter bounds for QBatchNormalization Power estimation.\n",
    "    \n",
    "    # weights_path=None,\n",
    "    # absolute path (including filename) of the model weights\n",
    "    \n",
    "    \n",
    "    keras_quantizer=\"fp32\",\n",
    "    # keras_quantizer to quantize weight/bias in un-quantized keras layers\n",
    "    \n",
    "    keras_accumulator=\"fp32\",\n",
    "    # keras_quantizer to quantize MAC in un-quantized keras layers\n",
    "    \n",
    "    for_reference=False,\n",
    "    # whether calculate baseline energy\n",
    ")\n",
    "q.qtools_stats_print()\n",
    "\n",
    "# caculate energy of the derived data type map.\n",
    "energy_dict = q.pe(\n",
    "    # whether to store parameters in dram, sram, or fixed\n",
    "    weights_on_memory=\"sram\",\n",
    "    # store activations in dram or sram\n",
    "    activations_on_memory=\"sram\",\n",
    "    # minimum sram size in number of bits\n",
    "    min_sram_size=8*16*1024*1024,\n",
    "    # whether load data from dram to sram (consider sram as a cache\n",
    "    # for dram. If false, we will assume data will be already in SRAM\n",
    "    rd_wr_on_io=False)\n",
    "\n",
    "# get stats of energy distribution in each layer\n",
    "energy_profile = q.extract_energy_profile(qtools_settings.cfg.include_energy, energy_dict)\n",
    "# extract sum of energy of each layer according to the rule specified in\n",
    "# qtools_settings.cfg.include_energy\n",
    "total_energy = q.extract_energy_sum(qtools_settings.cfg.include_energy, energy_dict)\n",
    "\n",
    "pprint.pprint(energy_profile)\n",
    "print()\n",
    "\n",
    "print(\"Total energy: {:.2f} uJ\".format(total_energy / 1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"source_quantizers\": [\n",
      "        {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        }\n",
      "    ],\n",
      "    \"batch_normalization\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                [\n",
      "                    null,\n",
      "                    3840,\n",
      "                    1\n",
      "                ]\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"q_conv1d\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                1,\n",
      "                32\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 32\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                3838,\n",
      "                32\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 368448\n",
      "    },\n",
      "    \"q_conv1d_1\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                32,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 64\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                3836,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 23568384\n",
      "    },\n",
      "    \"max_pooling1d\": {\n",
      "        \"layer_type\": \"MaxPooling1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 245504\n",
      "    },\n",
      "    \"q_conv1d_3\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                64,\n",
      "                96\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 96\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                96\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 11778048\n",
      "    },\n",
      "    \"q_conv1d_5\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                64,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 16\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 1963008\n",
      "    },\n",
      "    \"max_pooling1d_1\": {\n",
      "        \"layer_type\": \"MaxPooling1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 122688\n",
      "    },\n",
      "    \"q_conv1d_2\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                64,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 64\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 7852032\n",
      "    },\n",
      "    \"q_conv1d_4\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                96,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 128\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 70668288\n",
      "    },\n",
      "    \"q_conv1d_6\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                5,\n",
      "                16,\n",
      "                32\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 32\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                32\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 4907520\n",
      "    },\n",
      "    \"q_conv1d_7\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                64,\n",
      "                32\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 32\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                32\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 3926016\n",
      "    },\n",
      "    \"concatenate\": {\n",
      "        \"layer_type\": \"Concatenate\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"Concatenate_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 245376\n",
      "    },\n",
      "    \"q_conv1d_9\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                256,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 128\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 62816256\n",
      "    },\n",
      "    \"q_conv1d_11\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                256,\n",
      "                32\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 32\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                32\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 15704064\n",
      "    },\n",
      "    \"max_pooling1d_2\": {\n",
      "        \"layer_type\": \"MaxPooling1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                256\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 490752\n",
      "    },\n",
      "    \"q_conv1d_8\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                256,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 128\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 62816256\n",
      "    },\n",
      "    \"q_conv1d_10\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                128,\n",
      "                192\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 192\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                192\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 141336576\n",
      "    },\n",
      "    \"q_conv1d_12\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                5,\n",
      "                32,\n",
      "                96\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 96\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                96\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 29445120\n",
      "    },\n",
      "    \"q_conv1d_13\": {\n",
      "        \"layer_type\": \"QConv1D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                1,\n",
      "                256,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 64\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 31408128\n",
      "    },\n",
      "    \"concatenate_1\": {\n",
      "        \"layer_type\": \"Concatenate\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            },\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"Concatenate_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1917,\n",
      "                480\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 368064\n",
      "    },\n",
      "    \"flatten\": {\n",
      "        \"layer_type\": \"Flatten\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                920160\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 920160\n",
      "    },\n",
      "    \"q_dense\": {\n",
      "        \"layer_type\": \"QDense\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                920160,\n",
      "                4\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 4\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                4\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 3680640\n",
      "    }\n",
      "}\n",
      "{'batch_normalization': {'energy': {'inputs': 7303.28,\n",
      "                                    'op_cost': 28416.0,\n",
      "                                    'outputs': 3.8,\n",
      "                                    'parameters': 15.22},\n",
      "                         'total': 15.22},\n",
      " 'concatenate': {'energy': {'inputs': 933358.73,\n",
      "                            'op_cost': 0.0,\n",
      "                            'outputs': 933358.73,\n",
      "                            'parameters': 0.0},\n",
      "                 'total': 933358.73},\n",
      " 'concatenate_1': {'energy': {'inputs': 1750047.62,\n",
      "                              'op_cost': 0.0,\n",
      "                              'outputs': 1750047.62,\n",
      "                              'parameters': 0.0},\n",
      "                   'total': 1750047.62},\n",
      " 'flatten': {'energy': {'inputs': 1750047.62,\n",
      "                        'op_cost': 0.0,\n",
      "                        'outputs': 1750047.62,\n",
      "                        'parameters': 0.0},\n",
      "             'total': 1750047.62},\n",
      " 'max_pooling1d': {'energy': {'inputs': 466922.81,\n",
      "                              'op_cost': 0.0,\n",
      "                              'outputs': 233339.68,\n",
      "                              'parameters': 0.0},\n",
      "                   'total': 466922.81},\n",
      " 'max_pooling1d_1': {'energy': {'inputs': 233339.68,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 233339.68,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 233339.68},\n",
      " 'max_pooling1d_2': {'energy': {'inputs': 933358.73,\n",
      "                                'op_cost': 0.0,\n",
      "                                'outputs': 933358.73,\n",
      "                                'parameters': 0.0},\n",
      "                     'total': 933358.73},\n",
      " 'q_conv1d': {'energy': {'inputs': 7303.28,\n",
      "                         'op_cost': 1694860.8,\n",
      "                         'outputs': 233583.13,\n",
      "                         'parameters': 243.44},\n",
      "              'total': 1702407.52},\n",
      " 'q_conv1d_1': {'energy': {'inputs': 233583.13,\n",
      "                           'op_cost': 108414566.4,\n",
      "                           'outputs': 466922.81,\n",
      "                           'parameters': 11806.96},\n",
      "                'total': 108659956.49000001},\n",
      " 'q_conv1d_10': {'energy': {'inputs': 466679.37,\n",
      "                            'op_cost': 650148249.6,\n",
      "                            'outputs': 700019.05,\n",
      "                            'parameters': 140588.07},\n",
      "                 'total': 650755517.0400001},\n",
      " 'q_conv1d_11': {'energy': {'inputs': 933358.73,\n",
      "                            'op_cost': 72238694.4,\n",
      "                            'outputs': 116669.84,\n",
      "                            'parameters': 15641.18},\n",
      "                 'total': 73187694.31},\n",
      " 'q_conv1d_12': {'energy': {'inputs': 116669.84,\n",
      "                            'op_cost': 135447552.0,\n",
      "                            'outputs': 350009.52,\n",
      "                            'parameters': 29395.69},\n",
      "                 'total': 135593617.53},\n",
      " 'q_conv1d_13': {'energy': {'inputs': 933358.73,\n",
      "                            'op_cost': 144477388.8,\n",
      "                            'outputs': 233339.68,\n",
      "                            'parameters': 31282.37},\n",
      "                 'total': 145442029.9},\n",
      " 'q_conv1d_2': {'energy': {'inputs': 233339.68,\n",
      "                           'op_cost': 36119347.2,\n",
      "                           'outputs': 233339.68,\n",
      "                           'parameters': 7911.88},\n",
      "                'total': 36360598.760000005},\n",
      " 'q_conv1d_3': {'energy': {'inputs': 233339.68,\n",
      "                           'op_cost': 54179020.8,\n",
      "                           'outputs': 350009.52,\n",
      "                           'parameters': 11867.82},\n",
      "                'total': 54424228.3},\n",
      " 'q_conv1d_4': {'energy': {'inputs': 350009.52,\n",
      "                           'op_cost': 325074124.8,\n",
      "                           'outputs': 466679.37,\n",
      "                           'parameters': 70354.9},\n",
      "                'total': 325494489.22},\n",
      " 'q_conv1d_5': {'energy': {'inputs': 233339.68,\n",
      "                           'op_cost': 9029836.8,\n",
      "                           'outputs': 58334.92,\n",
      "                           'parameters': 1977.97},\n",
      "                'total': 9265154.450000001},\n",
      " 'q_conv1d_6': {'energy': {'inputs': 58334.92,\n",
      "                           'op_cost': 22574592.0,\n",
      "                           'outputs': 116669.84,\n",
      "                           'parameters': 4929.71},\n",
      "                'total': 22637856.63},\n",
      " 'q_conv1d_7': {'energy': {'inputs': 233339.68,\n",
      "                           'op_cost': 18059673.6,\n",
      "                           'outputs': 116669.84,\n",
      "                           'parameters': 3955.94},\n",
      "                'total': 18296969.220000003},\n",
      " 'q_conv1d_8': {'energy': {'inputs': 933358.73,\n",
      "                           'op_cost': 288954777.6,\n",
      "                           'outputs': 466679.37,\n",
      "                           'parameters': 62564.73},\n",
      "                'total': 289950701.06},\n",
      " 'q_conv1d_9': {'energy': {'inputs': 933358.73,\n",
      "                           'op_cost': 288954777.6,\n",
      "                           'outputs': 466679.37,\n",
      "                           'parameters': 62564.73},\n",
      "                'total': 289950701.06},\n",
      " 'q_dense': {'energy': {'inputs': 1750047.62,\n",
      "                        'op_cost': 16930944.0,\n",
      "                        'outputs': 7.61,\n",
      "                        'parameters': 7000198.09},\n",
      "             'total': 25681189.71}}\n",
      "\n",
      "Total energy: 2193.47 uJ\n"
     ]
    }
   ],
   "source": [
    "q = run_qtools.QTools(\n",
    "    model,\n",
    "    # energy calculation using a given process\n",
    "    # \"horowitz\" refers to 45nm process published at\n",
    "    # M. Horowitz, \"1.1 Computing's energy problem (and what we can do about\n",
    "    # it), \"2014 IEEE International Solid-State Circuits Conference Digest of\n",
    "    # Technical Papers (ISSCC), San Francisco, CA, 2014, pp. 10-14, \n",
    "    # doi: 10.1109/ISSCC.2014.6757323.\n",
    "    \n",
    "    process=\"horowitz\",\n",
    "    # quantizers for model input\n",
    "    source_quantizers=[\"fp32\"],\n",
    "    \n",
    "    is_inference=True,\n",
    "    # whether model has been trained already, which is\n",
    "    # needed to compute tighter bounds for QBatchNormalization Power estimation.\n",
    "    \n",
    "    # weights_path=None,\n",
    "    # absolute path (including filename) of the model weights\n",
    "    \n",
    "    \n",
    "    keras_quantizer=\"fp32\",\n",
    "    # keras_quantizer to quantize weight/bias in un-quantized keras layers\n",
    "    \n",
    "    keras_accumulator=\"fp32\",\n",
    "    # keras_quantizer to quantize MAC in un-quantized keras layers\n",
    "    \n",
    "    for_reference=True,\n",
    "    # whether calculate baseline energy\n",
    ")\n",
    "q.qtools_stats_print()\n",
    "\n",
    "# caculate energy of the derived data type map.\n",
    "energy_dict = q.pe(\n",
    "    # whether to store parameters in dram, sram, or fixed\n",
    "    weights_on_memory=\"sram\",\n",
    "    # store activations in dram or sram\n",
    "    activations_on_memory=\"sram\",\n",
    "    # minimum sram size in number of bits\n",
    "    min_sram_size=8*16*1024*1024,\n",
    "    # whether load data from dram to sram (consider sram as a cache\n",
    "    # for dram. If false, we will assume data will be already in SRAM\n",
    "    rd_wr_on_io=False)\n",
    "\n",
    "# get stats of energy distribution in each layer\n",
    "energy_profile = q.extract_energy_profile(qtools_settings.cfg.include_energy, energy_dict)\n",
    "# extract sum of energy of each layer according to the rule specified in\n",
    "# qtools_settings.cfg.include_energy\n",
    "total_energy = q.extract_energy_sum(qtools_settings.cfg.include_energy, energy_dict)\n",
    "\n",
    "pprint.pprint(energy_profile)\n",
    "print()\n",
    "\n",
    "print(\"Total energy: {:.2f} uJ\".format(total_energy / 1000000.0))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuClass": "premium",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
