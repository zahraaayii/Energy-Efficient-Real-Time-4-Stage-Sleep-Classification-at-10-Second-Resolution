{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R76a0E12YaBO",
    "outputId": "663d077e-44cb-4f67-bb8d-a97a2fdc0615"
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-optimize\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# base_dir='/content/drive/MyDrive/ucd/'\n",
    "base_dir='../../../folders/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CTnnrsLxYaBR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.utils.fixes import loguniform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFE\n",
    "np.int = np.int_\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ucddb002', 'ucddb003', 'ucddb005', 'ucddb006', 'ucddb007', 'ucddb008', 'ucddb009', 'ucddb010', 'ucddb011', 'ucddb012', 'ucddb013', 'ucddb014', 'ucddb015', 'ucddb017', 'ucddb018', 'ucddb019', 'ucddb020', 'ucddb021', 'ucddb022', 'ucddb023', 'ucddb024', 'ucddb025', 'ucddb026', 'ucddb027', 'ucddb028']\n"
     ]
    }
   ],
   "source": [
    "data_base=[f'ucddb{i:003d}' for i in range(2, 29)]\n",
    "data_base.remove('ucddb004')\n",
    "data_base.remove('ucddb016')\n",
    "print(data_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in data_base:\n",
    "#     i=pd.read_csv(base_dir+f'feature/{file}_win.csv')\n",
    "#     df = pd.concat([df, i], ignore_index=True)\n",
    "# df.dropna(how='all', axis=1,inplace=True)\n",
    "# df.to_csv(base_dir+f'all/all_win.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HRV_MeanNN_x</th>\n",
       "      <th>HRV_SDNN_x</th>\n",
       "      <th>HRV_RMSSD_x</th>\n",
       "      <th>HRV_SDSD_x</th>\n",
       "      <th>HRV_CVNN_x</th>\n",
       "      <th>HRV_CVSD_x</th>\n",
       "      <th>HRV_MedianNN_x</th>\n",
       "      <th>HRV_MadNN_x</th>\n",
       "      <th>HRV_MCVNN_x</th>\n",
       "      <th>HRV_IQRNN_x</th>\n",
       "      <th>...</th>\n",
       "      <th>peak_to_peak_y</th>\n",
       "      <th>rmse_y</th>\n",
       "      <th>kurtosis_y</th>\n",
       "      <th>skewness_y</th>\n",
       "      <th>waveform_factor_y</th>\n",
       "      <th>peak_factor_y</th>\n",
       "      <th>impulse_factor_y</th>\n",
       "      <th>margin_factor_y</th>\n",
       "      <th>rms_y</th>\n",
       "      <th>anns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>941.406250</td>\n",
       "      <td>13.877191</td>\n",
       "      <td>10.461470</td>\n",
       "      <td>10.590011</td>\n",
       "      <td>0.014741</td>\n",
       "      <td>0.011113</td>\n",
       "      <td>937.50000</td>\n",
       "      <td>11.582812</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>23.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>3.426618</td>\n",
       "      <td>0.499383</td>\n",
       "      <td>3.728094</td>\n",
       "      <td>-0.717594</td>\n",
       "      <td>0.220546</td>\n",
       "      <td>6.861699</td>\n",
       "      <td>1.513324</td>\n",
       "      <td>2.803092</td>\n",
       "      <td>2.316825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>932.963710</td>\n",
       "      <td>19.740977</td>\n",
       "      <td>10.578175</td>\n",
       "      <td>10.598053</td>\n",
       "      <td>0.021159</td>\n",
       "      <td>0.011338</td>\n",
       "      <td>937.50000</td>\n",
       "      <td>11.582812</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.426618</td>\n",
       "      <td>0.510929</td>\n",
       "      <td>3.205934</td>\n",
       "      <td>-0.847646</td>\n",
       "      <td>0.219974</td>\n",
       "      <td>6.706639</td>\n",
       "      <td>1.475284</td>\n",
       "      <td>2.785778</td>\n",
       "      <td>2.378262</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>784.417230</td>\n",
       "      <td>84.031488</td>\n",
       "      <td>92.695165</td>\n",
       "      <td>94.005934</td>\n",
       "      <td>0.107126</td>\n",
       "      <td>0.118171</td>\n",
       "      <td>773.43750</td>\n",
       "      <td>57.914062</td>\n",
       "      <td>0.074879</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.426618</td>\n",
       "      <td>0.512045</td>\n",
       "      <td>3.090319</td>\n",
       "      <td>-1.034765</td>\n",
       "      <td>0.213657</td>\n",
       "      <td>6.692021</td>\n",
       "      <td>1.429797</td>\n",
       "      <td>2.764269</td>\n",
       "      <td>2.453831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>915.826613</td>\n",
       "      <td>27.783640</td>\n",
       "      <td>20.768127</td>\n",
       "      <td>21.063296</td>\n",
       "      <td>0.030337</td>\n",
       "      <td>0.022677</td>\n",
       "      <td>914.06250</td>\n",
       "      <td>23.165625</td>\n",
       "      <td>0.025344</td>\n",
       "      <td>27.343750</td>\n",
       "      <td>...</td>\n",
       "      <td>3.409035</td>\n",
       "      <td>0.460080</td>\n",
       "      <td>3.062617</td>\n",
       "      <td>-0.937992</td>\n",
       "      <td>0.185486</td>\n",
       "      <td>7.409661</td>\n",
       "      <td>1.374385</td>\n",
       "      <td>2.723429</td>\n",
       "      <td>2.526806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>851.562500</td>\n",
       "      <td>115.654429</td>\n",
       "      <td>69.943265</td>\n",
       "      <td>71.024059</td>\n",
       "      <td>0.135814</td>\n",
       "      <td>0.082135</td>\n",
       "      <td>878.90625</td>\n",
       "      <td>98.453906</td>\n",
       "      <td>0.112019</td>\n",
       "      <td>146.484375</td>\n",
       "      <td>...</td>\n",
       "      <td>3.409035</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>4.127472</td>\n",
       "      <td>-1.289496</td>\n",
       "      <td>0.184498</td>\n",
       "      <td>7.256494</td>\n",
       "      <td>1.338809</td>\n",
       "      <td>2.705254</td>\n",
       "      <td>2.589996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20399</th>\n",
       "      <td>803.819444</td>\n",
       "      <td>42.248541</td>\n",
       "      <td>22.410536</td>\n",
       "      <td>22.369303</td>\n",
       "      <td>0.052560</td>\n",
       "      <td>0.027880</td>\n",
       "      <td>808.59375</td>\n",
       "      <td>28.957031</td>\n",
       "      <td>0.035812</td>\n",
       "      <td>33.203125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238339</td>\n",
       "      <td>0.114037</td>\n",
       "      <td>-1.477381</td>\n",
       "      <td>0.240137</td>\n",
       "      <td>0.037104</td>\n",
       "      <td>2.090020</td>\n",
       "      <td>0.077549</td>\n",
       "      <td>0.180015</td>\n",
       "      <td>3.074504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20400</th>\n",
       "      <td>740.985577</td>\n",
       "      <td>57.787447</td>\n",
       "      <td>17.377094</td>\n",
       "      <td>17.605423</td>\n",
       "      <td>0.077987</td>\n",
       "      <td>0.023451</td>\n",
       "      <td>734.37500</td>\n",
       "      <td>69.496875</td>\n",
       "      <td>0.094634</td>\n",
       "      <td>85.937500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238339</td>\n",
       "      <td>0.114434</td>\n",
       "      <td>-1.474395</td>\n",
       "      <td>0.259257</td>\n",
       "      <td>0.037259</td>\n",
       "      <td>2.082769</td>\n",
       "      <td>0.077601</td>\n",
       "      <td>0.180046</td>\n",
       "      <td>3.072412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20401</th>\n",
       "      <td>805.555556</td>\n",
       "      <td>13.043136</td>\n",
       "      <td>11.587810</td>\n",
       "      <td>11.754803</td>\n",
       "      <td>0.016191</td>\n",
       "      <td>0.014385</td>\n",
       "      <td>804.68750</td>\n",
       "      <td>11.582812</td>\n",
       "      <td>0.014394</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236386</td>\n",
       "      <td>0.113433</td>\n",
       "      <td>-1.441417</td>\n",
       "      <td>0.320433</td>\n",
       "      <td>0.036976</td>\n",
       "      <td>2.083932</td>\n",
       "      <td>0.077055</td>\n",
       "      <td>0.178622</td>\n",
       "      <td>3.068847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20402</th>\n",
       "      <td>808.159722</td>\n",
       "      <td>16.004808</td>\n",
       "      <td>10.889563</td>\n",
       "      <td>11.048543</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.013475</td>\n",
       "      <td>812.50000</td>\n",
       "      <td>23.165625</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>23.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236386</td>\n",
       "      <td>0.112289</td>\n",
       "      <td>-1.428370</td>\n",
       "      <td>0.317029</td>\n",
       "      <td>0.036602</td>\n",
       "      <td>2.105157</td>\n",
       "      <td>0.077054</td>\n",
       "      <td>0.178621</td>\n",
       "      <td>3.068897</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20403</th>\n",
       "      <td>792.229730</td>\n",
       "      <td>19.527731</td>\n",
       "      <td>10.001492</td>\n",
       "      <td>9.948072</td>\n",
       "      <td>0.024649</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>796.87500</td>\n",
       "      <td>23.165625</td>\n",
       "      <td>0.029071</td>\n",
       "      <td>23.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238339</td>\n",
       "      <td>0.113477</td>\n",
       "      <td>-1.419373</td>\n",
       "      <td>0.332327</td>\n",
       "      <td>0.036994</td>\n",
       "      <td>2.100331</td>\n",
       "      <td>0.077699</td>\n",
       "      <td>0.180102</td>\n",
       "      <td>3.068573</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20404 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HRV_MeanNN_x  HRV_SDNN_x  HRV_RMSSD_x  HRV_SDSD_x  HRV_CVNN_x  \\\n",
       "0        941.406250   13.877191    10.461470   10.590011    0.014741   \n",
       "1        932.963710   19.740977    10.578175   10.598053    0.021159   \n",
       "2        784.417230   84.031488    92.695165   94.005934    0.107126   \n",
       "3        915.826613   27.783640    20.768127   21.063296    0.030337   \n",
       "4        851.562500  115.654429    69.943265   71.024059    0.135814   \n",
       "...             ...         ...          ...         ...         ...   \n",
       "20399    803.819444   42.248541    22.410536   22.369303    0.052560   \n",
       "20400    740.985577   57.787447    17.377094   17.605423    0.077987   \n",
       "20401    805.555556   13.043136    11.587810   11.754803    0.016191   \n",
       "20402    808.159722   16.004808    10.889563   11.048543    0.019804   \n",
       "20403    792.229730   19.527731    10.001492    9.948072    0.024649   \n",
       "\n",
       "       HRV_CVSD_x  HRV_MedianNN_x  HRV_MadNN_x  HRV_MCVNN_x  HRV_IQRNN_x  ...  \\\n",
       "0        0.011113       937.50000    11.582812     0.012355    23.437500  ...   \n",
       "1        0.011338       937.50000    11.582812     0.012355    15.625000  ...   \n",
       "2        0.118171       773.43750    57.914062     0.074879    93.750000  ...   \n",
       "3        0.022677       914.06250    23.165625     0.025344    27.343750  ...   \n",
       "4        0.082135       878.90625    98.453906     0.112019   146.484375  ...   \n",
       "...           ...             ...          ...          ...          ...  ...   \n",
       "20399    0.027880       808.59375    28.957031     0.035812    33.203125  ...   \n",
       "20400    0.023451       734.37500    69.496875     0.094634    85.937500  ...   \n",
       "20401    0.014385       804.68750    11.582812     0.014394    15.625000  ...   \n",
       "20402    0.013475       812.50000    23.165625     0.028512    23.437500  ...   \n",
       "20403    0.012624       796.87500    23.165625     0.029071    23.437500  ...   \n",
       "\n",
       "       peak_to_peak_y    rmse_y  kurtosis_y  skewness_y  waveform_factor_y  \\\n",
       "0            3.426618  0.499383    3.728094   -0.717594           0.220546   \n",
       "1            3.426618  0.510929    3.205934   -0.847646           0.219974   \n",
       "2            3.426618  0.512045    3.090319   -1.034765           0.213657   \n",
       "3            3.409035  0.460080    3.062617   -0.937992           0.185486   \n",
       "4            3.409035  0.469791    4.127472   -1.289496           0.184498   \n",
       "...               ...       ...         ...         ...                ...   \n",
       "20399        0.238339  0.114037   -1.477381    0.240137           0.037104   \n",
       "20400        0.238339  0.114434   -1.474395    0.259257           0.037259   \n",
       "20401        0.236386  0.113433   -1.441417    0.320433           0.036976   \n",
       "20402        0.236386  0.112289   -1.428370    0.317029           0.036602   \n",
       "20403        0.238339  0.113477   -1.419373    0.332327           0.036994   \n",
       "\n",
       "       peak_factor_y  impulse_factor_y  margin_factor_y     rms_y  anns  \n",
       "0           6.861699          1.513324         2.803092  2.316825     0  \n",
       "1           6.706639          1.475284         2.785778  2.378262     0  \n",
       "2           6.692021          1.429797         2.764269  2.453831     0  \n",
       "3           7.409661          1.374385         2.723429  2.526806     0  \n",
       "4           7.256494          1.338809         2.705254  2.589996     0  \n",
       "...              ...               ...              ...       ...   ...  \n",
       "20399       2.090020          0.077549         0.180015  3.074504     0  \n",
       "20400       2.082769          0.077601         0.180046  3.072412     0  \n",
       "20401       2.083932          0.077055         0.178622  3.068847     0  \n",
       "20402       2.105157          0.077054         0.178621  3.068897     2  \n",
       "20403       2.100331          0.077699         0.180102  3.068573     2  \n",
       "\n",
       "[20404 rows x 188 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = pd.read_csv(base_dir+f'all/all_win.csv')\n",
    "data_set = data_set.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 31 features.\n"
     ]
    }
   ],
   "source": [
    "# Assuming your target variable is named 'target'\n",
    "x = data_set.drop('anns', axis=1)  # Features\n",
    "y = data_set['anns']  # Target variable\n",
    "\n",
    "# Create the estimator (in this case, LogisticRegression)\n",
    "estimator = RandomForestClassifier(verbose=3)\n",
    "\n",
    "# Create the RFE object\n",
    "rfe = RFE(estimator, n_features_to_select=30, step=3, verbose=10)\n",
    "\n",
    "# Fit the RFE object to the data\n",
    "rfe.fit(x, y)\n",
    "\n",
    "# Get the column names of the selected features\n",
    "selected_features = x.columns[rfe.support_]\n",
    "\n",
    "# Create a new DataFrame with the selected features\n",
    "x = data_set[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HRV_MeanNN_x</th>\n",
       "      <th>HRV_Prc20NN_x</th>\n",
       "      <th>HRV_MeanNN_y</th>\n",
       "      <th>HRV_SDANN1_y</th>\n",
       "      <th>HRV_CVSD_y</th>\n",
       "      <th>HRV_MCVNN_y</th>\n",
       "      <th>HRV_pNN20_y</th>\n",
       "      <th>HRV_MinNN_y</th>\n",
       "      <th>HRV_MaxNN_y</th>\n",
       "      <th>HRV_CSI_Modified_y</th>\n",
       "      <th>...</th>\n",
       "      <th>max_y</th>\n",
       "      <th>mean_y</th>\n",
       "      <th>std_y</th>\n",
       "      <th>rmse_y</th>\n",
       "      <th>kurtosis_y</th>\n",
       "      <th>skewness_y</th>\n",
       "      <th>waveform_factor_y</th>\n",
       "      <th>peak_factor_y</th>\n",
       "      <th>margin_factor_y</th>\n",
       "      <th>rms_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>941.406250</td>\n",
       "      <td>929.6875</td>\n",
       "      <td>887.054896</td>\n",
       "      <td>55.045392</td>\n",
       "      <td>0.111944</td>\n",
       "      <td>0.062822</td>\n",
       "      <td>32.937685</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1656.2500</td>\n",
       "      <td>1283.142942</td>\n",
       "      <td>...</td>\n",
       "      <td>3.170696</td>\n",
       "      <td>2.264299</td>\n",
       "      <td>0.490537</td>\n",
       "      <td>0.499383</td>\n",
       "      <td>3.728094</td>\n",
       "      <td>-0.717594</td>\n",
       "      <td>0.220546</td>\n",
       "      <td>6.861699</td>\n",
       "      <td>2.803092</td>\n",
       "      <td>2.316825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>932.963710</td>\n",
       "      <td>929.6875</td>\n",
       "      <td>890.181903</td>\n",
       "      <td>34.516891</td>\n",
       "      <td>0.112334</td>\n",
       "      <td>0.062822</td>\n",
       "      <td>35.223881</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1656.2500</td>\n",
       "      <td>1298.638356</td>\n",
       "      <td>...</td>\n",
       "      <td>3.170696</td>\n",
       "      <td>2.322683</td>\n",
       "      <td>0.511149</td>\n",
       "      <td>0.510929</td>\n",
       "      <td>3.205934</td>\n",
       "      <td>-0.847646</td>\n",
       "      <td>0.219974</td>\n",
       "      <td>6.706639</td>\n",
       "      <td>2.785778</td>\n",
       "      <td>2.378262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>784.417230</td>\n",
       "      <td>750.0000</td>\n",
       "      <td>893.314933</td>\n",
       "      <td>59.306612</td>\n",
       "      <td>0.112102</td>\n",
       "      <td>0.062294</td>\n",
       "      <td>35.928144</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1656.2500</td>\n",
       "      <td>1341.854801</td>\n",
       "      <td>...</td>\n",
       "      <td>3.170696</td>\n",
       "      <td>2.396577</td>\n",
       "      <td>0.526978</td>\n",
       "      <td>0.512045</td>\n",
       "      <td>3.090319</td>\n",
       "      <td>-1.034765</td>\n",
       "      <td>0.213657</td>\n",
       "      <td>6.692021</td>\n",
       "      <td>2.764269</td>\n",
       "      <td>2.453831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>915.826613</td>\n",
       "      <td>898.4375</td>\n",
       "      <td>911.847370</td>\n",
       "      <td>38.943009</td>\n",
       "      <td>0.105690</td>\n",
       "      <td>0.049420</td>\n",
       "      <td>32.926829</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1656.2500</td>\n",
       "      <td>1209.650164</td>\n",
       "      <td>...</td>\n",
       "      <td>3.153114</td>\n",
       "      <td>2.480407</td>\n",
       "      <td>0.482002</td>\n",
       "      <td>0.460080</td>\n",
       "      <td>3.062617</td>\n",
       "      <td>-0.937992</td>\n",
       "      <td>0.185486</td>\n",
       "      <td>7.409661</td>\n",
       "      <td>2.723429</td>\n",
       "      <td>2.526806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>851.562500</td>\n",
       "      <td>789.0625</td>\n",
       "      <td>913.560780</td>\n",
       "      <td>54.877815</td>\n",
       "      <td>0.105679</td>\n",
       "      <td>0.036759</td>\n",
       "      <td>32.110092</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1656.2500</td>\n",
       "      <td>1218.780913</td>\n",
       "      <td>...</td>\n",
       "      <td>3.153114</td>\n",
       "      <td>2.546320</td>\n",
       "      <td>0.473641</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>4.127472</td>\n",
       "      <td>-1.289496</td>\n",
       "      <td>0.184498</td>\n",
       "      <td>7.256494</td>\n",
       "      <td>2.705254</td>\n",
       "      <td>2.589996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20399</th>\n",
       "      <td>803.819444</td>\n",
       "      <td>789.0625</td>\n",
       "      <td>793.849469</td>\n",
       "      <td>14.224312</td>\n",
       "      <td>0.020415</td>\n",
       "      <td>0.029071</td>\n",
       "      <td>12.466844</td>\n",
       "      <td>632.8125</td>\n",
       "      <td>882.8125</td>\n",
       "      <td>832.470166</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203907</td>\n",
       "      <td>3.073420</td>\n",
       "      <td>0.081616</td>\n",
       "      <td>0.114037</td>\n",
       "      <td>-1.477381</td>\n",
       "      <td>0.240137</td>\n",
       "      <td>0.037104</td>\n",
       "      <td>2.090020</td>\n",
       "      <td>0.180015</td>\n",
       "      <td>3.074504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20400</th>\n",
       "      <td>740.985577</td>\n",
       "      <td>692.1875</td>\n",
       "      <td>794.921875</td>\n",
       "      <td>16.700587</td>\n",
       "      <td>0.019212</td>\n",
       "      <td>0.028788</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>632.8125</td>\n",
       "      <td>882.8125</td>\n",
       "      <td>831.505991</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203907</td>\n",
       "      <td>3.071327</td>\n",
       "      <td>0.081651</td>\n",
       "      <td>0.114434</td>\n",
       "      <td>-1.474395</td>\n",
       "      <td>0.259257</td>\n",
       "      <td>0.037259</td>\n",
       "      <td>2.082769</td>\n",
       "      <td>0.180046</td>\n",
       "      <td>3.072412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20401</th>\n",
       "      <td>805.555556</td>\n",
       "      <td>796.8750</td>\n",
       "      <td>800.289042</td>\n",
       "      <td>6.541426</td>\n",
       "      <td>0.018375</td>\n",
       "      <td>0.028788</td>\n",
       "      <td>10.723861</td>\n",
       "      <td>726.5625</td>\n",
       "      <td>882.8125</td>\n",
       "      <td>368.869150</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203907</td>\n",
       "      <td>3.067751</td>\n",
       "      <td>0.082016</td>\n",
       "      <td>0.113433</td>\n",
       "      <td>-1.441417</td>\n",
       "      <td>0.320433</td>\n",
       "      <td>0.036976</td>\n",
       "      <td>2.083932</td>\n",
       "      <td>0.178622</td>\n",
       "      <td>3.068847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20402</th>\n",
       "      <td>808.159722</td>\n",
       "      <td>796.8750</td>\n",
       "      <td>793.662964</td>\n",
       "      <td>18.535262</td>\n",
       "      <td>0.018353</td>\n",
       "      <td>0.029071</td>\n",
       "      <td>10.344828</td>\n",
       "      <td>679.6875</td>\n",
       "      <td>882.8125</td>\n",
       "      <td>664.841042</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203907</td>\n",
       "      <td>3.067813</td>\n",
       "      <td>0.081559</td>\n",
       "      <td>0.112289</td>\n",
       "      <td>-1.428370</td>\n",
       "      <td>0.317029</td>\n",
       "      <td>0.036602</td>\n",
       "      <td>2.105157</td>\n",
       "      <td>0.178621</td>\n",
       "      <td>3.068897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20403</th>\n",
       "      <td>792.229730</td>\n",
       "      <td>775.0000</td>\n",
       "      <td>792.390046</td>\n",
       "      <td>14.811247</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.029071</td>\n",
       "      <td>10.582011</td>\n",
       "      <td>679.6875</td>\n",
       "      <td>882.8125</td>\n",
       "      <td>664.539325</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203907</td>\n",
       "      <td>3.067486</td>\n",
       "      <td>0.081682</td>\n",
       "      <td>0.113477</td>\n",
       "      <td>-1.419373</td>\n",
       "      <td>0.332327</td>\n",
       "      <td>0.036994</td>\n",
       "      <td>2.100331</td>\n",
       "      <td>0.180102</td>\n",
       "      <td>3.068573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20404 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HRV_MeanNN_x  HRV_Prc20NN_x  HRV_MeanNN_y  HRV_SDANN1_y  HRV_CVSD_y  \\\n",
       "0        941.406250       929.6875    887.054896     55.045392    0.111944   \n",
       "1        932.963710       929.6875    890.181903     34.516891    0.112334   \n",
       "2        784.417230       750.0000    893.314933     59.306612    0.112102   \n",
       "3        915.826613       898.4375    911.847370     38.943009    0.105690   \n",
       "4        851.562500       789.0625    913.560780     54.877815    0.105679   \n",
       "...             ...            ...           ...           ...         ...   \n",
       "20399    803.819444       789.0625    793.849469     14.224312    0.020415   \n",
       "20400    740.985577       692.1875    794.921875     16.700587    0.019212   \n",
       "20401    805.555556       796.8750    800.289042      6.541426    0.018375   \n",
       "20402    808.159722       796.8750    793.662964     18.535262    0.018353   \n",
       "20403    792.229730       775.0000    792.390046     14.811247    0.018393   \n",
       "\n",
       "       HRV_MCVNN_y  HRV_pNN20_y  HRV_MinNN_y  HRV_MaxNN_y  HRV_CSI_Modified_y  \\\n",
       "0         0.062822    32.937685     304.6875    1656.2500         1283.142942   \n",
       "1         0.062822    35.223881     304.6875    1656.2500         1298.638356   \n",
       "2         0.062294    35.928144     304.6875    1656.2500         1341.854801   \n",
       "3         0.049420    32.926829     304.6875    1656.2500         1209.650164   \n",
       "4         0.036759    32.110092     304.6875    1656.2500         1218.780913   \n",
       "...            ...          ...          ...          ...                 ...   \n",
       "20399     0.029071    12.466844     632.8125     882.8125          832.470166   \n",
       "20400     0.028788    12.500000     632.8125     882.8125          831.505991   \n",
       "20401     0.028788    10.723861     726.5625     882.8125          368.869150   \n",
       "20402     0.029071    10.344828     679.6875     882.8125          664.841042   \n",
       "20403     0.029071    10.582011     679.6875     882.8125          664.539325   \n",
       "\n",
       "       ...     max_y    mean_y     std_y    rmse_y  kurtosis_y  skewness_y  \\\n",
       "0      ...  3.170696  2.264299  0.490537  0.499383    3.728094   -0.717594   \n",
       "1      ...  3.170696  2.322683  0.511149  0.510929    3.205934   -0.847646   \n",
       "2      ...  3.170696  2.396577  0.526978  0.512045    3.090319   -1.034765   \n",
       "3      ...  3.153114  2.480407  0.482002  0.460080    3.062617   -0.937992   \n",
       "4      ...  3.153114  2.546320  0.473641  0.469791    4.127472   -1.289496   \n",
       "...    ...       ...       ...       ...       ...         ...         ...   \n",
       "20399  ...  3.203907  3.073420  0.081616  0.114037   -1.477381    0.240137   \n",
       "20400  ...  3.203907  3.071327  0.081651  0.114434   -1.474395    0.259257   \n",
       "20401  ...  3.203907  3.067751  0.082016  0.113433   -1.441417    0.320433   \n",
       "20402  ...  3.203907  3.067813  0.081559  0.112289   -1.428370    0.317029   \n",
       "20403  ...  3.203907  3.067486  0.081682  0.113477   -1.419373    0.332327   \n",
       "\n",
       "       waveform_factor_y  peak_factor_y  margin_factor_y     rms_y  \n",
       "0               0.220546       6.861699         2.803092  2.316825  \n",
       "1               0.219974       6.706639         2.785778  2.378262  \n",
       "2               0.213657       6.692021         2.764269  2.453831  \n",
       "3               0.185486       7.409661         2.723429  2.526806  \n",
       "4               0.184498       7.256494         2.705254  2.589996  \n",
       "...                  ...            ...              ...       ...  \n",
       "20399           0.037104       2.090020         0.180015  3.074504  \n",
       "20400           0.037259       2.082769         0.180046  3.072412  \n",
       "20401           0.036976       2.083932         0.178622  3.068847  \n",
       "20402           0.036602       2.105157         0.178621  3.068897  \n",
       "20403           0.036994       2.100331         0.180102  3.068573  \n",
       "\n",
       "[20404 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=4405 (21.589%)\n",
      "Class=2, n=10347 (50.711%)\n",
      "Class=3, n=2661 (13.042%)\n",
      "Class=1, n=2991 (14.659%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter = Counter(y)\n",
    "for k,v in counter.items():\n",
    " per = v / len(y) * 100\n",
    " print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= train_test_split(x,y, test_size=0.2,stratify=y,random_state=1)\n",
    "del x\n",
    "del y\n",
    "del data_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SVC()\n",
    "# model.fit(x_train, y_train)\n",
    "# y_pred= model.predict(x_test)\n",
    "# print(classification_report(y_test,y_pred,target_names=['WAKE','REM','LIGHT','DEEP']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xhw2e_eKMnjL",
    "outputId": "a96dd1ab-fb4c-4158-d2ad-82b75a83df2f"
   },
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "\n",
    "m = SVC()\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                           ('m', m)])\n",
    "\n",
    "param_grid = {\n",
    "    'm__C': [0.1, 1, 10],  # Regularization parameter\n",
    "    'm__kernel': ['rbf', 'sigmoid','linear', 'poly'],  # Kernel type\n",
    "    'm__gamma': ['scale',1.0],  # Kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n",
    "    'm__degree': [2,3,4],  # Degree of the polynomial kernel function\n",
    "    'm__class_weight':['balanced']\n",
    " \n",
    "}     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "beNzI2owMr90",
    "outputId": "a0649b39-6e23-4f7d-dbf9-09eec42fcd29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.781 total time=  29.1s\n",
      "[CV 4/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.788 total time=  29.7s\n",
      "[CV 1/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.779 total time=  31.4s\n",
      "[CV 3/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.801 total time=  32.3s\n",
      "[CV 5/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.803 total time=  36.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=rbf;, score=0.526 total time=   4.6s\n",
      "[CV 3/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=rbf;, score=0.549 total time=   4.6s\n",
      "[CV 1/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=rbf;, score=0.563 total time=   4.7s\n",
      "[CV 4/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=rbf;, score=0.556 total time=   4.7s\n",
      "[CV 5/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=rbf;, score=0.573 total time=   4.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=poly;, score=0.776 total time=  23.5s\n",
      "[CV 1/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=poly;, score=0.784 total time=  23.6s\n",
      "[CV 2/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=poly;, score=0.773 total time=  26.5s\n",
      "[CV 5/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=poly;, score=0.799 total time=  28.9s\n",
      "[CV 3/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=poly;, score=0.802 total time=  30.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.573 total time=   4.2s\n",
      "[CV 1/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.563 total time=   4.1s\n",
      "[CV 2/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.526 total time=   4.6s\n",
      "[CV 3/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.549 total time=   5.0s\n",
      "[CV 4/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.556 total time=   5.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=rbf;, score=0.556 total time=   4.3s\n",
      "[CV 5/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=rbf;, score=0.573 total time=   4.3s\n",
      "[CV 2/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=rbf;, score=0.526 total time=   4.5s\n",
      "[CV 3/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=rbf;, score=0.549 total time=   5.3s\n",
      "[CV 1/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=rbf;, score=0.563 total time=   6.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=rbf;, score=0.853 total time=   6.4s\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=rbf;, score=0.850 total time=   7.6s\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=rbf;, score=0.842 total time=   7.2s\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=rbf;, score=0.850 total time=   7.6s\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=rbf;, score=0.841 total time=  10.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.563 total time=   3.8s\n",
      "[CV 3/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.549 total time=   4.6s\n",
      "[CV 2/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.526 total time=   4.6s\n",
      "[CV 5/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.573 total time=   4.7s\n",
      "[CV 4/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.556 total time=   5.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=linear;, score=0.500 total time=   5.8s\n",
      "[CV 4/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=linear;, score=0.518 total time=   5.8s\n",
      "[CV 3/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=linear;, score=0.504 total time=   6.8s\n",
      "[CV 1/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=linear;, score=0.518 total time=   6.8s\n",
      "[CV 2/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=linear;, score=0.510 total time=   6.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=poly;, score=0.629 total time=   3.5s\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=poly;, score=0.636 total time=   4.2s\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=poly;, score=0.647 total time=   4.4s\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=poly;, score=0.647 total time=   4.5s\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=poly;, score=0.627 total time=   5.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=rbf;, score=0.669 total time=   2.6s\n",
      "[CV 4/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=rbf;, score=0.693 total time=   3.1s\n",
      "[CV 5/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=rbf;, score=0.675 total time=   4.1s\n",
      "[CV 1/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=rbf;, score=0.678 total time=   4.2s\n",
      "[CV 3/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=rbf;, score=0.683 total time=   4.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=rbf;, score=0.762 total time=   3.1s\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=rbf;, score=0.771 total time=   3.2s\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=rbf;, score=0.779 total time=   3.2s\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=rbf;, score=0.782 total time=   3.4s\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=rbf;, score=0.779 total time=   3.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=poly;, score=0.599 total time=   3.0s\n",
      "[CV 3/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=poly;, score=0.595 total time=   3.1s\n",
      "[CV 2/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=poly;, score=0.607 total time=   3.7s\n",
      "[CV 4/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=poly;, score=0.597 total time=   4.0s\n",
      "[CV 1/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=poly;, score=0.598 total time=   4.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=linear;, score=0.500 total time=  30.9s\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=linear;, score=0.507 total time=  32.1s\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=linear;, score=0.519 total time=  34.6s\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=linear;, score=0.511 total time=  35.4s\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=linear;, score=0.521 total time=  37.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=sigmoid;, score=0.221 total time=   3.0s\n",
      "[CV 2/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=sigmoid;, score=0.235 total time=   3.2s\n",
      "[CV 4/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=sigmoid;, score=0.202 total time=   3.5s\n",
      "[CV 1/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=sigmoid;, score=0.222 total time=   4.0s\n",
      "[CV 5/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=sigmoid;, score=0.227 total time=   4.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=sigmoid;, score=0.271 total time=   3.8s\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=sigmoid;, score=0.278 total time=   3.8s\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=sigmoid;, score=0.273 total time=   4.0s\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=sigmoid;, score=0.273 total time=   4.3s\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=sigmoid;, score=0.271 total time=   5.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=poly;, score=0.795 total time=  23.8s\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=poly;, score=0.775 total time=  24.9s\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=poly;, score=0.770 total time=  27.3s\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=poly;, score=0.773 total time=  28.9s\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=poly;, score=0.796 total time=  30.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.766 total time= 1.4min\n",
      "[CV 2/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.772 total time= 1.5min\n",
      "[CV 4/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.765 total time= 1.6min\n",
      "[CV 3/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.783 total time= 1.6min\n",
      "[CV 5/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.804 total time= 1.7min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=rbf;, score=0.850 total time=   6.3s\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=rbf;, score=0.853 total time=   8.6s\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=rbf;, score=0.841 total time=   8.8s\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=rbf;, score=0.850 total time=   9.6s\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=rbf;, score=0.842 total time=  10.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.850 total time=   6.9s\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.853 total time=   7.4s\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.842 total time=   8.3s\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.841 total time=   8.4s\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.850 total time=  10.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=linear;, score=0.503 total time=   2.8s\n",
      "[CV 3/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=linear;, score=0.501 total time=   2.9s\n",
      "[CV 1/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=linear;, score=0.512 total time=   4.0s\n",
      "[CV 5/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=linear;, score=0.488 total time=   4.3s\n",
      "[CV 4/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=linear;, score=0.514 total time=   4.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=rbf;, score=0.858 total time=   5.0s\n",
      "[CV 2/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=rbf;, score=0.838 total time=   5.0s\n",
      "[CV 4/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=rbf;, score=0.844 total time=   5.2s\n",
      "[CV 1/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=rbf;, score=0.846 total time=   6.9s\n",
      "[CV 3/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=rbf;, score=0.853 total time=   7.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=linear;, score=0.518 total time=   4.6s\n",
      "[CV 2/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=linear;, score=0.510 total time=   5.1s\n",
      "[CV 3/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=linear;, score=0.504 total time=   5.2s\n",
      "[CV 5/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=linear;, score=0.500 total time=   7.2s\n",
      "[CV 4/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=linear;, score=0.518 total time=   7.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=rbf;, score=0.562 total time=   2.8s\n",
      "[CV 1/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=rbf;, score=0.582 total time=   2.9s\n",
      "[CV 2/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=rbf;, score=0.577 total time=   3.2s\n",
      "[CV 4/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=rbf;, score=0.575 total time=   4.0s\n",
      "[CV 3/5] END m__C=0.1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=rbf;, score=0.570 total time=   4.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=linear;, score=0.512 total time=   2.9s\n",
      "[CV 5/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=linear;, score=0.488 total time=   3.7s\n",
      "[CV 3/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=linear;, score=0.501 total time=   3.8s\n",
      "[CV 2/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=linear;, score=0.503 total time=   3.9s\n",
      "[CV 4/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=linear;, score=0.514 total time=   4.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=rbf;, score=0.838 total time=   5.4s\n",
      "[CV 1/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=rbf;, score=0.846 total time=   5.9s\n",
      "[CV 3/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=rbf;, score=0.853 total time=   6.9s\n",
      "[CV 5/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=rbf;, score=0.858 total time=   8.2s\n",
      "[CV 4/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=rbf;, score=0.844 total time=   8.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.853 total time=   4.6s\n",
      "[CV 4/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.844 total time=   4.7s\n",
      "[CV 1/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.846 total time=   4.8s\n",
      "[CV 5/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.858 total time=   6.3s\n",
      "[CV 2/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=rbf;, score=0.838 total time=   6.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=sigmoid;, score=0.330 total time=   3.0s\n",
      "[CV 1/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=sigmoid;, score=0.338 total time=   3.1s\n",
      "[CV 2/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=sigmoid;, score=0.336 total time=   3.3s\n",
      "[CV 4/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=sigmoid;, score=0.334 total time=   4.3s\n",
      "[CV 3/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=sigmoid;, score=0.329 total time=   4.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=poly;, score=0.666 total time=   2.6s\n",
      "[CV 1/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=poly;, score=0.672 total time=   2.7s\n",
      "[CV 3/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=poly;, score=0.680 total time=   2.9s\n",
      "[CV 4/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=poly;, score=0.681 total time=   3.3s\n",
      "[CV 5/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=poly;, score=0.669 total time=   3.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=sigmoid;, score=0.234 total time=   3.0s\n",
      "[CV 3/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=sigmoid;, score=0.222 total time=   3.4s\n",
      "[CV 1/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=sigmoid;, score=0.216 total time=   3.5s\n",
      "[CV 5/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=sigmoid;, score=0.228 total time=   3.6s\n",
      "[CV 4/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=sigmoid;, score=0.230 total time=   5.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=linear;, score=0.500 total time=  29.4s\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=linear;, score=0.507 total time=  36.6s\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=linear;, score=0.521 total time=  37.8s\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=linear;, score=0.519 total time=  41.4s\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=linear;, score=0.511 total time=  42.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=sigmoid;, score=0.276 total time=   2.8s\n",
      "[CV 1/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=sigmoid;, score=0.276 total time=   4.1s\n",
      "[CV 2/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=sigmoid;, score=0.285 total time=   4.8s\n",
      "[CV 4/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=sigmoid;, score=0.276 total time=   5.1s\n",
      "[CV 3/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=sigmoid;, score=0.278 total time=   5.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=sigmoid;, score=0.217 total time=   2.9s\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=sigmoid;, score=0.234 total time=   3.7s\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=sigmoid;, score=0.200 total time=   5.1s\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=sigmoid;, score=0.222 total time=   6.0s\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=sigmoid;, score=0.228 total time=   6.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=linear;, score=0.504 total time=   5.1s\n",
      "[CV 5/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=linear;, score=0.500 total time=   6.3s\n",
      "[CV 4/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=linear;, score=0.518 total time=   7.4s\n",
      "[CV 1/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=linear;, score=0.518 total time=   7.9s\n",
      "[CV 2/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=linear;, score=0.510 total time=   8.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=rbf;, score=0.693 total time=   2.3s\n",
      "[CV 3/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=rbf;, score=0.683 total time=   2.7s\n",
      "[CV 1/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=rbf;, score=0.678 total time=   3.5s\n",
      "[CV 5/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=rbf;, score=0.675 total time=   4.0s\n",
      "[CV 2/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=rbf;, score=0.669 total time=   4.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=poly;, score=0.743 total time=   2.8s\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=poly;, score=0.735 total time=   2.8s\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=poly;, score=0.724 total time=   4.0s\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=poly;, score=0.738 total time=   4.6s\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=poly;, score=0.740 total time=   4.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=poly;, score=0.657 total time=   8.2s\n",
      "[CV 1/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=poly;, score=0.659 total time=  10.7s\n",
      "[CV 3/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=poly;, score=0.670 total time=  12.5s\n",
      "[CV 2/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=poly;, score=0.650 total time=  13.3s\n",
      "[CV 4/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=poly;, score=0.669 total time=  13.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=poly;, score=0.690 total time= 9.1min\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=poly;, score=0.680 total time= 9.2min\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=poly;, score=0.687 total time=10.2min\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=poly;, score=0.688 total time=10.6min\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=poly;, score=0.687 total time=11.5min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=rbf;, score=0.779 total time=   2.4s\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=rbf;, score=0.762 total time=   2.4s\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=rbf;, score=0.782 total time=   2.8s\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=rbf;, score=0.771 total time=   4.2s\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=rbf;, score=0.779 total time=   4.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=linear;, score=0.501 total time=   2.7s\n",
      "[CV 5/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=linear;, score=0.488 total time=   2.7s\n",
      "[CV 1/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=linear;, score=0.512 total time=   3.7s\n",
      "[CV 2/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=linear;, score=0.503 total time=   4.2s\n",
      "[CV 4/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=linear;, score=0.514 total time=   4.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=rbf;, score=0.779 total time=   2.5s\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=rbf;, score=0.762 total time=   2.6s\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=rbf;, score=0.771 total time=   2.6s\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=rbf;, score=0.782 total time=   2.6s\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=2, m__gamma=scale, m__kernel=rbf;, score=0.779 total time=   3.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=linear;, score=0.488 total time=   2.7s\n",
      "[CV 4/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=linear;, score=0.514 total time=   2.7s\n",
      "[CV 2/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=linear;, score=0.503 total time=   3.5s\n",
      "[CV 1/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=linear;, score=0.512 total time=   3.8s\n",
      "[CV 3/5] END m__C=0.1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=linear;, score=0.501 total time=   4.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.766 total time= 1.1min\n",
      "[CV 4/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.765 total time= 1.3min\n",
      "[CV 5/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.804 total time= 1.3min\n",
      "[CV 2/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.772 total time= 1.6min\n",
      "[CV 3/5] END m__C=1, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.783 total time= 1.7min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=poly;, score=0.583 total time=   3.2s\n",
      "[CV 5/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=poly;, score=0.583 total time=   3.3s\n",
      "[CV 2/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=poly;, score=0.597 total time=   3.1s\n",
      "[CV 1/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=poly;, score=0.576 total time=   3.2s\n",
      "[CV 3/5] END m__C=0.1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=poly;, score=0.569 total time=   3.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.774 total time= 2.6min\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.752 total time= 2.8min\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.751 total time= 2.9min\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.775 total time= 2.9min\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=1.0, m__kernel=poly;, score=0.748 total time= 3.2min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=rbf;, score=0.782 total time=   2.8s\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=rbf;, score=0.779 total time=   2.7s\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=rbf;, score=0.771 total time=   2.8s\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=rbf;, score=0.762 total time=   3.7s\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=rbf;, score=0.779 total time=   4.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=poly;, score=0.680 total time=  49.1s\n",
      "[CV 4/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=poly;, score=0.681 total time=  51.3s\n",
      "[CV 1/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=poly;, score=0.681 total time=  52.2s\n",
      "[CV 2/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=poly;, score=0.670 total time=  54.6s\n",
      "[CV 5/5] END m__C=1, m__class_weight=balanced, m__degree=2, m__gamma=1.0, m__kernel=poly;, score=0.676 total time= 1.3min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=poly;, score=0.776 total time=  23.1s\n",
      "[CV 5/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=poly;, score=0.795 total time=  32.2s\n",
      "[CV 3/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=poly;, score=0.795 total time=  32.5s\n",
      "[CV 4/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=poly;, score=0.773 total time=  33.5s\n",
      "[CV 2/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=1.0, m__kernel=poly;, score=0.770 total time=  34.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=linear;, score=0.519 total time=  26.4s\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=linear;, score=0.511 total time=  27.9s\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=linear;, score=0.521 total time=  28.6s\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=linear;, score=0.507 total time=  33.0s\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=linear;, score=0.500 total time=  36.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=sigmoid;, score=0.273 total time=   2.7s\n",
      "[CV 4/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=sigmoid;, score=0.271 total time=   2.9s\n",
      "[CV 2/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=sigmoid;, score=0.278 total time=   3.0s\n",
      "[CV 3/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=sigmoid;, score=0.271 total time=   4.0s\n",
      "[CV 5/5] END m__C=10, m__class_weight=balanced, m__degree=3, m__gamma=scale, m__kernel=sigmoid;, score=0.273 total time=   4.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=poly;, score=0.690 total time=   2.5s\n",
      "[CV 4/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=poly;, score=0.681 total time=   2.8s\n",
      "[CV 3/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=poly;, score=0.683 total time=   3.0s\n",
      "[CV 1/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=poly;, score=0.679 total time=   3.4s\n",
      "[CV 2/5] END m__C=1, m__class_weight=balanced, m__degree=4, m__gamma=scale, m__kernel=poly;, score=0.684 total time=   3.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=Pipeline(steps=[(&#x27;std_slc&#x27;, StandardScaler()),\n",
       "                                        (&#x27;m&#x27;, SVC())]),\n",
       "              n_jobs=-1, scoring=&#x27;f1_macro&#x27;,\n",
       "              search_spaces={&#x27;m__C&#x27;: [0.1, 1, 10],\n",
       "                             &#x27;m__class_weight&#x27;: [&#x27;balanced&#x27;],\n",
       "                             &#x27;m__degree&#x27;: [2, 3, 4], &#x27;m__gamma&#x27;: [&#x27;scale&#x27;, 1.0],\n",
       "                             &#x27;m__kernel&#x27;: [&#x27;rbf&#x27;, &#x27;sigmoid&#x27;, &#x27;linear&#x27;, &#x27;poly&#x27;]},\n",
       "              verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BayesSearchCV<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=Pipeline(steps=[(&#x27;std_slc&#x27;, StandardScaler()),\n",
       "                                        (&#x27;m&#x27;, SVC())]),\n",
       "              n_jobs=-1, scoring=&#x27;f1_macro&#x27;,\n",
       "              search_spaces={&#x27;m__C&#x27;: [0.1, 1, 10],\n",
       "                             &#x27;m__class_weight&#x27;: [&#x27;balanced&#x27;],\n",
       "                             &#x27;m__degree&#x27;: [2, 3, 4], &#x27;m__gamma&#x27;: [&#x27;scale&#x27;, 1.0],\n",
       "                             &#x27;m__kernel&#x27;: [&#x27;rbf&#x27;, &#x27;sigmoid&#x27;, &#x27;linear&#x27;, &#x27;poly&#x27;]},\n",
       "              verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;std_slc&#x27;, StandardScaler()),\n",
       "                (&#x27;m&#x27;, SVC(C=1, class_weight=&#x27;balanced&#x27;, degree=4, gamma=1.0))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">SVC</label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=1, class_weight=&#x27;balanced&#x27;, degree=4, gamma=1.0)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=Pipeline(steps=[('std_slc', StandardScaler()),\n",
       "                                        ('m', SVC())]),\n",
       "              n_jobs=-1, scoring='f1_macro',\n",
       "              search_spaces={'m__C': [0.1, 1, 10],\n",
       "                             'm__class_weight': ['balanced'],\n",
       "                             'm__degree': [2, 3, 4], 'm__gamma': ['scale', 1.0],\n",
       "                             'm__kernel': ['rbf', 'sigmoid', 'linear', 'poly']},\n",
       "              verbose=3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GS = BayesSearchCV(pipe, param_grid,n_iter=50,cv=5,verbose=3,n_jobs=-1,refit=True,scoring='f1_macro')\n",
    "clf_GS.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "uzj5qygOMz_C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('std_slc', StandardScaler()),\n",
      "                ('m', SVC(C=1, class_weight='balanced', degree=4, gamma=1.0))])\n"
     ]
    }
   ],
   "source": [
    "print(clf_GS.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZfgheqJMNC13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        WAKE       0.77      0.80      0.79       881\n",
      "         REM       0.92      0.89      0.90       598\n",
      "       LIGHT       0.88      0.87      0.88      2070\n",
      "        DEEP       0.86      0.87      0.87       532\n",
      "\n",
      "    accuracy                           0.86      4081\n",
      "   macro avg       0.86      0.86      0.86      4081\n",
      "weighted avg       0.86      0.86      0.86      4081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred= clf_GS.predict(x_test)\n",
    "print(classification_report(y_test,y_pred,target_names=['WAKE','REM','LIGHT','DEEP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "lEY8hu4GwUUh",
    "outputId": "908d523a-08b9-4e40-c082-bc4c847b19cb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['WAKE','REM','LIGHT','DEEP'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
