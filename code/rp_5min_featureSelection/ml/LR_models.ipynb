{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R76a0E12YaBO",
    "outputId": "35096a5c-c593-4233-d40f-8d8c05b8e1d3"
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-optimize\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# base_dir='/content/drive/MyDrive/ucd/'\n",
    "base_dir='../../../folders/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CTnnrsLxYaBR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "np.int = np.int_\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ucddb002', 'ucddb003', 'ucddb005', 'ucddb006', 'ucddb007', 'ucddb008', 'ucddb009', 'ucddb010', 'ucddb011', 'ucddb012', 'ucddb013', 'ucddb014', 'ucddb015', 'ucddb017', 'ucddb018', 'ucddb019', 'ucddb020', 'ucddb021', 'ucddb022', 'ucddb023', 'ucddb024', 'ucddb025', 'ucddb026', 'ucddb027', 'ucddb028']\n"
     ]
    }
   ],
   "source": [
    "data_base=[f'ucddb{i:003d}' for i in range(2, 29)]\n",
    "data_base.remove('ucddb004')\n",
    "data_base.remove('ucddb016')\n",
    "print(data_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "# for file in data_base:\n",
    "#     i=pd.read_csv(base_dir+f'feature/{file}_win.csv')\n",
    "#     df = pd.concat([df, i], ignore_index=True)\n",
    "# df.dropna(how='all', axis=1,inplace=True)\n",
    "# df.to_csv(base_dir+f'all/all_win.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HRV_MeanNN_x</th>\n",
       "      <th>HRV_SDNN_x</th>\n",
       "      <th>HRV_RMSSD_x</th>\n",
       "      <th>HRV_SDSD_x</th>\n",
       "      <th>HRV_CVNN_x</th>\n",
       "      <th>HRV_CVSD_x</th>\n",
       "      <th>HRV_MedianNN_x</th>\n",
       "      <th>HRV_MadNN_x</th>\n",
       "      <th>HRV_MCVNN_x</th>\n",
       "      <th>HRV_IQRNN_x</th>\n",
       "      <th>...</th>\n",
       "      <th>peak_to_peak_y</th>\n",
       "      <th>rmse_y</th>\n",
       "      <th>kurtosis_y</th>\n",
       "      <th>skewness_y</th>\n",
       "      <th>waveform_factor_y</th>\n",
       "      <th>peak_factor_y</th>\n",
       "      <th>impulse_factor_y</th>\n",
       "      <th>margin_factor_y</th>\n",
       "      <th>rms_y</th>\n",
       "      <th>anns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>941.406250</td>\n",
       "      <td>13.877191</td>\n",
       "      <td>10.461470</td>\n",
       "      <td>10.590011</td>\n",
       "      <td>0.014741</td>\n",
       "      <td>0.011113</td>\n",
       "      <td>937.50000</td>\n",
       "      <td>11.582812</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>23.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>3.426618</td>\n",
       "      <td>0.499383</td>\n",
       "      <td>3.728094</td>\n",
       "      <td>-0.717594</td>\n",
       "      <td>0.220546</td>\n",
       "      <td>6.861699</td>\n",
       "      <td>1.513324</td>\n",
       "      <td>2.803092</td>\n",
       "      <td>2.316825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>932.963710</td>\n",
       "      <td>19.740977</td>\n",
       "      <td>10.578175</td>\n",
       "      <td>10.598053</td>\n",
       "      <td>0.021159</td>\n",
       "      <td>0.011338</td>\n",
       "      <td>937.50000</td>\n",
       "      <td>11.582812</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.426618</td>\n",
       "      <td>0.510929</td>\n",
       "      <td>3.205934</td>\n",
       "      <td>-0.847646</td>\n",
       "      <td>0.219974</td>\n",
       "      <td>6.706639</td>\n",
       "      <td>1.475284</td>\n",
       "      <td>2.785778</td>\n",
       "      <td>2.378262</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>784.417230</td>\n",
       "      <td>84.031488</td>\n",
       "      <td>92.695165</td>\n",
       "      <td>94.005934</td>\n",
       "      <td>0.107126</td>\n",
       "      <td>0.118171</td>\n",
       "      <td>773.43750</td>\n",
       "      <td>57.914062</td>\n",
       "      <td>0.074879</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.426618</td>\n",
       "      <td>0.512045</td>\n",
       "      <td>3.090319</td>\n",
       "      <td>-1.034765</td>\n",
       "      <td>0.213657</td>\n",
       "      <td>6.692021</td>\n",
       "      <td>1.429797</td>\n",
       "      <td>2.764269</td>\n",
       "      <td>2.453831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>915.826613</td>\n",
       "      <td>27.783640</td>\n",
       "      <td>20.768127</td>\n",
       "      <td>21.063296</td>\n",
       "      <td>0.030337</td>\n",
       "      <td>0.022677</td>\n",
       "      <td>914.06250</td>\n",
       "      <td>23.165625</td>\n",
       "      <td>0.025344</td>\n",
       "      <td>27.343750</td>\n",
       "      <td>...</td>\n",
       "      <td>3.409035</td>\n",
       "      <td>0.460080</td>\n",
       "      <td>3.062617</td>\n",
       "      <td>-0.937992</td>\n",
       "      <td>0.185486</td>\n",
       "      <td>7.409661</td>\n",
       "      <td>1.374385</td>\n",
       "      <td>2.723429</td>\n",
       "      <td>2.526806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>851.562500</td>\n",
       "      <td>115.654429</td>\n",
       "      <td>69.943265</td>\n",
       "      <td>71.024059</td>\n",
       "      <td>0.135814</td>\n",
       "      <td>0.082135</td>\n",
       "      <td>878.90625</td>\n",
       "      <td>98.453906</td>\n",
       "      <td>0.112019</td>\n",
       "      <td>146.484375</td>\n",
       "      <td>...</td>\n",
       "      <td>3.409035</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>4.127472</td>\n",
       "      <td>-1.289496</td>\n",
       "      <td>0.184498</td>\n",
       "      <td>7.256494</td>\n",
       "      <td>1.338809</td>\n",
       "      <td>2.705254</td>\n",
       "      <td>2.589996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20399</th>\n",
       "      <td>803.819444</td>\n",
       "      <td>42.248541</td>\n",
       "      <td>22.410536</td>\n",
       "      <td>22.369303</td>\n",
       "      <td>0.052560</td>\n",
       "      <td>0.027880</td>\n",
       "      <td>808.59375</td>\n",
       "      <td>28.957031</td>\n",
       "      <td>0.035812</td>\n",
       "      <td>33.203125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238339</td>\n",
       "      <td>0.114037</td>\n",
       "      <td>-1.477381</td>\n",
       "      <td>0.240137</td>\n",
       "      <td>0.037104</td>\n",
       "      <td>2.090020</td>\n",
       "      <td>0.077549</td>\n",
       "      <td>0.180015</td>\n",
       "      <td>3.074504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20400</th>\n",
       "      <td>740.985577</td>\n",
       "      <td>57.787447</td>\n",
       "      <td>17.377094</td>\n",
       "      <td>17.605423</td>\n",
       "      <td>0.077987</td>\n",
       "      <td>0.023451</td>\n",
       "      <td>734.37500</td>\n",
       "      <td>69.496875</td>\n",
       "      <td>0.094634</td>\n",
       "      <td>85.937500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238339</td>\n",
       "      <td>0.114434</td>\n",
       "      <td>-1.474395</td>\n",
       "      <td>0.259257</td>\n",
       "      <td>0.037259</td>\n",
       "      <td>2.082769</td>\n",
       "      <td>0.077601</td>\n",
       "      <td>0.180046</td>\n",
       "      <td>3.072412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20401</th>\n",
       "      <td>805.555556</td>\n",
       "      <td>13.043136</td>\n",
       "      <td>11.587810</td>\n",
       "      <td>11.754803</td>\n",
       "      <td>0.016191</td>\n",
       "      <td>0.014385</td>\n",
       "      <td>804.68750</td>\n",
       "      <td>11.582812</td>\n",
       "      <td>0.014394</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236386</td>\n",
       "      <td>0.113433</td>\n",
       "      <td>-1.441417</td>\n",
       "      <td>0.320433</td>\n",
       "      <td>0.036976</td>\n",
       "      <td>2.083932</td>\n",
       "      <td>0.077055</td>\n",
       "      <td>0.178622</td>\n",
       "      <td>3.068847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20402</th>\n",
       "      <td>808.159722</td>\n",
       "      <td>16.004808</td>\n",
       "      <td>10.889563</td>\n",
       "      <td>11.048543</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.013475</td>\n",
       "      <td>812.50000</td>\n",
       "      <td>23.165625</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>23.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236386</td>\n",
       "      <td>0.112289</td>\n",
       "      <td>-1.428370</td>\n",
       "      <td>0.317029</td>\n",
       "      <td>0.036602</td>\n",
       "      <td>2.105157</td>\n",
       "      <td>0.077054</td>\n",
       "      <td>0.178621</td>\n",
       "      <td>3.068897</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20403</th>\n",
       "      <td>792.229730</td>\n",
       "      <td>19.527731</td>\n",
       "      <td>10.001492</td>\n",
       "      <td>9.948072</td>\n",
       "      <td>0.024649</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>796.87500</td>\n",
       "      <td>23.165625</td>\n",
       "      <td>0.029071</td>\n",
       "      <td>23.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238339</td>\n",
       "      <td>0.113477</td>\n",
       "      <td>-1.419373</td>\n",
       "      <td>0.332327</td>\n",
       "      <td>0.036994</td>\n",
       "      <td>2.100331</td>\n",
       "      <td>0.077699</td>\n",
       "      <td>0.180102</td>\n",
       "      <td>3.068573</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20404 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HRV_MeanNN_x  HRV_SDNN_x  HRV_RMSSD_x  HRV_SDSD_x  HRV_CVNN_x  \\\n",
       "0        941.406250   13.877191    10.461470   10.590011    0.014741   \n",
       "1        932.963710   19.740977    10.578175   10.598053    0.021159   \n",
       "2        784.417230   84.031488    92.695165   94.005934    0.107126   \n",
       "3        915.826613   27.783640    20.768127   21.063296    0.030337   \n",
       "4        851.562500  115.654429    69.943265   71.024059    0.135814   \n",
       "...             ...         ...          ...         ...         ...   \n",
       "20399    803.819444   42.248541    22.410536   22.369303    0.052560   \n",
       "20400    740.985577   57.787447    17.377094   17.605423    0.077987   \n",
       "20401    805.555556   13.043136    11.587810   11.754803    0.016191   \n",
       "20402    808.159722   16.004808    10.889563   11.048543    0.019804   \n",
       "20403    792.229730   19.527731    10.001492    9.948072    0.024649   \n",
       "\n",
       "       HRV_CVSD_x  HRV_MedianNN_x  HRV_MadNN_x  HRV_MCVNN_x  HRV_IQRNN_x  ...  \\\n",
       "0        0.011113       937.50000    11.582812     0.012355    23.437500  ...   \n",
       "1        0.011338       937.50000    11.582812     0.012355    15.625000  ...   \n",
       "2        0.118171       773.43750    57.914062     0.074879    93.750000  ...   \n",
       "3        0.022677       914.06250    23.165625     0.025344    27.343750  ...   \n",
       "4        0.082135       878.90625    98.453906     0.112019   146.484375  ...   \n",
       "...           ...             ...          ...          ...          ...  ...   \n",
       "20399    0.027880       808.59375    28.957031     0.035812    33.203125  ...   \n",
       "20400    0.023451       734.37500    69.496875     0.094634    85.937500  ...   \n",
       "20401    0.014385       804.68750    11.582812     0.014394    15.625000  ...   \n",
       "20402    0.013475       812.50000    23.165625     0.028512    23.437500  ...   \n",
       "20403    0.012624       796.87500    23.165625     0.029071    23.437500  ...   \n",
       "\n",
       "       peak_to_peak_y    rmse_y  kurtosis_y  skewness_y  waveform_factor_y  \\\n",
       "0            3.426618  0.499383    3.728094   -0.717594           0.220546   \n",
       "1            3.426618  0.510929    3.205934   -0.847646           0.219974   \n",
       "2            3.426618  0.512045    3.090319   -1.034765           0.213657   \n",
       "3            3.409035  0.460080    3.062617   -0.937992           0.185486   \n",
       "4            3.409035  0.469791    4.127472   -1.289496           0.184498   \n",
       "...               ...       ...         ...         ...                ...   \n",
       "20399        0.238339  0.114037   -1.477381    0.240137           0.037104   \n",
       "20400        0.238339  0.114434   -1.474395    0.259257           0.037259   \n",
       "20401        0.236386  0.113433   -1.441417    0.320433           0.036976   \n",
       "20402        0.236386  0.112289   -1.428370    0.317029           0.036602   \n",
       "20403        0.238339  0.113477   -1.419373    0.332327           0.036994   \n",
       "\n",
       "       peak_factor_y  impulse_factor_y  margin_factor_y     rms_y  anns  \n",
       "0           6.861699          1.513324         2.803092  2.316825     0  \n",
       "1           6.706639          1.475284         2.785778  2.378262     0  \n",
       "2           6.692021          1.429797         2.764269  2.453831     0  \n",
       "3           7.409661          1.374385         2.723429  2.526806     0  \n",
       "4           7.256494          1.338809         2.705254  2.589996     0  \n",
       "...              ...               ...              ...       ...   ...  \n",
       "20399       2.090020          0.077549         0.180015  3.074504     0  \n",
       "20400       2.082769          0.077601         0.180046  3.072412     0  \n",
       "20401       2.083932          0.077055         0.178622  3.068847     0  \n",
       "20402       2.105157          0.077054         0.178621  3.068897     2  \n",
       "20403       2.100331          0.077699         0.180102  3.068573     2  \n",
       "\n",
       "[20404 rows x 188 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = pd.read_csv(base_dir+f'all/all_win.csv')\n",
    "data_set = data_set.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 31 features.\n"
     ]
    }
   ],
   "source": [
    "# Assuming your target variable is named 'target'\n",
    "x = data_set.drop('anns', axis=1)  # Features\n",
    "y = data_set['anns']  # Target variable\n",
    "\n",
    "# Create the estimator (in this case, LogisticRegression)\n",
    "estimator = RandomForestClassifier()\n",
    "\n",
    "# Create the RFE object\n",
    "rfe = RFE(estimator, n_features_to_select=30, step=3, verbose=10)\n",
    "\n",
    "# Fit the RFE object to the data\n",
    "rfe.fit(x, y)\n",
    "\n",
    "# Get the column names of the selected features\n",
    "selected_features = x.columns[rfe.support_]\n",
    "\n",
    "# Create a new DataFrame with the selected features\n",
    "x = data_set[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HRV_MeanNN_x</th>\n",
       "      <th>HRV_Prc20NN_x</th>\n",
       "      <th>HRV_MeanNN_y</th>\n",
       "      <th>HRV_SDANN1_y</th>\n",
       "      <th>HRV_CVSD_y</th>\n",
       "      <th>HRV_MCVNN_y</th>\n",
       "      <th>HRV_pNN20_y</th>\n",
       "      <th>HRV_MinNN_y</th>\n",
       "      <th>HRV_MaxNN_y</th>\n",
       "      <th>HRV_SD1SD2_y</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_y</th>\n",
       "      <th>std_y</th>\n",
       "      <th>var_y</th>\n",
       "      <th>rmse_y</th>\n",
       "      <th>kurtosis_y</th>\n",
       "      <th>skewness_y</th>\n",
       "      <th>waveform_factor_y</th>\n",
       "      <th>peak_factor_y</th>\n",
       "      <th>margin_factor_y</th>\n",
       "      <th>rms_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>941.406250</td>\n",
       "      <td>929.6875</td>\n",
       "      <td>887.054896</td>\n",
       "      <td>55.045392</td>\n",
       "      <td>0.111944</td>\n",
       "      <td>0.062822</td>\n",
       "      <td>32.937685</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1656.2500</td>\n",
       "      <td>0.468204</td>\n",
       "      <td>...</td>\n",
       "      <td>2.264299</td>\n",
       "      <td>0.490537</td>\n",
       "      <td>0.240627</td>\n",
       "      <td>0.499383</td>\n",
       "      <td>3.728094</td>\n",
       "      <td>-0.717594</td>\n",
       "      <td>0.220546</td>\n",
       "      <td>6.861699</td>\n",
       "      <td>2.803092</td>\n",
       "      <td>2.316825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>932.963710</td>\n",
       "      <td>929.6875</td>\n",
       "      <td>890.181903</td>\n",
       "      <td>34.516891</td>\n",
       "      <td>0.112334</td>\n",
       "      <td>0.062822</td>\n",
       "      <td>35.223881</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1656.2500</td>\n",
       "      <td>0.467034</td>\n",
       "      <td>...</td>\n",
       "      <td>2.322683</td>\n",
       "      <td>0.511149</td>\n",
       "      <td>0.261274</td>\n",
       "      <td>0.510929</td>\n",
       "      <td>3.205934</td>\n",
       "      <td>-0.847646</td>\n",
       "      <td>0.219974</td>\n",
       "      <td>6.706639</td>\n",
       "      <td>2.785778</td>\n",
       "      <td>2.378262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>784.417230</td>\n",
       "      <td>750.0000</td>\n",
       "      <td>893.314933</td>\n",
       "      <td>59.306612</td>\n",
       "      <td>0.112102</td>\n",
       "      <td>0.062294</td>\n",
       "      <td>35.928144</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1656.2500</td>\n",
       "      <td>0.459784</td>\n",
       "      <td>...</td>\n",
       "      <td>2.396577</td>\n",
       "      <td>0.526978</td>\n",
       "      <td>0.277706</td>\n",
       "      <td>0.512045</td>\n",
       "      <td>3.090319</td>\n",
       "      <td>-1.034765</td>\n",
       "      <td>0.213657</td>\n",
       "      <td>6.692021</td>\n",
       "      <td>2.764269</td>\n",
       "      <td>2.453831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>915.826613</td>\n",
       "      <td>898.4375</td>\n",
       "      <td>911.847370</td>\n",
       "      <td>38.943009</td>\n",
       "      <td>0.105690</td>\n",
       "      <td>0.049420</td>\n",
       "      <td>32.926829</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1656.2500</td>\n",
       "      <td>0.475065</td>\n",
       "      <td>...</td>\n",
       "      <td>2.480407</td>\n",
       "      <td>0.482002</td>\n",
       "      <td>0.232326</td>\n",
       "      <td>0.460080</td>\n",
       "      <td>3.062617</td>\n",
       "      <td>-0.937992</td>\n",
       "      <td>0.185486</td>\n",
       "      <td>7.409661</td>\n",
       "      <td>2.723429</td>\n",
       "      <td>2.526806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>851.562500</td>\n",
       "      <td>789.0625</td>\n",
       "      <td>913.560780</td>\n",
       "      <td>54.877815</td>\n",
       "      <td>0.105679</td>\n",
       "      <td>0.036759</td>\n",
       "      <td>32.110092</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1656.2500</td>\n",
       "      <td>0.473701</td>\n",
       "      <td>...</td>\n",
       "      <td>2.546320</td>\n",
       "      <td>0.473641</td>\n",
       "      <td>0.224336</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>4.127472</td>\n",
       "      <td>-1.289496</td>\n",
       "      <td>0.184498</td>\n",
       "      <td>7.256494</td>\n",
       "      <td>2.705254</td>\n",
       "      <td>2.589996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20399</th>\n",
       "      <td>803.819444</td>\n",
       "      <td>789.0625</td>\n",
       "      <td>793.849469</td>\n",
       "      <td>14.224312</td>\n",
       "      <td>0.020415</td>\n",
       "      <td>0.029071</td>\n",
       "      <td>12.466844</td>\n",
       "      <td>632.8125</td>\n",
       "      <td>882.8125</td>\n",
       "      <td>0.234756</td>\n",
       "      <td>...</td>\n",
       "      <td>3.073420</td>\n",
       "      <td>0.081616</td>\n",
       "      <td>0.006661</td>\n",
       "      <td>0.114037</td>\n",
       "      <td>-1.477381</td>\n",
       "      <td>0.240137</td>\n",
       "      <td>0.037104</td>\n",
       "      <td>2.090020</td>\n",
       "      <td>0.180015</td>\n",
       "      <td>3.074504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20400</th>\n",
       "      <td>740.985577</td>\n",
       "      <td>692.1875</td>\n",
       "      <td>794.921875</td>\n",
       "      <td>16.700587</td>\n",
       "      <td>0.019212</td>\n",
       "      <td>0.028788</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>632.8125</td>\n",
       "      <td>882.8125</td>\n",
       "      <td>0.228074</td>\n",
       "      <td>...</td>\n",
       "      <td>3.071327</td>\n",
       "      <td>0.081651</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.114434</td>\n",
       "      <td>-1.474395</td>\n",
       "      <td>0.259257</td>\n",
       "      <td>0.037259</td>\n",
       "      <td>2.082769</td>\n",
       "      <td>0.180046</td>\n",
       "      <td>3.072412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20401</th>\n",
       "      <td>805.555556</td>\n",
       "      <td>796.8750</td>\n",
       "      <td>800.289042</td>\n",
       "      <td>6.541426</td>\n",
       "      <td>0.018375</td>\n",
       "      <td>0.028788</td>\n",
       "      <td>10.723861</td>\n",
       "      <td>726.5625</td>\n",
       "      <td>882.8125</td>\n",
       "      <td>0.336018</td>\n",
       "      <td>...</td>\n",
       "      <td>3.067751</td>\n",
       "      <td>0.082016</td>\n",
       "      <td>0.006727</td>\n",
       "      <td>0.113433</td>\n",
       "      <td>-1.441417</td>\n",
       "      <td>0.320433</td>\n",
       "      <td>0.036976</td>\n",
       "      <td>2.083932</td>\n",
       "      <td>0.178622</td>\n",
       "      <td>3.068847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20402</th>\n",
       "      <td>808.159722</td>\n",
       "      <td>796.8750</td>\n",
       "      <td>793.662964</td>\n",
       "      <td>18.535262</td>\n",
       "      <td>0.018353</td>\n",
       "      <td>0.029071</td>\n",
       "      <td>10.344828</td>\n",
       "      <td>679.6875</td>\n",
       "      <td>882.8125</td>\n",
       "      <td>0.249087</td>\n",
       "      <td>...</td>\n",
       "      <td>3.067813</td>\n",
       "      <td>0.081559</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>0.112289</td>\n",
       "      <td>-1.428370</td>\n",
       "      <td>0.317029</td>\n",
       "      <td>0.036602</td>\n",
       "      <td>2.105157</td>\n",
       "      <td>0.178621</td>\n",
       "      <td>3.068897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20403</th>\n",
       "      <td>792.229730</td>\n",
       "      <td>775.0000</td>\n",
       "      <td>792.390046</td>\n",
       "      <td>14.811247</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.029071</td>\n",
       "      <td>10.582011</td>\n",
       "      <td>679.6875</td>\n",
       "      <td>882.8125</td>\n",
       "      <td>0.249226</td>\n",
       "      <td>...</td>\n",
       "      <td>3.067486</td>\n",
       "      <td>0.081682</td>\n",
       "      <td>0.006672</td>\n",
       "      <td>0.113477</td>\n",
       "      <td>-1.419373</td>\n",
       "      <td>0.332327</td>\n",
       "      <td>0.036994</td>\n",
       "      <td>2.100331</td>\n",
       "      <td>0.180102</td>\n",
       "      <td>3.068573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20404 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HRV_MeanNN_x  HRV_Prc20NN_x  HRV_MeanNN_y  HRV_SDANN1_y  HRV_CVSD_y  \\\n",
       "0        941.406250       929.6875    887.054896     55.045392    0.111944   \n",
       "1        932.963710       929.6875    890.181903     34.516891    0.112334   \n",
       "2        784.417230       750.0000    893.314933     59.306612    0.112102   \n",
       "3        915.826613       898.4375    911.847370     38.943009    0.105690   \n",
       "4        851.562500       789.0625    913.560780     54.877815    0.105679   \n",
       "...             ...            ...           ...           ...         ...   \n",
       "20399    803.819444       789.0625    793.849469     14.224312    0.020415   \n",
       "20400    740.985577       692.1875    794.921875     16.700587    0.019212   \n",
       "20401    805.555556       796.8750    800.289042      6.541426    0.018375   \n",
       "20402    808.159722       796.8750    793.662964     18.535262    0.018353   \n",
       "20403    792.229730       775.0000    792.390046     14.811247    0.018393   \n",
       "\n",
       "       HRV_MCVNN_y  HRV_pNN20_y  HRV_MinNN_y  HRV_MaxNN_y  HRV_SD1SD2_y  ...  \\\n",
       "0         0.062822    32.937685     304.6875    1656.2500      0.468204  ...   \n",
       "1         0.062822    35.223881     304.6875    1656.2500      0.467034  ...   \n",
       "2         0.062294    35.928144     304.6875    1656.2500      0.459784  ...   \n",
       "3         0.049420    32.926829     304.6875    1656.2500      0.475065  ...   \n",
       "4         0.036759    32.110092     304.6875    1656.2500      0.473701  ...   \n",
       "...            ...          ...          ...          ...           ...  ...   \n",
       "20399     0.029071    12.466844     632.8125     882.8125      0.234756  ...   \n",
       "20400     0.028788    12.500000     632.8125     882.8125      0.228074  ...   \n",
       "20401     0.028788    10.723861     726.5625     882.8125      0.336018  ...   \n",
       "20402     0.029071    10.344828     679.6875     882.8125      0.249087  ...   \n",
       "20403     0.029071    10.582011     679.6875     882.8125      0.249226  ...   \n",
       "\n",
       "         mean_y     std_y     var_y    rmse_y  kurtosis_y  skewness_y  \\\n",
       "0      2.264299  0.490537  0.240627  0.499383    3.728094   -0.717594   \n",
       "1      2.322683  0.511149  0.261274  0.510929    3.205934   -0.847646   \n",
       "2      2.396577  0.526978  0.277706  0.512045    3.090319   -1.034765   \n",
       "3      2.480407  0.482002  0.232326  0.460080    3.062617   -0.937992   \n",
       "4      2.546320  0.473641  0.224336  0.469791    4.127472   -1.289496   \n",
       "...         ...       ...       ...       ...         ...         ...   \n",
       "20399  3.073420  0.081616  0.006661  0.114037   -1.477381    0.240137   \n",
       "20400  3.071327  0.081651  0.006667  0.114434   -1.474395    0.259257   \n",
       "20401  3.067751  0.082016  0.006727  0.113433   -1.441417    0.320433   \n",
       "20402  3.067813  0.081559  0.006652  0.112289   -1.428370    0.317029   \n",
       "20403  3.067486  0.081682  0.006672  0.113477   -1.419373    0.332327   \n",
       "\n",
       "       waveform_factor_y  peak_factor_y  margin_factor_y     rms_y  \n",
       "0               0.220546       6.861699         2.803092  2.316825  \n",
       "1               0.219974       6.706639         2.785778  2.378262  \n",
       "2               0.213657       6.692021         2.764269  2.453831  \n",
       "3               0.185486       7.409661         2.723429  2.526806  \n",
       "4               0.184498       7.256494         2.705254  2.589996  \n",
       "...                  ...            ...              ...       ...  \n",
       "20399           0.037104       2.090020         0.180015  3.074504  \n",
       "20400           0.037259       2.082769         0.180046  3.072412  \n",
       "20401           0.036976       2.083932         0.178622  3.068847  \n",
       "20402           0.036602       2.105157         0.178621  3.068897  \n",
       "20403           0.036994       2.100331         0.180102  3.068573  \n",
       "\n",
       "[20404 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=4405 (21.589%)\n",
      "Class=2, n=10347 (50.711%)\n",
      "Class=3, n=2661 (13.042%)\n",
      "Class=1, n=2991 (14.659%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize distribution\n",
    "counter = Counter(y)\n",
    "for k,v in counter.items():\n",
    " per = v / len(y) * 100\n",
    " print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= train_test_split(x,y, test_size=0.2,stratify=y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression()\n",
    "# model.fit(x_train, y_train)\n",
    "# y_pred= model.predict(x_test)\n",
    "# print(classification_report(y_test,y_pred,target_names=['WAKE','REM','LIGHT','DEEP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__C=10, m__penalty=l2, m__solver=liblinear, m__tol=0.001;, score=0.479 total time=   0.5s\n",
      "[CV 1/5] END m__C=10, m__penalty=l2, m__solver=liblinear, m__tol=0.001;, score=0.471 total time=   0.9s\n",
      "[CV 3/5] END m__C=10, m__penalty=l2, m__solver=liblinear, m__tol=0.001;, score=0.469 total time=   1.0s\n",
      "[CV 5/5] END m__C=10, m__penalty=l2, m__solver=liblinear, m__tol=0.001;, score=0.484 total time=   0.9s\n",
      "[CV 2/5] END m__C=10, m__penalty=l2, m__solver=liblinear, m__tol=0.001;, score=0.474 total time=   1.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END m__C=0.1, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.477 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END m__C=0.1, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.481 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END m__C=0.1, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.495 total time=   1.7s\n",
      "[CV 3/5] END m__C=0.1, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.473 total time=   1.7s\n",
      "[CV 1/5] END m__C=0.1, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.473 total time=   1.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END m__C=0.1, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.495 total time=   1.0s\n",
      "[CV 4/5] END m__C=0.1, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.477 total time=   1.0s\n",
      "[CV 2/5] END m__C=0.1, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.481 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END m__C=0.1, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.473 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END m__C=0.1, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.473 total time=   2.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.395 total time=   0.3s\n",
      "[CV 5/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.418 total time=   0.4s\n",
      "[CV 4/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.407 total time=   0.3s\n",
      "[CV 2/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.404 total time=   0.5s\n",
      "[CV 3/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.406 total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__C=0.1, m__penalty=l1, m__solver=liblinear, m__tol=0.0001;, score=0.464 total time=   1.3s\n",
      "[CV 5/5] END m__C=0.1, m__penalty=l1, m__solver=liblinear, m__tol=0.0001;, score=0.475 total time=   1.5s\n",
      "[CV 4/5] END m__C=0.1, m__penalty=l1, m__solver=liblinear, m__tol=0.0001;, score=0.468 total time=   1.6s\n",
      "[CV 2/5] END m__C=0.1, m__penalty=l1, m__solver=liblinear, m__tol=0.0001;, score=0.468 total time=   1.7s\n",
      "[CV 1/5] END m__C=0.1, m__penalty=l1, m__solver=liblinear, m__tol=0.0001;, score=0.460 total time=   4.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.500 total time=   1.0s\n",
      "[CV 4/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.489 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.478 total time=   1.0s\n",
      "[CV 1/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.486 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.483 total time=   1.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=1, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.485 total time=   0.2s\n",
      "[CV 4/5] END m__C=1, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.478 total time=   0.3s\n",
      "[CV 2/5] END m__C=1, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.474 total time=   0.4s\n",
      "[CV 1/5] END m__C=1, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.469 total time=   0.4s\n",
      "[CV 3/5] END m__C=1, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.468 total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.482 total time=   0.9s\n",
      "[CV 3/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.476 total time=   0.9s\n",
      "[CV 4/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.489 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.485 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.501 total time=   1.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__C=1, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.478 total time=   0.3s\n",
      "[CV 3/5] END m__C=1, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.468 total time=   0.3s\n",
      "[CV 2/5] END m__C=1, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.474 total time=   0.4s\n",
      "[CV 1/5] END m__C=1, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.469 total time=   0.5s\n",
      "[CV 5/5] END m__C=1, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.485 total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.478 total time=   0.3s\n",
      "[CV 1/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.472 total time=   0.3s\n",
      "[CV 3/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.466 total time=   0.5s\n",
      "[CV 5/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.486 total time=   0.5s\n",
      "[CV 2/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.474 total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.370 total time=   0.1s\n",
      "[CV 5/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.372 total time=   0.1s\n",
      "[CV 1/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.357 total time=   0.1s\n",
      "[CV 4/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.373 total time=   0.1s\n",
      "[CV 2/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.370 total time=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.474 total time=   0.4s\n",
      "[CV 2/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.477 total time=   0.5s\n",
      "[CV 3/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.473 total time=   0.7s\n",
      "[CV 5/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.495 total time=   0.9s\n",
      "[CV 4/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.478 total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=0.1, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.490 total time=   0.3s\n",
      "[CV 1/5] END m__C=0.1, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.466 total time=   0.3s\n",
      "[CV 2/5] END m__C=0.1, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.472 total time=   0.3s\n",
      "[CV 3/5] END m__C=0.1, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.469 total time=   0.5s\n",
      "[CV 4/5] END m__C=0.1, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.472 total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.478 total time=   0.8s\n",
      "[CV 2/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.483 total time=   0.8s\n",
      "[CV 4/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.489 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.501 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.486 total time=   1.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=0.01, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.450 total time=   0.1s\n",
      "[CV 4/5] END m__C=0.01, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.440 total time=   0.1s\n",
      "[CV 1/5] END m__C=0.01, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.429 total time=   0.3s\n",
      "[CV 2/5] END m__C=0.01, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.441 total time=   0.3s\n",
      "[CV 3/5] END m__C=0.01, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.443 total time=   0.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.475 total time=   0.7s\n",
      "[CV 4/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.484 total time=   0.7s\n",
      "[CV 2/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.481 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.500 total time=   1.2s\n",
      "[CV 1/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.480 total time=   1.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__C=10, m__penalty=l2, m__solver=saga, m__tol=0.01;, score=0.473 total time=   0.2s\n",
      "[CV 2/5] END m__C=10, m__penalty=l2, m__solver=saga, m__tol=0.01;, score=0.476 total time=   0.4s\n",
      "[CV 5/5] END m__C=10, m__penalty=l2, m__solver=saga, m__tol=0.01;, score=0.495 total time=   0.4s\n",
      "[CV 3/5] END m__C=10, m__penalty=l2, m__solver=saga, m__tol=0.01;, score=0.473 total time=   0.5s\n",
      "[CV 4/5] END m__C=10, m__penalty=l2, m__solver=saga, m__tol=0.01;, score=0.478 total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END m__C=10, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.479 total time=   0.6s\n",
      "[CV 1/5] END m__C=10, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.486 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END m__C=10, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.489 total time=   0.9s\n",
      "[CV 2/5] END m__C=10, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.483 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END m__C=10, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.500 total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END m__C=10, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.486 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END m__C=10, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.483 total time=   1.0s\n",
      "[CV 5/5] END m__C=10, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.500 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END m__C=10, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.479 total time=   1.3s\n",
      "[CV 4/5] END m__C=10, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.489 total time=   1.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END m__C=0.01, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.465 total time=   0.7s\n",
      "[CV 3/5] END m__C=0.01, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.467 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END m__C=0.01, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.453 total time=   1.0s\n",
      "[CV 5/5] END m__C=0.01, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.478 total time=   1.3s\n",
      "[CV 2/5] END m__C=0.01, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.459 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=10, m__penalty=l2, m__solver=liblinear, m__tol=0.0001;, score=0.483 total time=   0.4s\n",
      "[CV 4/5] END m__C=10, m__penalty=l2, m__solver=liblinear, m__tol=0.0001;, score=0.479 total time=   0.7s\n",
      "[CV 2/5] END m__C=10, m__penalty=l2, m__solver=liblinear, m__tol=0.0001;, score=0.474 total time=   0.9s\n",
      "[CV 3/5] END m__C=10, m__penalty=l2, m__solver=liblinear, m__tol=0.0001;, score=0.469 total time=   1.1s\n",
      "[CV 1/5] END m__C=10, m__penalty=l2, m__solver=liblinear, m__tol=0.0001;, score=0.470 total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.0001;, score=0.373 total time=   0.1s\n",
      "[CV 3/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.0001;, score=0.370 total time=   0.1s\n",
      "[CV 5/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.0001;, score=0.373 total time=   0.2s\n",
      "[CV 1/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.0001;, score=0.357 total time=   0.2s\n",
      "[CV 2/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.0001;, score=0.370 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END m__C=1, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.487 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END m__C=1, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.500 total time=   1.1s\n",
      "[CV 2/5] END m__C=1, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.483 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END m__C=1, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.477 total time=   1.4s\n",
      "[CV 4/5] END m__C=1, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.489 total time=   1.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__C=0.01, m__penalty=l2, m__solver=saga, m__tol=0.01;, score=0.459 total time=   0.2s\n",
      "[CV 1/5] END m__C=0.01, m__penalty=l2, m__solver=saga, m__tol=0.01;, score=0.447 total time=   0.3s\n",
      "[CV 5/5] END m__C=0.01, m__penalty=l2, m__solver=saga, m__tol=0.01;, score=0.473 total time=   0.3s\n",
      "[CV 3/5] END m__C=0.01, m__penalty=l2, m__solver=saga, m__tol=0.01;, score=0.463 total time=   0.3s\n",
      "[CV 2/5] END m__C=0.01, m__penalty=l2, m__solver=saga, m__tol=0.01;, score=0.454 total time=   0.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__C=0.1, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.463 total time=   0.2s\n",
      "[CV 3/5] END m__C=0.1, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.464 total time=   0.2s\n",
      "[CV 2/5] END m__C=0.1, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.470 total time=   0.3s\n",
      "[CV 4/5] END m__C=0.1, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.470 total time=   0.3s\n",
      "[CV 5/5] END m__C=0.1, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.483 total time=   0.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__C=10, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.475 total time=   1.5s\n",
      "[CV 1/5] END m__C=10, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.469 total time=   1.5s\n",
      "[CV 5/5] END m__C=10, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.481 total time=   2.1s\n",
      "[CV 4/5] END m__C=10, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.480 total time=   2.4s\n",
      "[CV 3/5] END m__C=10, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.468 total time=   3.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__C=0.01, m__penalty=l2, m__solver=liblinear, m__tol=0.0001;, score=0.442 total time=   0.2s\n",
      "[CV 4/5] END m__C=0.01, m__penalty=l2, m__solver=liblinear, m__tol=0.0001;, score=0.440 total time=   0.3s\n",
      "[CV 1/5] END m__C=0.01, m__penalty=l2, m__solver=liblinear, m__tol=0.0001;, score=0.429 total time=   0.4s\n",
      "[CV 5/5] END m__C=0.01, m__penalty=l2, m__solver=liblinear, m__tol=0.0001;, score=0.450 total time=   0.4s\n",
      "[CV 2/5] END m__C=0.01, m__penalty=l2, m__solver=liblinear, m__tol=0.0001;, score=0.441 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.405 total time=   0.8s\n",
      "[CV 4/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.411 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.419 total time=   1.1s\n",
      "[CV 3/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.413 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.415 total time=   1.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.01;, score=0.472 total time=   0.2s\n",
      "[CV 2/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.01;, score=0.474 total time=   0.4s\n",
      "[CV 4/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.01;, score=0.477 total time=   0.4s\n",
      "[CV 5/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.01;, score=0.492 total time=   0.5s\n",
      "[CV 1/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.01;, score=0.469 total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.500 total time=   0.6s\n",
      "[CV 4/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.484 total time=   0.6s\n",
      "[CV 3/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.475 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.481 total time=   1.0s\n",
      "[CV 1/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.480 total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__C=10, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.479 total time=   0.2s\n",
      "[CV 2/5] END m__C=10, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.474 total time=   0.3s\n",
      "[CV 1/5] END m__C=10, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.471 total time=   0.4s\n",
      "[CV 5/5] END m__C=10, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.484 total time=   0.4s\n",
      "[CV 3/5] END m__C=10, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.468 total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.478 total time=   1.0s\n",
      "[CV 4/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.489 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.486 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.500 total time=   1.9s\n",
      "[CV 2/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.483 total time=   1.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.481 total time=   0.6s\n",
      "[CV 1/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.480 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.475 total time=   0.9s\n",
      "[CV 4/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.484 total time=   1.0s\n",
      "[CV 5/5] END m__C=0.1, m__penalty=l2, m__solver=saga, m__tol=0.001;, score=0.500 total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__C=0.1, m__penalty=l2, m__solver=liblinear, m__tol=0.001;, score=0.464 total time=   0.3s\n",
      "[CV 4/5] END m__C=0.1, m__penalty=l2, m__solver=liblinear, m__tol=0.001;, score=0.470 total time=   0.4s\n",
      "[CV 5/5] END m__C=0.1, m__penalty=l2, m__solver=liblinear, m__tol=0.001;, score=0.484 total time=   0.4s\n",
      "[CV 1/5] END m__C=0.1, m__penalty=l2, m__solver=liblinear, m__tol=0.001;, score=0.463 total time=   0.5s\n",
      "[CV 2/5] END m__C=0.1, m__penalty=l2, m__solver=liblinear, m__tol=0.001;, score=0.471 total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.477 total time=   0.3s\n",
      "[CV 5/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.495 total time=   0.7s\n",
      "[CV 3/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.473 total time=   0.7s\n",
      "[CV 2/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.477 total time=   0.7s\n",
      "[CV 1/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.471 total time=   0.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.485 total time=   0.8s\n",
      "[CV 4/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.489 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.476 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.482 total time=   1.4s\n",
      "[CV 5/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.501 total time=   1.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.367 total time=   0.1s\n",
      "[CV 5/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.375 total time=   0.1s\n",
      "[CV 4/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.374 total time=   0.2s\n",
      "[CV 1/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.354 total time=   0.2s\n",
      "[CV 3/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.369 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__C=10, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.475 total time=   1.2s\n",
      "[CV 4/5] END m__C=10, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.480 total time=   1.5s\n",
      "[CV 5/5] END m__C=10, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.483 total time=   1.6s\n",
      "[CV 3/5] END m__C=10, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.468 total time=   1.8s\n",
      "[CV 1/5] END m__C=10, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.469 total time=   2.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END m__C=1, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.489 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END m__C=1, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.477 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END m__C=1, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.487 total time=   1.4s\n",
      "[CV 2/5] END m__C=1, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.483 total time=   1.5s\n",
      "[CV 5/5] END m__C=1, m__penalty=l2, m__solver=saga, m__tol=0.0001;, score=0.500 total time=   1.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.468 total time=   1.0s\n",
      "[CV 4/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.480 total time=   1.0s\n",
      "[CV 2/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.475 total time=   1.2s\n",
      "[CV 5/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.483 total time=   1.5s\n",
      "[CV 1/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.468 total time=   1.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.477 total time=   0.4s\n",
      "[CV 5/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.495 total time=   0.6s\n",
      "[CV 3/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.473 total time=   0.8s\n",
      "[CV 1/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.471 total time=   0.8s\n",
      "[CV 4/5] END m__C=1, m__penalty=l1, m__solver=saga, m__tol=0.01;, score=0.478 total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.411 total time=   0.7s\n",
      "[CV 3/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.413 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.419 total time=   1.1s\n",
      "[CV 2/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.415 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.001;, score=0.405 total time=   1.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.470 total time=   0.3s\n",
      "[CV 5/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.485 total time=   0.3s\n",
      "[CV 2/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.474 total time=   0.4s\n",
      "[CV 3/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.467 total time=   0.4s\n",
      "[CV 4/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.478 total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.486 total time=   0.8s\n",
      "[CV 5/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.500 total time=   0.8s\n",
      "[CV 2/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.483 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.478 total time=   1.2s\n",
      "[CV 4/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.489 total time=   1.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.372 total time=   0.1s\n",
      "[CV 1/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.357 total time=   0.2s\n",
      "[CV 2/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.370 total time=   0.2s\n",
      "[CV 3/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.370 total time=   0.2s\n",
      "[CV 4/5] END m__C=0.01, m__penalty=l1, m__solver=liblinear, m__tol=0.001;, score=0.372 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.413 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.419 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.411 total time=   1.6s\n",
      "[CV 1/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.405 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END m__C=0.01, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.415 total time=   1.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.0001;, score=0.483 total time=   1.5s\n",
      "[CV 3/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.0001;, score=0.468 total time=   1.8s\n",
      "[CV 2/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.0001;, score=0.475 total time=   2.5s\n",
      "[CV 4/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.0001;, score=0.480 total time=   2.7s\n",
      "[CV 1/5] END m__C=1, m__penalty=l1, m__solver=liblinear, m__tol=0.0001;, score=0.468 total time=   3.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=10, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.482 total time=   0.2s\n",
      "[CV 1/5] END m__C=10, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.469 total time=   0.3s\n",
      "[CV 2/5] END m__C=10, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.476 total time=   0.3s\n",
      "[CV 3/5] END m__C=10, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.468 total time=   0.4s\n",
      "[CV 4/5] END m__C=10, m__penalty=l2, m__solver=liblinear, m__tol=0.01;, score=0.479 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__C=0.1, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.477 total time=   0.2s\n",
      "[CV 3/5] END m__C=0.1, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.463 total time=   0.3s\n",
      "[CV 2/5] END m__C=0.1, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.467 total time=   0.4s\n",
      "[CV 4/5] END m__C=0.1, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.467 total time=   0.4s\n",
      "[CV 1/5] END m__C=0.1, m__penalty=l1, m__solver=liblinear, m__tol=0.01;, score=0.458 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.478 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.486 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.483 total time=   1.4s\n",
      "[CV 5/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.500 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahra/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END m__C=10, m__penalty=l1, m__solver=saga, m__tol=0.0001;, score=0.489 total time=   1.7s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=Pipeline(steps=[(&#x27;std_slc&#x27;, StandardScaler()),\n",
       "                                        (&#x27;m&#x27;, LogisticRegression())]),\n",
       "              n_jobs=-1, scoring=&#x27;f1_macro&#x27;,\n",
       "              search_spaces={&#x27;m__C&#x27;: [0.01, 0.1, 1, 10],\n",
       "                             &#x27;m__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                             &#x27;m__solver&#x27;: [&#x27;liblinear&#x27;, &#x27;saga&#x27;],\n",
       "                             &#x27;m__tol&#x27;: [0.0001, 0.001, 0.01]},\n",
       "              verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BayesSearchCV<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=Pipeline(steps=[(&#x27;std_slc&#x27;, StandardScaler()),\n",
       "                                        (&#x27;m&#x27;, LogisticRegression())]),\n",
       "              n_jobs=-1, scoring=&#x27;f1_macro&#x27;,\n",
       "              search_spaces={&#x27;m__C&#x27;: [0.01, 0.1, 1, 10],\n",
       "                             &#x27;m__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                             &#x27;m__solver&#x27;: [&#x27;liblinear&#x27;, &#x27;saga&#x27;],\n",
       "                             &#x27;m__tol&#x27;: [0.0001, 0.001, 0.01]},\n",
       "              verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;std_slc&#x27;, StandardScaler()),\n",
       "                (&#x27;m&#x27;, LogisticRegression(C=10, solver=&#x27;saga&#x27;, tol=0.001))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LogisticRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=10, solver=&#x27;saga&#x27;, tol=0.001)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=Pipeline(steps=[('std_slc', StandardScaler()),\n",
       "                                        ('m', LogisticRegression())]),\n",
       "              n_jobs=-1, scoring='f1_macro',\n",
       "              search_spaces={'m__C': [0.01, 0.1, 1, 10],\n",
       "                             'm__penalty': ['l1', 'l2'],\n",
       "                             'm__solver': ['liblinear', 'saga'],\n",
       "                             'm__tol': [0.0001, 0.001, 0.01]},\n",
       "              verbose=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression()\n",
    "pipe = Pipeline(steps=[('std_slc', StandardScaler()), ('m', m)])\n",
    "pipe.get_params().keys()\n",
    "param_grid = {\n",
    "    'm__solver': ['liblinear', 'saga'],  \n",
    "    'm__penalty': ['l1','l2'],\n",
    "    'm__tol': [1e-4, 1e-3, 1e-2],\n",
    "    'm__C': [ 0.01, 0.1, 1, 10],\n",
    "    # 'm__max_iter': [100, 200, 300],\n",
    "            \n",
    "}\n",
    "clf = BayesSearchCV(pipe, param_grid,n_iter=50,cv=5,verbose=3,n_jobs=-1,refit=True,scoring='f1_macro')\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hn3Byz647VIO",
    "outputId": "a88c8ec4-cf27-4a67-ead6-068b58fecdee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('std_slc', StandardScaler()),\n",
      "                ('m', LogisticRegression(C=10, solver='saga', tol=0.001))])\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wPXFPEVa7bmu",
    "outputId": "69c89a74-6277-4969-9ee4-b886fa5ae3c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        WAKE       0.58      0.40      0.47       881\n",
      "         REM       0.59      0.39      0.47       598\n",
      "       LIGHT       0.61      0.85      0.71      2070\n",
      "        DEEP       0.57      0.21      0.31       532\n",
      "\n",
      "    accuracy                           0.60      4081\n",
      "   macro avg       0.59      0.46      0.49      4081\n",
      "weighted avg       0.60      0.60      0.57      4081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred= clf.predict(x_test)\n",
    "print(classification_report(y_test,y_pred,target_names=['WAKE','REM','LIGHT','DEEP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "0TLBXFGtC074",
    "outputId": "a198067c-baf8-4d19-c7da-03d5ffccfb5b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['WAKE','REM','LIGHT','DEEP'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
