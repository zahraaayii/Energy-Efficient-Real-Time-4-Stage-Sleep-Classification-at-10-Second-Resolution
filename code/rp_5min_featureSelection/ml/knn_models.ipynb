{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R76a0E12YaBO",
    "outputId": "8d085d9e-aced-4ee4-d20f-85729f687986"
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-optimize\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# base_dir='/content/drive/MyDrive/ucd/'\n",
    "base_dir='../../../folders/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CTnnrsLxYaBR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFE\n",
    "np.int = np.int_\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ucddb002', 'ucddb003', 'ucddb005', 'ucddb006', 'ucddb007', 'ucddb008', 'ucddb009', 'ucddb010', 'ucddb011', 'ucddb012', 'ucddb013', 'ucddb014', 'ucddb015', 'ucddb017', 'ucddb018', 'ucddb019', 'ucddb020', 'ucddb021', 'ucddb022', 'ucddb023', 'ucddb024', 'ucddb025', 'ucddb026', 'ucddb027', 'ucddb028']\n"
     ]
    }
   ],
   "source": [
    "data_base=[f'ucddb{i:003d}' for i in range(2, 29)]\n",
    "data_base.remove('ucddb004')\n",
    "data_base.remove('ucddb016')\n",
    "print(data_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "# for file in data_base:\n",
    "#     i=pd.read_csv(base_dir+f'feature/{file}_win.csv')\n",
    "#     df = pd.concat([df, i], ignore_index=True)\n",
    "# df.dropna(how='all', axis=1,inplace=True)\n",
    "# df.to_csv(base_dir+f'all/all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HRV_MeanNN_x</th>\n",
       "      <th>HRV_SDNN_x</th>\n",
       "      <th>HRV_RMSSD_x</th>\n",
       "      <th>HRV_SDSD_x</th>\n",
       "      <th>HRV_CVNN_x</th>\n",
       "      <th>HRV_CVSD_x</th>\n",
       "      <th>HRV_MedianNN_x</th>\n",
       "      <th>HRV_MadNN_x</th>\n",
       "      <th>HRV_MCVNN_x</th>\n",
       "      <th>HRV_IQRNN_x</th>\n",
       "      <th>...</th>\n",
       "      <th>peak_to_peak_y</th>\n",
       "      <th>rmse_y</th>\n",
       "      <th>kurtosis_y</th>\n",
       "      <th>skewness_y</th>\n",
       "      <th>waveform_factor_y</th>\n",
       "      <th>peak_factor_y</th>\n",
       "      <th>impulse_factor_y</th>\n",
       "      <th>margin_factor_y</th>\n",
       "      <th>rms_y</th>\n",
       "      <th>anns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>941.406250</td>\n",
       "      <td>13.877191</td>\n",
       "      <td>10.461470</td>\n",
       "      <td>10.590011</td>\n",
       "      <td>0.014741</td>\n",
       "      <td>0.011113</td>\n",
       "      <td>937.50000</td>\n",
       "      <td>11.582812</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>23.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>3.426618</td>\n",
       "      <td>0.499383</td>\n",
       "      <td>3.728094</td>\n",
       "      <td>-0.717594</td>\n",
       "      <td>0.220546</td>\n",
       "      <td>6.861699</td>\n",
       "      <td>1.513324</td>\n",
       "      <td>2.803092</td>\n",
       "      <td>2.316825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>932.963710</td>\n",
       "      <td>19.740977</td>\n",
       "      <td>10.578175</td>\n",
       "      <td>10.598053</td>\n",
       "      <td>0.021159</td>\n",
       "      <td>0.011338</td>\n",
       "      <td>937.50000</td>\n",
       "      <td>11.582812</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.426618</td>\n",
       "      <td>0.510929</td>\n",
       "      <td>3.205934</td>\n",
       "      <td>-0.847646</td>\n",
       "      <td>0.219974</td>\n",
       "      <td>6.706639</td>\n",
       "      <td>1.475284</td>\n",
       "      <td>2.785778</td>\n",
       "      <td>2.378262</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>784.417230</td>\n",
       "      <td>84.031488</td>\n",
       "      <td>92.695165</td>\n",
       "      <td>94.005934</td>\n",
       "      <td>0.107126</td>\n",
       "      <td>0.118171</td>\n",
       "      <td>773.43750</td>\n",
       "      <td>57.914062</td>\n",
       "      <td>0.074879</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.426618</td>\n",
       "      <td>0.512045</td>\n",
       "      <td>3.090319</td>\n",
       "      <td>-1.034765</td>\n",
       "      <td>0.213657</td>\n",
       "      <td>6.692021</td>\n",
       "      <td>1.429797</td>\n",
       "      <td>2.764269</td>\n",
       "      <td>2.453831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>915.826613</td>\n",
       "      <td>27.783640</td>\n",
       "      <td>20.768127</td>\n",
       "      <td>21.063296</td>\n",
       "      <td>0.030337</td>\n",
       "      <td>0.022677</td>\n",
       "      <td>914.06250</td>\n",
       "      <td>23.165625</td>\n",
       "      <td>0.025344</td>\n",
       "      <td>27.343750</td>\n",
       "      <td>...</td>\n",
       "      <td>3.409035</td>\n",
       "      <td>0.460080</td>\n",
       "      <td>3.062617</td>\n",
       "      <td>-0.937992</td>\n",
       "      <td>0.185486</td>\n",
       "      <td>7.409661</td>\n",
       "      <td>1.374385</td>\n",
       "      <td>2.723429</td>\n",
       "      <td>2.526806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>851.562500</td>\n",
       "      <td>115.654429</td>\n",
       "      <td>69.943265</td>\n",
       "      <td>71.024059</td>\n",
       "      <td>0.135814</td>\n",
       "      <td>0.082135</td>\n",
       "      <td>878.90625</td>\n",
       "      <td>98.453906</td>\n",
       "      <td>0.112019</td>\n",
       "      <td>146.484375</td>\n",
       "      <td>...</td>\n",
       "      <td>3.409035</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>4.127472</td>\n",
       "      <td>-1.289496</td>\n",
       "      <td>0.184498</td>\n",
       "      <td>7.256494</td>\n",
       "      <td>1.338809</td>\n",
       "      <td>2.705254</td>\n",
       "      <td>2.589996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20399</th>\n",
       "      <td>803.819444</td>\n",
       "      <td>42.248541</td>\n",
       "      <td>22.410536</td>\n",
       "      <td>22.369303</td>\n",
       "      <td>0.052560</td>\n",
       "      <td>0.027880</td>\n",
       "      <td>808.59375</td>\n",
       "      <td>28.957031</td>\n",
       "      <td>0.035812</td>\n",
       "      <td>33.203125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238339</td>\n",
       "      <td>0.114037</td>\n",
       "      <td>-1.477381</td>\n",
       "      <td>0.240137</td>\n",
       "      <td>0.037104</td>\n",
       "      <td>2.090020</td>\n",
       "      <td>0.077549</td>\n",
       "      <td>0.180015</td>\n",
       "      <td>3.074504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20400</th>\n",
       "      <td>740.985577</td>\n",
       "      <td>57.787447</td>\n",
       "      <td>17.377094</td>\n",
       "      <td>17.605423</td>\n",
       "      <td>0.077987</td>\n",
       "      <td>0.023451</td>\n",
       "      <td>734.37500</td>\n",
       "      <td>69.496875</td>\n",
       "      <td>0.094634</td>\n",
       "      <td>85.937500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238339</td>\n",
       "      <td>0.114434</td>\n",
       "      <td>-1.474395</td>\n",
       "      <td>0.259257</td>\n",
       "      <td>0.037259</td>\n",
       "      <td>2.082769</td>\n",
       "      <td>0.077601</td>\n",
       "      <td>0.180046</td>\n",
       "      <td>3.072412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20401</th>\n",
       "      <td>805.555556</td>\n",
       "      <td>13.043136</td>\n",
       "      <td>11.587810</td>\n",
       "      <td>11.754803</td>\n",
       "      <td>0.016191</td>\n",
       "      <td>0.014385</td>\n",
       "      <td>804.68750</td>\n",
       "      <td>11.582812</td>\n",
       "      <td>0.014394</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236386</td>\n",
       "      <td>0.113433</td>\n",
       "      <td>-1.441417</td>\n",
       "      <td>0.320433</td>\n",
       "      <td>0.036976</td>\n",
       "      <td>2.083932</td>\n",
       "      <td>0.077055</td>\n",
       "      <td>0.178622</td>\n",
       "      <td>3.068847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20402</th>\n",
       "      <td>808.159722</td>\n",
       "      <td>16.004808</td>\n",
       "      <td>10.889563</td>\n",
       "      <td>11.048543</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.013475</td>\n",
       "      <td>812.50000</td>\n",
       "      <td>23.165625</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>23.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236386</td>\n",
       "      <td>0.112289</td>\n",
       "      <td>-1.428370</td>\n",
       "      <td>0.317029</td>\n",
       "      <td>0.036602</td>\n",
       "      <td>2.105157</td>\n",
       "      <td>0.077054</td>\n",
       "      <td>0.178621</td>\n",
       "      <td>3.068897</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20403</th>\n",
       "      <td>792.229730</td>\n",
       "      <td>19.527731</td>\n",
       "      <td>10.001492</td>\n",
       "      <td>9.948072</td>\n",
       "      <td>0.024649</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>796.87500</td>\n",
       "      <td>23.165625</td>\n",
       "      <td>0.029071</td>\n",
       "      <td>23.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238339</td>\n",
       "      <td>0.113477</td>\n",
       "      <td>-1.419373</td>\n",
       "      <td>0.332327</td>\n",
       "      <td>0.036994</td>\n",
       "      <td>2.100331</td>\n",
       "      <td>0.077699</td>\n",
       "      <td>0.180102</td>\n",
       "      <td>3.068573</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20404 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HRV_MeanNN_x  HRV_SDNN_x  HRV_RMSSD_x  HRV_SDSD_x  HRV_CVNN_x  \\\n",
       "0        941.406250   13.877191    10.461470   10.590011    0.014741   \n",
       "1        932.963710   19.740977    10.578175   10.598053    0.021159   \n",
       "2        784.417230   84.031488    92.695165   94.005934    0.107126   \n",
       "3        915.826613   27.783640    20.768127   21.063296    0.030337   \n",
       "4        851.562500  115.654429    69.943265   71.024059    0.135814   \n",
       "...             ...         ...          ...         ...         ...   \n",
       "20399    803.819444   42.248541    22.410536   22.369303    0.052560   \n",
       "20400    740.985577   57.787447    17.377094   17.605423    0.077987   \n",
       "20401    805.555556   13.043136    11.587810   11.754803    0.016191   \n",
       "20402    808.159722   16.004808    10.889563   11.048543    0.019804   \n",
       "20403    792.229730   19.527731    10.001492    9.948072    0.024649   \n",
       "\n",
       "       HRV_CVSD_x  HRV_MedianNN_x  HRV_MadNN_x  HRV_MCVNN_x  HRV_IQRNN_x  ...  \\\n",
       "0        0.011113       937.50000    11.582812     0.012355    23.437500  ...   \n",
       "1        0.011338       937.50000    11.582812     0.012355    15.625000  ...   \n",
       "2        0.118171       773.43750    57.914062     0.074879    93.750000  ...   \n",
       "3        0.022677       914.06250    23.165625     0.025344    27.343750  ...   \n",
       "4        0.082135       878.90625    98.453906     0.112019   146.484375  ...   \n",
       "...           ...             ...          ...          ...          ...  ...   \n",
       "20399    0.027880       808.59375    28.957031     0.035812    33.203125  ...   \n",
       "20400    0.023451       734.37500    69.496875     0.094634    85.937500  ...   \n",
       "20401    0.014385       804.68750    11.582812     0.014394    15.625000  ...   \n",
       "20402    0.013475       812.50000    23.165625     0.028512    23.437500  ...   \n",
       "20403    0.012624       796.87500    23.165625     0.029071    23.437500  ...   \n",
       "\n",
       "       peak_to_peak_y    rmse_y  kurtosis_y  skewness_y  waveform_factor_y  \\\n",
       "0            3.426618  0.499383    3.728094   -0.717594           0.220546   \n",
       "1            3.426618  0.510929    3.205934   -0.847646           0.219974   \n",
       "2            3.426618  0.512045    3.090319   -1.034765           0.213657   \n",
       "3            3.409035  0.460080    3.062617   -0.937992           0.185486   \n",
       "4            3.409035  0.469791    4.127472   -1.289496           0.184498   \n",
       "...               ...       ...         ...         ...                ...   \n",
       "20399        0.238339  0.114037   -1.477381    0.240137           0.037104   \n",
       "20400        0.238339  0.114434   -1.474395    0.259257           0.037259   \n",
       "20401        0.236386  0.113433   -1.441417    0.320433           0.036976   \n",
       "20402        0.236386  0.112289   -1.428370    0.317029           0.036602   \n",
       "20403        0.238339  0.113477   -1.419373    0.332327           0.036994   \n",
       "\n",
       "       peak_factor_y  impulse_factor_y  margin_factor_y     rms_y  anns  \n",
       "0           6.861699          1.513324         2.803092  2.316825     0  \n",
       "1           6.706639          1.475284         2.785778  2.378262     0  \n",
       "2           6.692021          1.429797         2.764269  2.453831     0  \n",
       "3           7.409661          1.374385         2.723429  2.526806     0  \n",
       "4           7.256494          1.338809         2.705254  2.589996     0  \n",
       "...              ...               ...              ...       ...   ...  \n",
       "20399       2.090020          0.077549         0.180015  3.074504     0  \n",
       "20400       2.082769          0.077601         0.180046  3.072412     0  \n",
       "20401       2.083932          0.077055         0.178622  3.068847     0  \n",
       "20402       2.105157          0.077054         0.178621  3.068897     2  \n",
       "20403       2.100331          0.077699         0.180102  3.068573     2  \n",
       "\n",
       "[20404 rows x 188 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = pd.read_csv(base_dir+f'all/all_win.csv')\n",
    "data_set = data_set.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 31 features.\n"
     ]
    }
   ],
   "source": [
    "# Assuming your target variable is named 'target'\n",
    "x = data_set.drop('anns', axis=1)  # Features\n",
    "y = data_set['anns']  # Target variable\n",
    "\n",
    "# Create the estimator (in this case, LogisticRegression)\n",
    "estimator = RandomForestClassifier()\n",
    "\n",
    "# Create the RFE object\n",
    "rfe = RFE(estimator, n_features_to_select=30, step=3, verbose=10)\n",
    "\n",
    "# Fit the RFE object to the data\n",
    "rfe.fit(x, y)\n",
    "\n",
    "# Get the column names of the selected features\n",
    "selected_features = x.columns[rfe.support_]\n",
    "\n",
    "# Create a new DataFrame with the selected features\n",
    "x = data_set[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HRV_MeanNN_x</th>\n",
       "      <th>HRV_Prc20NN_x</th>\n",
       "      <th>HRV_MeanNN_y</th>\n",
       "      <th>HRV_SDANN1_y</th>\n",
       "      <th>HRV_CVSD_y</th>\n",
       "      <th>HRV_MCVNN_y</th>\n",
       "      <th>HRV_SDRMSSD_y</th>\n",
       "      <th>HRV_pNN20_y</th>\n",
       "      <th>HRV_MinNN_y</th>\n",
       "      <th>HRV_MaxNN_y</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_y</th>\n",
       "      <th>median_y</th>\n",
       "      <th>std_y</th>\n",
       "      <th>var_y</th>\n",
       "      <th>peak_to_peak_y</th>\n",
       "      <th>rmse_y</th>\n",
       "      <th>kurtosis_y</th>\n",
       "      <th>skewness_y</th>\n",
       "      <th>waveform_factor_y</th>\n",
       "      <th>peak_factor_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>941.406250</td>\n",
       "      <td>929.6875</td>\n",
       "      <td>887.054896</td>\n",
       "      <td>55.045392</td>\n",
       "      <td>0.111944</td>\n",
       "      <td>0.062822</td>\n",
       "      <td>1.180125</td>\n",
       "      <td>32.937685</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1656.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>2.264299</td>\n",
       "      <td>2.138217</td>\n",
       "      <td>0.490537</td>\n",
       "      <td>0.240627</td>\n",
       "      <td>3.426618</td>\n",
       "      <td>0.499383</td>\n",
       "      <td>3.728094</td>\n",
       "      <td>-0.717594</td>\n",
       "      <td>0.220546</td>\n",
       "      <td>6.861699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>932.963710</td>\n",
       "      <td>929.6875</td>\n",
       "      <td>890.181903</td>\n",
       "      <td>34.516891</td>\n",
       "      <td>0.112334</td>\n",
       "      <td>0.062822</td>\n",
       "      <td>1.181979</td>\n",
       "      <td>35.223881</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1656.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>2.322683</td>\n",
       "      <td>2.182173</td>\n",
       "      <td>0.511149</td>\n",
       "      <td>0.261274</td>\n",
       "      <td>3.426618</td>\n",
       "      <td>0.510929</td>\n",
       "      <td>3.205934</td>\n",
       "      <td>-0.847646</td>\n",
       "      <td>0.219974</td>\n",
       "      <td>6.706639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>784.417230</td>\n",
       "      <td>750.0000</td>\n",
       "      <td>893.314933</td>\n",
       "      <td>59.306612</td>\n",
       "      <td>0.112102</td>\n",
       "      <td>0.062294</td>\n",
       "      <td>1.197097</td>\n",
       "      <td>35.928144</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1656.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>2.396577</td>\n",
       "      <td>2.293529</td>\n",
       "      <td>0.526978</td>\n",
       "      <td>0.277706</td>\n",
       "      <td>3.426618</td>\n",
       "      <td>0.512045</td>\n",
       "      <td>3.090319</td>\n",
       "      <td>-1.034765</td>\n",
       "      <td>0.213657</td>\n",
       "      <td>6.692021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>915.826613</td>\n",
       "      <td>898.4375</td>\n",
       "      <td>911.847370</td>\n",
       "      <td>38.943009</td>\n",
       "      <td>0.105690</td>\n",
       "      <td>0.049420</td>\n",
       "      <td>1.165251</td>\n",
       "      <td>32.926829</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1656.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>2.480407</td>\n",
       "      <td>2.476190</td>\n",
       "      <td>0.482002</td>\n",
       "      <td>0.232326</td>\n",
       "      <td>3.409035</td>\n",
       "      <td>0.460080</td>\n",
       "      <td>3.062617</td>\n",
       "      <td>-0.937992</td>\n",
       "      <td>0.185486</td>\n",
       "      <td>7.409661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>851.562500</td>\n",
       "      <td>789.0625</td>\n",
       "      <td>913.560780</td>\n",
       "      <td>54.877815</td>\n",
       "      <td>0.105679</td>\n",
       "      <td>0.036759</td>\n",
       "      <td>1.168852</td>\n",
       "      <td>32.110092</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1656.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>2.546320</td>\n",
       "      <td>2.625641</td>\n",
       "      <td>0.473641</td>\n",
       "      <td>0.224336</td>\n",
       "      <td>3.409035</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>4.127472</td>\n",
       "      <td>-1.289496</td>\n",
       "      <td>0.184498</td>\n",
       "      <td>7.256494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20399</th>\n",
       "      <td>803.819444</td>\n",
       "      <td>789.0625</td>\n",
       "      <td>793.849469</td>\n",
       "      <td>14.224312</td>\n",
       "      <td>0.020415</td>\n",
       "      <td>0.029071</td>\n",
       "      <td>2.215166</td>\n",
       "      <td>12.466844</td>\n",
       "      <td>632.8125</td>\n",
       "      <td>882.8125</td>\n",
       "      <td>...</td>\n",
       "      <td>3.073420</td>\n",
       "      <td>3.055433</td>\n",
       "      <td>0.081616</td>\n",
       "      <td>0.006661</td>\n",
       "      <td>0.238339</td>\n",
       "      <td>0.114037</td>\n",
       "      <td>-1.477381</td>\n",
       "      <td>0.240137</td>\n",
       "      <td>0.037104</td>\n",
       "      <td>2.090020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20400</th>\n",
       "      <td>740.985577</td>\n",
       "      <td>692.1875</td>\n",
       "      <td>794.921875</td>\n",
       "      <td>16.700587</td>\n",
       "      <td>0.019212</td>\n",
       "      <td>0.028788</td>\n",
       "      <td>2.249370</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>632.8125</td>\n",
       "      <td>882.8125</td>\n",
       "      <td>...</td>\n",
       "      <td>3.071327</td>\n",
       "      <td>3.051526</td>\n",
       "      <td>0.081651</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.238339</td>\n",
       "      <td>0.114434</td>\n",
       "      <td>-1.474395</td>\n",
       "      <td>0.259257</td>\n",
       "      <td>0.037259</td>\n",
       "      <td>2.082769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20401</th>\n",
       "      <td>805.555556</td>\n",
       "      <td>796.8750</td>\n",
       "      <td>800.289042</td>\n",
       "      <td>6.541426</td>\n",
       "      <td>0.018375</td>\n",
       "      <td>0.028788</td>\n",
       "      <td>1.571215</td>\n",
       "      <td>10.723861</td>\n",
       "      <td>726.5625</td>\n",
       "      <td>882.8125</td>\n",
       "      <td>...</td>\n",
       "      <td>3.067751</td>\n",
       "      <td>3.045665</td>\n",
       "      <td>0.082016</td>\n",
       "      <td>0.006727</td>\n",
       "      <td>0.236386</td>\n",
       "      <td>0.113433</td>\n",
       "      <td>-1.441417</td>\n",
       "      <td>0.320433</td>\n",
       "      <td>0.036976</td>\n",
       "      <td>2.083932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20402</th>\n",
       "      <td>808.159722</td>\n",
       "      <td>796.8750</td>\n",
       "      <td>793.662964</td>\n",
       "      <td>18.535262</td>\n",
       "      <td>0.018353</td>\n",
       "      <td>0.029071</td>\n",
       "      <td>2.075336</td>\n",
       "      <td>10.344828</td>\n",
       "      <td>679.6875</td>\n",
       "      <td>882.8125</td>\n",
       "      <td>...</td>\n",
       "      <td>3.067813</td>\n",
       "      <td>3.049573</td>\n",
       "      <td>0.081559</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>0.236386</td>\n",
       "      <td>0.112289</td>\n",
       "      <td>-1.428370</td>\n",
       "      <td>0.317029</td>\n",
       "      <td>0.036602</td>\n",
       "      <td>2.105157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20403</th>\n",
       "      <td>792.229730</td>\n",
       "      <td>775.0000</td>\n",
       "      <td>792.390046</td>\n",
       "      <td>14.811247</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.029071</td>\n",
       "      <td>2.070117</td>\n",
       "      <td>10.582011</td>\n",
       "      <td>679.6875</td>\n",
       "      <td>882.8125</td>\n",
       "      <td>...</td>\n",
       "      <td>3.067486</td>\n",
       "      <td>3.047619</td>\n",
       "      <td>0.081682</td>\n",
       "      <td>0.006672</td>\n",
       "      <td>0.238339</td>\n",
       "      <td>0.113477</td>\n",
       "      <td>-1.419373</td>\n",
       "      <td>0.332327</td>\n",
       "      <td>0.036994</td>\n",
       "      <td>2.100331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20404 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HRV_MeanNN_x  HRV_Prc20NN_x  HRV_MeanNN_y  HRV_SDANN1_y  HRV_CVSD_y  \\\n",
       "0        941.406250       929.6875    887.054896     55.045392    0.111944   \n",
       "1        932.963710       929.6875    890.181903     34.516891    0.112334   \n",
       "2        784.417230       750.0000    893.314933     59.306612    0.112102   \n",
       "3        915.826613       898.4375    911.847370     38.943009    0.105690   \n",
       "4        851.562500       789.0625    913.560780     54.877815    0.105679   \n",
       "...             ...            ...           ...           ...         ...   \n",
       "20399    803.819444       789.0625    793.849469     14.224312    0.020415   \n",
       "20400    740.985577       692.1875    794.921875     16.700587    0.019212   \n",
       "20401    805.555556       796.8750    800.289042      6.541426    0.018375   \n",
       "20402    808.159722       796.8750    793.662964     18.535262    0.018353   \n",
       "20403    792.229730       775.0000    792.390046     14.811247    0.018393   \n",
       "\n",
       "       HRV_MCVNN_y  HRV_SDRMSSD_y  HRV_pNN20_y  HRV_MinNN_y  HRV_MaxNN_y  ...  \\\n",
       "0         0.062822       1.180125    32.937685     304.6875    1656.2500  ...   \n",
       "1         0.062822       1.181979    35.223881     304.6875    1656.2500  ...   \n",
       "2         0.062294       1.197097    35.928144     304.6875    1656.2500  ...   \n",
       "3         0.049420       1.165251    32.926829     304.6875    1656.2500  ...   \n",
       "4         0.036759       1.168852    32.110092     304.6875    1656.2500  ...   \n",
       "...            ...            ...          ...          ...          ...  ...   \n",
       "20399     0.029071       2.215166    12.466844     632.8125     882.8125  ...   \n",
       "20400     0.028788       2.249370    12.500000     632.8125     882.8125  ...   \n",
       "20401     0.028788       1.571215    10.723861     726.5625     882.8125  ...   \n",
       "20402     0.029071       2.075336    10.344828     679.6875     882.8125  ...   \n",
       "20403     0.029071       2.070117    10.582011     679.6875     882.8125  ...   \n",
       "\n",
       "         mean_y  median_y     std_y     var_y  peak_to_peak_y    rmse_y  \\\n",
       "0      2.264299  2.138217  0.490537  0.240627        3.426618  0.499383   \n",
       "1      2.322683  2.182173  0.511149  0.261274        3.426618  0.510929   \n",
       "2      2.396577  2.293529  0.526978  0.277706        3.426618  0.512045   \n",
       "3      2.480407  2.476190  0.482002  0.232326        3.409035  0.460080   \n",
       "4      2.546320  2.625641  0.473641  0.224336        3.409035  0.469791   \n",
       "...         ...       ...       ...       ...             ...       ...   \n",
       "20399  3.073420  3.055433  0.081616  0.006661        0.238339  0.114037   \n",
       "20400  3.071327  3.051526  0.081651  0.006667        0.238339  0.114434   \n",
       "20401  3.067751  3.045665  0.082016  0.006727        0.236386  0.113433   \n",
       "20402  3.067813  3.049573  0.081559  0.006652        0.236386  0.112289   \n",
       "20403  3.067486  3.047619  0.081682  0.006672        0.238339  0.113477   \n",
       "\n",
       "       kurtosis_y  skewness_y  waveform_factor_y  peak_factor_y  \n",
       "0        3.728094   -0.717594           0.220546       6.861699  \n",
       "1        3.205934   -0.847646           0.219974       6.706639  \n",
       "2        3.090319   -1.034765           0.213657       6.692021  \n",
       "3        3.062617   -0.937992           0.185486       7.409661  \n",
       "4        4.127472   -1.289496           0.184498       7.256494  \n",
       "...           ...         ...                ...            ...  \n",
       "20399   -1.477381    0.240137           0.037104       2.090020  \n",
       "20400   -1.474395    0.259257           0.037259       2.082769  \n",
       "20401   -1.441417    0.320433           0.036976       2.083932  \n",
       "20402   -1.428370    0.317029           0.036602       2.105157  \n",
       "20403   -1.419373    0.332327           0.036994       2.100331  \n",
       "\n",
       "[20404 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=4405 (21.589%)\n",
      "Class=2, n=10347 (50.711%)\n",
      "Class=3, n=2661 (13.042%)\n",
      "Class=1, n=2991 (14.659%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize distribution\n",
    "counter = Counter(y)\n",
    "for k,v in counter.items():\n",
    " per = v / len(y) * 100\n",
    " print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= train_test_split(x,y, test_size=0.2,stratify=y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = KNeighborsClassifier()\n",
    "# model.fit(x_train, y_train)\n",
    "# y_pred= model.predict(x_test)\n",
    "# print(classification_report(y_test,y_pred,target_names=['WAKE','REM','LIGHT','DEEP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-XFsFVnff2xw",
    "outputId": "4dfdc937-2f04-46ed-da1e-ed2b67308b00"
   },
   "outputs": [],
   "source": [
    "m = KNeighborsClassifier()\n",
    "pipe = Pipeline(steps=[('std_slc', StandardScaler()), ('m', m)])\n",
    "param_grid = {\n",
    "    'm__n_neighbors': [1,3, 5, 7, 9, 11],  # Number of neighbors to use\n",
    "    'm__weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
    "    'm__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algorithm used to compute the nearest neighbors\n",
    "    'm__leaf_size': [30, 40, 50],  # Leaf size passed to BallTree or KDTree\n",
    "    'm__p': [1, 2],  # Power parameter for the Minkowski metric           \n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "_eErKIokgfIj",
    "outputId": "0f4617c9-8aea-4d1b-af02-357db18486e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=11, m__p=1, m__weights=distance;, score=0.847 total time=   0.8s\n",
      "[CV 2/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=11, m__p=1, m__weights=distance;, score=0.840 total time=   0.8s\n",
      "[CV 3/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=11, m__p=1, m__weights=distance;, score=0.842 total time=   1.1s\n",
      "[CV 5/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=11, m__p=1, m__weights=distance;, score=0.854 total time=   1.2s\n",
      "[CV 4/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=11, m__p=1, m__weights=distance;, score=0.838 total time=   1.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=9, m__p=1, m__weights=distance;, score=0.850 total time=   0.7s\n",
      "[CV 5/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=9, m__p=1, m__weights=distance;, score=0.857 total time=   0.7s\n",
      "[CV 3/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=9, m__p=1, m__weights=distance;, score=0.853 total time=   0.7s\n",
      "[CV 2/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=9, m__p=1, m__weights=distance;, score=0.848 total time=   1.0s\n",
      "[CV 1/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=9, m__p=1, m__weights=distance;, score=0.855 total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=9, m__p=2, m__weights=uniform;, score=0.790 total time=   0.1s\n",
      "[CV 2/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=9, m__p=2, m__weights=uniform;, score=0.787 total time=   0.2s\n",
      "[CV 3/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=9, m__p=2, m__weights=uniform;, score=0.789 total time=   0.1s\n",
      "[CV 1/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=9, m__p=2, m__weights=uniform;, score=0.783 total time=   0.2s\n",
      "[CV 4/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=9, m__p=2, m__weights=uniform;, score=0.781 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=9, m__p=1, m__weights=uniform;, score=0.803 total time=   0.3s\n",
      "[CV 4/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=9, m__p=1, m__weights=uniform;, score=0.804 total time=   0.2s\n",
      "[CV 2/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=9, m__p=1, m__weights=uniform;, score=0.801 total time=   0.2s\n",
      "[CV 3/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=9, m__p=1, m__weights=uniform;, score=0.806 total time=   0.2s\n",
      "[CV 5/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=9, m__p=1, m__weights=uniform;, score=0.813 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__algorithm=ball_tree, m__leaf_size=50, m__n_neighbors=7, m__p=2, m__weights=distance;, score=0.836 total time=   0.1s\n",
      "[CV 3/5] END m__algorithm=ball_tree, m__leaf_size=50, m__n_neighbors=7, m__p=2, m__weights=distance;, score=0.839 total time=   0.1s\n",
      "[CV 4/5] END m__algorithm=ball_tree, m__leaf_size=50, m__n_neighbors=7, m__p=2, m__weights=distance;, score=0.836 total time=   0.1s\n",
      "[CV 1/5] END m__algorithm=ball_tree, m__leaf_size=50, m__n_neighbors=7, m__p=2, m__weights=distance;, score=0.840 total time=   0.1s\n",
      "[CV 5/5] END m__algorithm=ball_tree, m__leaf_size=50, m__n_neighbors=7, m__p=2, m__weights=distance;, score=0.846 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__algorithm=ball_tree, m__leaf_size=30, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.884 total time=   0.2s\n",
      "[CV 4/5] END m__algorithm=ball_tree, m__leaf_size=30, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.869 total time=   0.3s\n",
      "[CV 1/5] END m__algorithm=ball_tree, m__leaf_size=30, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.876 total time=   0.2s\n",
      "[CV 3/5] END m__algorithm=ball_tree, m__leaf_size=30, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.878 total time=   0.2s\n",
      "[CV 2/5] END m__algorithm=ball_tree, m__leaf_size=30, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.866 total time=   0.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=2, m__weights=distance;, score=0.859 total time=   0.1s\n",
      "[CV 5/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=2, m__weights=distance;, score=0.871 total time=   0.1s\n",
      "[CV 3/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=2, m__weights=distance;, score=0.872 total time=   0.1s\n",
      "[CV 1/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=2, m__weights=distance;, score=0.863 total time=   0.1s\n",
      "[CV 4/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=2, m__weights=distance;, score=0.861 total time=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=7, m__p=1, m__weights=distance;, score=0.868 total time=   0.2s\n",
      "[CV 1/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=7, m__p=1, m__weights=distance;, score=0.861 total time=   0.3s\n",
      "[CV 4/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=7, m__p=1, m__weights=distance;, score=0.858 total time=   0.4s\n",
      "[CV 2/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=7, m__p=1, m__weights=distance;, score=0.858 total time=   0.4s\n",
      "[CV 3/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=7, m__p=1, m__weights=distance;, score=0.858 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__algorithm=auto, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.885 total time=   0.2s\n",
      "[CV 1/5] END m__algorithm=auto, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.880 total time=   0.3s\n",
      "[CV 5/5] END m__algorithm=auto, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.892 total time=   0.4s\n",
      "[CV 2/5] END m__algorithm=auto, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.877 total time=   0.4s\n",
      "[CV 4/5] END m__algorithm=auto, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.879 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=5, m__p=1, m__weights=uniform;, score=0.854 total time=   0.6s\n",
      "[CV 5/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=5, m__p=1, m__weights=uniform;, score=0.860 total time=   0.6s\n",
      "[CV 1/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=5, m__p=1, m__weights=uniform;, score=0.853 total time=   0.7s\n",
      "[CV 4/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=5, m__p=1, m__weights=uniform;, score=0.848 total time=   0.8s\n",
      "[CV 2/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=5, m__p=1, m__weights=uniform;, score=0.845 total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=3, m__p=2, m__weights=uniform;, score=0.856 total time=   0.2s\n",
      "[CV 2/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=3, m__p=2, m__weights=uniform;, score=0.845 total time=   0.2s\n",
      "[CV 1/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=3, m__p=2, m__weights=uniform;, score=0.848 total time=   0.2s\n",
      "[CV 5/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=3, m__p=2, m__weights=uniform;, score=0.854 total time=   0.2s\n",
      "[CV 4/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=3, m__p=2, m__weights=uniform;, score=0.849 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=5, m__p=1, m__weights=uniform;, score=0.845 total time=   0.7s\n",
      "[CV 4/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=5, m__p=1, m__weights=uniform;, score=0.848 total time=   0.7s\n",
      "[CV 1/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=5, m__p=1, m__weights=uniform;, score=0.853 total time=   0.7s\n",
      "[CV 3/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=5, m__p=1, m__weights=uniform;, score=0.854 total time=   0.8s\n",
      "[CV 5/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=5, m__p=1, m__weights=uniform;, score=0.860 total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__algorithm=ball_tree, m__leaf_size=50, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.884 total time=   0.2s\n",
      "[CV 4/5] END m__algorithm=ball_tree, m__leaf_size=50, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.869 total time=   0.4s\n",
      "[CV 2/5] END m__algorithm=ball_tree, m__leaf_size=50, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.866 total time=   0.4s\n",
      "[CV 1/5] END m__algorithm=ball_tree, m__leaf_size=50, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.876 total time=   0.4s\n",
      "[CV 3/5] END m__algorithm=ball_tree, m__leaf_size=50, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.878 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=5, m__p=2, m__weights=uniform;, score=0.830 total time=   0.1s\n",
      "[CV 4/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=5, m__p=2, m__weights=uniform;, score=0.829 total time=   0.1s\n",
      "[CV 5/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=5, m__p=2, m__weights=uniform;, score=0.841 total time=   0.1s\n",
      "[CV 2/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=5, m__p=2, m__weights=uniform;, score=0.830 total time=   0.1s\n",
      "[CV 3/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=5, m__p=2, m__weights=uniform;, score=0.829 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=2, m__weights=uniform;, score=0.861 total time=   0.1s\n",
      "[CV 1/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=2, m__weights=uniform;, score=0.863 total time=   0.2s\n",
      "[CV 5/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=2, m__weights=uniform;, score=0.871 total time=   0.2s\n",
      "[CV 3/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=2, m__weights=uniform;, score=0.872 total time=   0.2s\n",
      "[CV 2/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=2, m__weights=uniform;, score=0.859 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=3, m__p=2, m__weights=uniform;, score=0.849 total time=   0.1s\n",
      "[CV 1/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=3, m__p=2, m__weights=uniform;, score=0.848 total time=   0.1s\n",
      "[CV 5/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=3, m__p=2, m__weights=uniform;, score=0.854 total time=   0.1s\n",
      "[CV 2/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=3, m__p=2, m__weights=uniform;, score=0.845 total time=   0.2s\n",
      "[CV 3/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=3, m__p=2, m__weights=uniform;, score=0.856 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=11, m__p=1, m__weights=uniform;, score=0.786 total time=   0.3s\n",
      "[CV 5/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=11, m__p=1, m__weights=uniform;, score=0.795 total time=   0.3s\n",
      "[CV 4/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=11, m__p=1, m__weights=uniform;, score=0.784 total time=   0.4s\n",
      "[CV 2/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=11, m__p=1, m__weights=uniform;, score=0.789 total time=   0.4s\n",
      "[CV 3/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=11, m__p=1, m__weights=uniform;, score=0.785 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__algorithm=ball_tree, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.892 total time=   0.3s\n",
      "[CV 4/5] END m__algorithm=ball_tree, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.879 total time=   0.4s\n",
      "[CV 1/5] END m__algorithm=ball_tree, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.880 total time=   0.4s\n",
      "[CV 2/5] END m__algorithm=ball_tree, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.877 total time=   0.4s\n",
      "[CV 3/5] END m__algorithm=ball_tree, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.885 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=7, m__p=1, m__weights=distance;, score=0.868 total time=   0.6s\n",
      "[CV 3/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=7, m__p=1, m__weights=distance;, score=0.858 total time=   0.8s\n",
      "[CV 4/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=7, m__p=1, m__weights=distance;, score=0.858 total time=   1.0s\n",
      "[CV 2/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=7, m__p=1, m__weights=distance;, score=0.858 total time=   1.1s\n",
      "[CV 1/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=7, m__p=1, m__weights=distance;, score=0.861 total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.866 total time=   0.8s\n",
      "[CV 3/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.878 total time=   0.8s\n",
      "[CV 5/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.884 total time=   1.0s\n",
      "[CV 1/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.876 total time=   1.0s\n",
      "[CV 4/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.869 total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__algorithm=ball_tree, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.879 total time=   0.3s\n",
      "[CV 5/5] END m__algorithm=ball_tree, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.892 total time=   0.3s\n",
      "[CV 3/5] END m__algorithm=ball_tree, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.885 total time=   0.4s\n",
      "[CV 1/5] END m__algorithm=ball_tree, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.880 total time=   0.5s\n",
      "[CV 2/5] END m__algorithm=ball_tree, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.877 total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=11, m__p=2, m__weights=distance;, score=0.830 total time=   0.1s\n",
      "[CV 2/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=11, m__p=2, m__weights=distance;, score=0.814 total time=   0.2s\n",
      "[CV 1/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=11, m__p=2, m__weights=distance;, score=0.820 total time=   0.2s\n",
      "[CV 4/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=11, m__p=2, m__weights=distance;, score=0.818 total time=   0.2s\n",
      "[CV 3/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=11, m__p=2, m__weights=distance;, score=0.823 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.892 total time=   0.4s\n",
      "[CV 3/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.885 total time=   0.5s\n",
      "[CV 1/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.880 total time=   0.5s\n",
      "[CV 2/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.877 total time=   0.6s\n",
      "[CV 4/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.879 total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=1, m__p=2, m__weights=distance;, score=0.872 total time=   0.1s\n",
      "[CV 4/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=1, m__p=2, m__weights=distance;, score=0.861 total time=   0.1s\n",
      "[CV 5/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=1, m__p=2, m__weights=distance;, score=0.871 total time=   0.1s\n",
      "[CV 1/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=1, m__p=2, m__weights=distance;, score=0.862 total time=   0.1s\n",
      "[CV 2/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=1, m__p=2, m__weights=distance;, score=0.859 total time=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=3, m__p=2, m__weights=distance;, score=0.862 total time=   0.2s\n",
      "[CV 1/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=3, m__p=2, m__weights=distance;, score=0.856 total time=   0.2s\n",
      "[CV 2/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=3, m__p=2, m__weights=distance;, score=0.850 total time=   0.2s\n",
      "[CV 3/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=3, m__p=2, m__weights=distance;, score=0.860 total time=   0.3s\n",
      "[CV 4/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=3, m__p=2, m__weights=distance;, score=0.858 total time=   0.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.879 total time=   0.2s\n",
      "[CV 5/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.892 total time=   0.2s\n",
      "[CV 2/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.877 total time=   0.3s\n",
      "[CV 3/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.885 total time=   0.4s\n",
      "[CV 1/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.880 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__algorithm=auto, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.877 total time=   0.3s\n",
      "[CV 5/5] END m__algorithm=auto, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.892 total time=   0.4s\n",
      "[CV 1/5] END m__algorithm=auto, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.880 total time=   0.5s\n",
      "[CV 3/5] END m__algorithm=auto, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.885 total time=   0.5s\n",
      "[CV 4/5] END m__algorithm=auto, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.879 total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=3, m__p=2, m__weights=uniform;, score=0.847 total time=   0.2s\n",
      "[CV 4/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=3, m__p=2, m__weights=uniform;, score=0.849 total time=   0.2s\n",
      "[CV 5/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=3, m__p=2, m__weights=uniform;, score=0.854 total time=   0.2s\n",
      "[CV 2/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=3, m__p=2, m__weights=uniform;, score=0.845 total time=   0.3s\n",
      "[CV 3/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=3, m__p=2, m__weights=uniform;, score=0.856 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=11, m__p=2, m__weights=uniform;, score=0.761 total time=   0.3s\n",
      "[CV 5/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=11, m__p=2, m__weights=uniform;, score=0.775 total time=   0.4s\n",
      "[CV 2/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=11, m__p=2, m__weights=uniform;, score=0.762 total time=   0.4s\n",
      "[CV 1/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=11, m__p=2, m__weights=uniform;, score=0.770 total time=   0.4s\n",
      "[CV 3/5] END m__algorithm=kd_tree, m__leaf_size=50, m__n_neighbors=11, m__p=2, m__weights=uniform;, score=0.769 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=7, m__p=1, m__weights=uniform;, score=0.824 total time=   0.4s\n",
      "[CV 5/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=7, m__p=1, m__weights=uniform;, score=0.838 total time=   0.4s\n",
      "[CV 4/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=7, m__p=1, m__weights=uniform;, score=0.826 total time=   0.4s\n",
      "[CV 1/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=7, m__p=1, m__weights=uniform;, score=0.829 total time=   0.4s\n",
      "[CV 3/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=7, m__p=1, m__weights=uniform;, score=0.829 total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__algorithm=brute, m__leaf_size=50, m__n_neighbors=5, m__p=1, m__weights=distance;, score=0.871 total time=   0.4s\n",
      "[CV 2/5] END m__algorithm=brute, m__leaf_size=50, m__n_neighbors=5, m__p=1, m__weights=distance;, score=0.866 total time=   0.4s\n",
      "[CV 1/5] END m__algorithm=brute, m__leaf_size=50, m__n_neighbors=5, m__p=1, m__weights=distance;, score=0.869 total time=   0.5s\n",
      "[CV 5/5] END m__algorithm=brute, m__leaf_size=50, m__n_neighbors=5, m__p=1, m__weights=distance;, score=0.879 total time=   0.5s\n",
      "[CV 4/5] END m__algorithm=brute, m__leaf_size=50, m__n_neighbors=5, m__p=1, m__weights=distance;, score=0.868 total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.885 total time=   0.3s\n",
      "[CV 2/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.877 total time=   0.4s\n",
      "[CV 1/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.880 total time=   0.4s\n",
      "[CV 4/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.879 total time=   0.5s\n",
      "[CV 5/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.892 total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.892 total time=   0.2s\n",
      "[CV 3/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.885 total time=   0.3s\n",
      "[CV 1/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.880 total time=   0.4s\n",
      "[CV 2/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.877 total time=   0.4s\n",
      "[CV 4/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.879 total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__algorithm=auto, m__leaf_size=50, m__n_neighbors=3, m__p=1, m__weights=uniform;, score=0.867 total time=   0.4s\n",
      "[CV 5/5] END m__algorithm=auto, m__leaf_size=50, m__n_neighbors=3, m__p=1, m__weights=uniform;, score=0.880 total time=   0.5s\n",
      "[CV 2/5] END m__algorithm=auto, m__leaf_size=50, m__n_neighbors=3, m__p=1, m__weights=uniform;, score=0.860 total time=   0.5s\n",
      "[CV 4/5] END m__algorithm=auto, m__leaf_size=50, m__n_neighbors=3, m__p=1, m__weights=uniform;, score=0.861 total time=   0.5s\n",
      "[CV 3/5] END m__algorithm=auto, m__leaf_size=50, m__n_neighbors=3, m__p=1, m__weights=uniform;, score=0.875 total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.892 total time=   0.3s\n",
      "[CV 4/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.879 total time=   0.4s\n",
      "[CV 1/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.880 total time=   0.4s\n",
      "[CV 2/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.877 total time=   0.4s\n",
      "[CV 3/5] END m__algorithm=auto, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.885 total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=9, m__p=2, m__weights=distance;, score=0.828 total time=   0.1s\n",
      "[CV 4/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=9, m__p=2, m__weights=distance;, score=0.821 total time=   0.1s\n",
      "[CV 3/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=9, m__p=2, m__weights=distance;, score=0.832 total time=   0.2s\n",
      "[CV 1/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=9, m__p=2, m__weights=distance;, score=0.831 total time=   0.2s\n",
      "[CV 5/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=9, m__p=2, m__weights=distance;, score=0.834 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.877 total time=   0.3s\n",
      "[CV 3/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.885 total time=   0.3s\n",
      "[CV 4/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.879 total time=   0.4s\n",
      "[CV 1/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.880 total time=   0.4s\n",
      "[CV 5/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.892 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=5, m__p=2, m__weights=distance;, score=0.849 total time=   0.1s\n",
      "[CV 5/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=5, m__p=2, m__weights=distance;, score=0.859 total time=   0.2s\n",
      "[CV 4/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=5, m__p=2, m__weights=distance;, score=0.844 total time=   0.2s\n",
      "[CV 1/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=5, m__p=2, m__weights=distance;, score=0.851 total time=   0.2s\n",
      "[CV 3/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=5, m__p=2, m__weights=distance;, score=0.847 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=7, m__p=2, m__weights=uniform;, score=0.808 total time=   0.1s\n",
      "[CV 3/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=7, m__p=2, m__weights=uniform;, score=0.806 total time=   0.1s\n",
      "[CV 4/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=7, m__p=2, m__weights=uniform;, score=0.803 total time=   0.1s\n",
      "[CV 5/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=7, m__p=2, m__weights=uniform;, score=0.812 total time=   0.2s\n",
      "[CV 2/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=7, m__p=2, m__weights=uniform;, score=0.805 total time=   0.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.885 total time=   0.3s\n",
      "[CV 1/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.880 total time=   0.5s\n",
      "[CV 5/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.892 total time=   0.5s\n",
      "[CV 2/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.877 total time=   0.5s\n",
      "[CV 4/5] END m__algorithm=kd_tree, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.879 total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.876 total time=   0.4s\n",
      "[CV 5/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.884 total time=   0.4s\n",
      "[CV 2/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.866 total time=   0.4s\n",
      "[CV 4/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.869 total time=   0.4s\n",
      "[CV 3/5] END m__algorithm=brute, m__leaf_size=40, m__n_neighbors=3, m__p=1, m__weights=distance;, score=0.878 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=5, m__p=1, m__weights=distance;, score=0.868 total time=   0.6s\n",
      "[CV 3/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=5, m__p=1, m__weights=distance;, score=0.871 total time=   0.8s\n",
      "[CV 2/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=5, m__p=1, m__weights=distance;, score=0.866 total time=   0.9s\n",
      "[CV 1/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=5, m__p=1, m__weights=distance;, score=0.869 total time=   0.9s\n",
      "[CV 5/5] END m__algorithm=kd_tree, m__leaf_size=40, m__n_neighbors=5, m__p=1, m__weights=distance;, score=0.879 total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.879 total time=   0.2s\n",
      "[CV 2/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.877 total time=   0.3s\n",
      "[CV 1/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.880 total time=   0.3s\n",
      "[CV 3/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.885 total time=   0.4s\n",
      "[CV 5/5] END m__algorithm=auto, m__leaf_size=30, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.892 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.877 total time=   0.2s\n",
      "[CV 5/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.892 total time=   0.3s\n",
      "[CV 1/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.880 total time=   0.3s\n",
      "[CV 4/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.879 total time=   0.4s\n",
      "[CV 3/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=distance;, score=0.885 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__algorithm=ball_tree, m__leaf_size=30, m__n_neighbors=7, m__p=1, m__weights=uniform;, score=0.838 total time=   0.3s\n",
      "[CV 3/5] END m__algorithm=ball_tree, m__leaf_size=30, m__n_neighbors=7, m__p=1, m__weights=uniform;, score=0.829 total time=   0.4s\n",
      "[CV 1/5] END m__algorithm=ball_tree, m__leaf_size=30, m__n_neighbors=7, m__p=1, m__weights=uniform;, score=0.829 total time=   0.4s\n",
      "[CV 4/5] END m__algorithm=ball_tree, m__leaf_size=30, m__n_neighbors=7, m__p=1, m__weights=uniform;, score=0.826 total time=   0.4s\n",
      "[CV 2/5] END m__algorithm=ball_tree, m__leaf_size=30, m__n_neighbors=7, m__p=1, m__weights=uniform;, score=0.824 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.879 total time=   0.2s\n",
      "[CV 2/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.877 total time=   0.3s\n",
      "[CV 1/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.880 total time=   0.4s\n",
      "[CV 5/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.892 total time=   0.4s\n",
      "[CV 3/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.885 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=5, m__p=1, m__weights=distance;, score=0.879 total time=   0.4s\n",
      "[CV 1/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=5, m__p=1, m__weights=distance;, score=0.869 total time=   0.4s\n",
      "[CV 2/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=5, m__p=1, m__weights=distance;, score=0.866 total time=   0.4s\n",
      "[CV 4/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=5, m__p=1, m__weights=distance;, score=0.868 total time=   0.4s\n",
      "[CV 3/5] END m__algorithm=ball_tree, m__leaf_size=40, m__n_neighbors=5, m__p=1, m__weights=distance;, score=0.871 total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END m__algorithm=brute, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.880 total time=   0.3s\n",
      "[CV 4/5] END m__algorithm=brute, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.879 total time=   0.3s\n",
      "[CV 2/5] END m__algorithm=brute, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.877 total time=   0.4s\n",
      "[CV 5/5] END m__algorithm=brute, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.892 total time=   0.4s\n",
      "[CV 3/5] END m__algorithm=brute, m__leaf_size=50, m__n_neighbors=1, m__p=1, m__weights=uniform;, score=0.885 total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=11, m__p=2, m__weights=distance;, score=0.818 total time=   0.1s\n",
      "[CV 3/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=11, m__p=2, m__weights=distance;, score=0.823 total time=   0.1s\n",
      "[CV 2/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=11, m__p=2, m__weights=distance;, score=0.814 total time=   0.1s\n",
      "[CV 5/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=11, m__p=2, m__weights=distance;, score=0.830 total time=   0.1s\n",
      "[CV 1/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=11, m__p=2, m__weights=distance;, score=0.820 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=11, m__p=1, m__weights=distance;, score=0.842 total time=   0.3s\n",
      "[CV 2/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=11, m__p=1, m__weights=distance;, score=0.840 total time=   0.3s\n",
      "[CV 5/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=11, m__p=1, m__weights=distance;, score=0.854 total time=   0.4s\n",
      "[CV 4/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=11, m__p=1, m__weights=distance;, score=0.838 total time=   0.4s\n",
      "[CV 1/5] END m__algorithm=brute, m__leaf_size=30, m__n_neighbors=11, m__p=1, m__weights=distance;, score=0.847 total time=   0.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=Pipeline(steps=[(&#x27;std_slc&#x27;, StandardScaler()),\n",
       "                                        (&#x27;m&#x27;, KNeighborsClassifier())]),\n",
       "              n_jobs=-1, scoring=&#x27;f1_macro&#x27;,\n",
       "              search_spaces={&#x27;m__algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;, &#x27;kd_tree&#x27;,\n",
       "                                              &#x27;brute&#x27;],\n",
       "                             &#x27;m__leaf_size&#x27;: [30, 40, 50],\n",
       "                             &#x27;m__n_neighbors&#x27;: [1, 3, 5, 7, 9, 11],\n",
       "                             &#x27;m__p&#x27;: [1, 2],\n",
       "                             &#x27;m__weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "              verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BayesSearchCV<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=Pipeline(steps=[(&#x27;std_slc&#x27;, StandardScaler()),\n",
       "                                        (&#x27;m&#x27;, KNeighborsClassifier())]),\n",
       "              n_jobs=-1, scoring=&#x27;f1_macro&#x27;,\n",
       "              search_spaces={&#x27;m__algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;, &#x27;kd_tree&#x27;,\n",
       "                                              &#x27;brute&#x27;],\n",
       "                             &#x27;m__leaf_size&#x27;: [30, 40, 50],\n",
       "                             &#x27;m__n_neighbors&#x27;: [1, 3, 5, 7, 9, 11],\n",
       "                             &#x27;m__p&#x27;: [1, 2],\n",
       "                             &#x27;m__weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "              verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;std_slc&#x27;, StandardScaler()),\n",
       "                (&#x27;m&#x27;, KNeighborsClassifier(leaf_size=50, n_neighbors=1, p=1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">KNeighborsClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(leaf_size=50, n_neighbors=1, p=1)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=Pipeline(steps=[('std_slc', StandardScaler()),\n",
       "                                        ('m', KNeighborsClassifier())]),\n",
       "              n_jobs=-1, scoring='f1_macro',\n",
       "              search_spaces={'m__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                             'm__leaf_size': [30, 40, 50],\n",
       "                             'm__n_neighbors': [1, 3, 5, 7, 9, 11],\n",
       "                             'm__p': [1, 2],\n",
       "                             'm__weights': ['uniform', 'distance']},\n",
       "              verbose=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BayesSearchCV(pipe, param_grid,n_iter=50,cv=5,verbose=3,n_jobs=-1,refit=True,scoring='f1_macro')\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57o4Jn5Sg1i1",
    "outputId": "562dbe35-d2d1-44ce-c221-692e6d0564e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('std_slc', StandardScaler()),\n",
      "                ('m', KNeighborsClassifier(leaf_size=50, n_neighbors=1, p=1))])\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ccOhJJGg2lB",
    "outputId": "9f009b29-dd12-49c4-9c97-4deed9b34942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        WAKE       0.84      0.74      0.79       881\n",
      "         REM       0.92      0.96      0.94       598\n",
      "       LIGHT       0.88      0.91      0.90      2070\n",
      "        DEEP       0.90      0.92      0.91       532\n",
      "\n",
      "    accuracy                           0.88      4081\n",
      "   macro avg       0.89      0.88      0.88      4081\n",
      "weighted avg       0.88      0.88      0.88      4081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred= clf.predict(x_test)\n",
    "print(classification_report(y_test,y_pred,target_names=['WAKE','REM','LIGHT','DEEP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "qcWVMS8FTBXn",
    "outputId": "8bbd58fe-7df5-4c65-d24d-e1e7ccbfa146"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# %%\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['WAKE','REM','LIGHT','DEEP'])\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
